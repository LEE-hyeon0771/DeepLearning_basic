{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12e5443",
   "metadata": {},
   "source": [
    "# 기본 CNN 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ff2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    '''\n",
    "    input_dim - 입력 데이터(채널 수, 높이, 너비)\n",
    "    conv_param - 합성곱 계층의 하이퍼파라미터(딕셔너리)\n",
    "    -- filter_num = 필터수\n",
    "    -- filter_size = 필터 크기\n",
    "    -- stride = 스트라이드\n",
    "    -- pad = 패딩\n",
    "    -- hidden_size = 은닉층(완전연결)의 뉴런 수\n",
    "    -- output_size = 출력층(완전연결)의 뉴런 수\n",
    "    -- weight_init_std = 초기화 때의 가중치 표준편차\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                conv_param = {'filter_num}':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        \n",
    "        # 합성곱 계층의 출력 크기\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        \n",
    "        # 풀링 계층의 출력 크기\n",
    "        pool_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2))\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = OrderDict()\n",
    "        self.layers['Conv'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.parmas['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        \n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "    \n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f472d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.29927186711489\n",
      "=== epoch:1, train acc:0.181, test acc:0.193 ===\n",
      "train loss:2.2986847965333554\n",
      "train loss:2.295721698092865\n",
      "train loss:2.2898670914782913\n",
      "train loss:2.2835651093639915\n",
      "train loss:2.271047211014419\n",
      "train loss:2.252790354297983\n",
      "train loss:2.236141653621637\n",
      "train loss:2.23260546515645\n",
      "train loss:2.2182793429729815\n",
      "train loss:2.1822454780037037\n",
      "train loss:2.1623701657794476\n",
      "train loss:2.1559971138372687\n",
      "train loss:2.0857599182445963\n",
      "train loss:1.9842707678268274\n",
      "train loss:1.928239576013476\n",
      "train loss:1.9223302773922282\n",
      "train loss:1.8340434086910862\n",
      "train loss:1.7520853802082212\n",
      "train loss:1.8338031893242925\n",
      "train loss:1.6859393505097233\n",
      "train loss:1.6727622875882444\n",
      "train loss:1.5661912961794846\n",
      "train loss:1.4519782085610555\n",
      "train loss:1.4360577728007455\n",
      "train loss:1.3223392982443423\n",
      "train loss:1.2783107949890968\n",
      "train loss:1.2538239636284736\n",
      "train loss:1.1440150104310327\n",
      "train loss:0.9767240515195356\n",
      "train loss:0.8644166803971823\n",
      "train loss:1.0231945697843683\n",
      "train loss:0.9054105471195578\n",
      "train loss:0.8444667287554541\n",
      "train loss:0.8066144209939319\n",
      "train loss:0.6840676077737803\n",
      "train loss:0.6941443609623751\n",
      "train loss:0.7089852959681636\n",
      "train loss:0.6870847566251314\n",
      "train loss:0.6836897666042079\n",
      "train loss:0.676279424478014\n",
      "train loss:0.6364069986783683\n",
      "train loss:0.7465720814746056\n",
      "train loss:0.6482692588384057\n",
      "train loss:0.5289427988383075\n",
      "train loss:0.5555912134851578\n",
      "train loss:0.47828995047836165\n",
      "train loss:0.7330403992371813\n",
      "train loss:0.5502406203317987\n",
      "train loss:0.7728014928785433\n",
      "train loss:0.45526900777048324\n",
      "train loss:0.5391042042706029\n",
      "train loss:0.7037433687634379\n",
      "train loss:0.5514480406320125\n",
      "train loss:0.5744492733568893\n",
      "train loss:0.44694480789031027\n",
      "train loss:0.5922263576378862\n",
      "train loss:0.445194202731612\n",
      "train loss:0.45621070593401825\n",
      "train loss:0.49145967615294095\n",
      "train loss:0.6248130591248156\n",
      "train loss:0.47431994546964246\n",
      "train loss:0.42688413127797004\n",
      "train loss:0.5842648413735226\n",
      "train loss:0.46575923643169226\n",
      "train loss:0.45621124869219265\n",
      "train loss:0.7170105461105551\n",
      "train loss:0.5803877150626107\n",
      "train loss:0.558135050408843\n",
      "train loss:0.4035601462490666\n",
      "train loss:0.42834974692166106\n",
      "train loss:0.514949030974874\n",
      "train loss:0.5196159070483748\n",
      "train loss:0.4024414158283236\n",
      "train loss:0.48041840649453155\n",
      "train loss:0.49686377700707185\n",
      "train loss:0.4584827923261083\n",
      "train loss:0.5210466288722331\n",
      "train loss:0.5787068103397428\n",
      "train loss:0.336800002345494\n",
      "train loss:0.5475485939638656\n",
      "train loss:0.45138985104148227\n",
      "train loss:0.5989406607922236\n",
      "train loss:0.47389691316020643\n",
      "train loss:0.447616485142129\n",
      "train loss:0.5861556731756338\n",
      "train loss:0.3985084583983257\n",
      "train loss:0.3724933368077367\n",
      "train loss:0.45108755164577397\n",
      "train loss:0.4389965801661429\n",
      "train loss:0.38685646479104446\n",
      "train loss:0.511646190818577\n",
      "train loss:0.5675376969500341\n",
      "train loss:0.47055529579501104\n",
      "train loss:0.44106652946399355\n",
      "train loss:0.5606662239244051\n",
      "train loss:0.40758058091727806\n",
      "train loss:0.5405762458596509\n",
      "train loss:0.3648341808328175\n",
      "train loss:0.51628985099781\n",
      "train loss:0.43325212050768785\n",
      "train loss:0.47683188309625285\n",
      "train loss:0.363179119436707\n",
      "train loss:0.4361434342069498\n",
      "train loss:0.2960831383760102\n",
      "train loss:0.411974072996569\n",
      "train loss:0.4065671165103633\n",
      "train loss:0.39160362054434467\n",
      "train loss:0.5157018582669906\n",
      "train loss:0.43015096240033573\n",
      "train loss:0.4328347793580187\n",
      "train loss:0.4194847827562246\n",
      "train loss:0.37310208074415946\n",
      "train loss:0.4962336392497431\n",
      "train loss:0.2607846947178013\n",
      "train loss:0.34141770360326157\n",
      "train loss:0.32103096166004996\n",
      "train loss:0.5516073535397649\n",
      "train loss:0.4441838290654272\n",
      "train loss:0.5892610378525951\n",
      "train loss:0.4897893084898509\n",
      "train loss:0.32455332992291075\n",
      "train loss:0.4106695748048269\n",
      "train loss:0.4424927091475461\n",
      "train loss:0.32266829857175955\n",
      "train loss:0.36271494693201645\n",
      "train loss:0.31251025865393034\n",
      "train loss:0.24850401747490447\n",
      "train loss:0.2995214178121839\n",
      "train loss:0.2391787745815469\n",
      "train loss:0.49645261832822735\n",
      "train loss:0.2884472372335037\n",
      "train loss:0.43125840352939776\n",
      "train loss:0.32877465585813964\n",
      "train loss:0.4509204931459304\n",
      "train loss:0.28756650024331987\n",
      "train loss:0.19022814157201537\n",
      "train loss:0.31031798380762565\n",
      "train loss:0.3494932027142246\n",
      "train loss:0.43405272940399975\n",
      "train loss:0.26769372914355144\n",
      "train loss:0.40537211084444\n",
      "train loss:0.3052792211122814\n",
      "train loss:0.26048631962964075\n",
      "train loss:0.36888500502857263\n",
      "train loss:0.5143600554124385\n",
      "train loss:0.2669843069378351\n",
      "train loss:0.33894576904834284\n",
      "train loss:0.3305612086359091\n",
      "train loss:0.4479637580366612\n",
      "train loss:0.40364375727710977\n",
      "train loss:0.25558968921224356\n",
      "train loss:0.3855967614777984\n",
      "train loss:0.2077567621626055\n",
      "train loss:0.2050075155741151\n",
      "train loss:0.4282664949811065\n",
      "train loss:0.21722028656856485\n",
      "train loss:0.14187787328205892\n",
      "train loss:0.3432053783378467\n",
      "train loss:0.40271971381864724\n",
      "train loss:0.36146123114086737\n",
      "train loss:0.2443166708300009\n",
      "train loss:0.24642742627213388\n",
      "train loss:0.18574020568266267\n",
      "train loss:0.23309335947002915\n",
      "train loss:0.4543655801303759\n",
      "train loss:0.4032294688628285\n",
      "train loss:0.2953041048463258\n",
      "train loss:0.377386711320524\n",
      "train loss:0.28923501126049134\n",
      "train loss:0.4457968638441866\n",
      "train loss:0.28683664549884924\n",
      "train loss:0.3661899913067401\n",
      "train loss:0.4035935112658416\n",
      "train loss:0.2449775709184735\n",
      "train loss:0.4994021621591149\n",
      "train loss:0.3063641769560547\n",
      "train loss:0.32410673525337286\n",
      "train loss:0.22679619401818438\n",
      "train loss:0.311985998843919\n",
      "train loss:0.3641430164784709\n",
      "train loss:0.2667259240339542\n",
      "train loss:0.23379181133766236\n",
      "train loss:0.32056269028434914\n",
      "train loss:0.2392291805439746\n",
      "train loss:0.43365226040971094\n",
      "train loss:0.3428607265241783\n",
      "train loss:0.5084656979181812\n",
      "train loss:0.28877000122001584\n",
      "train loss:0.26504653267401684\n",
      "train loss:0.2784335489979089\n",
      "train loss:0.23790204909903678\n",
      "train loss:0.23971422952280427\n",
      "train loss:0.5411996675817045\n",
      "train loss:0.34197334329682505\n",
      "train loss:0.27439530437648707\n",
      "train loss:0.30008022853536875\n",
      "train loss:0.39729560287028287\n",
      "train loss:0.41829278543045634\n",
      "train loss:0.21800135995932163\n",
      "train loss:0.33741761268515924\n",
      "train loss:0.3432415875774691\n",
      "train loss:0.3536162723206062\n",
      "train loss:0.26106450302860174\n",
      "train loss:0.29591796586301\n",
      "train loss:0.25061123016150133\n",
      "train loss:0.403709449775654\n",
      "train loss:0.5233463336301517\n",
      "train loss:0.36199829439870507\n",
      "train loss:0.38699685011422497\n",
      "train loss:0.24401258122293626\n",
      "train loss:0.38845222024460646\n",
      "train loss:0.2737371936907484\n",
      "train loss:0.4263025024629134\n",
      "train loss:0.222635047535285\n",
      "train loss:0.23586113549006232\n",
      "train loss:0.14927585482430614\n",
      "train loss:0.20939227891906573\n",
      "train loss:0.5300012971239031\n",
      "train loss:0.35526618647483155\n",
      "train loss:0.2729853755483418\n",
      "train loss:0.3013346041986906\n",
      "train loss:0.3358415693393804\n",
      "train loss:0.20890035536288348\n",
      "train loss:0.2545261197744766\n",
      "train loss:0.3381829214382951\n",
      "train loss:0.3844272693070074\n",
      "train loss:0.21597064653839682\n",
      "train loss:0.27913299353160775\n",
      "train loss:0.32182842590259936\n",
      "train loss:0.2829717929524335\n",
      "train loss:0.3680552555628129\n",
      "train loss:0.2614532363670191\n",
      "train loss:0.2973046761032193\n",
      "train loss:0.2650576347133435\n",
      "train loss:0.3567775412557285\n",
      "train loss:0.378651760702841\n",
      "train loss:0.2699300920813396\n",
      "train loss:0.5155027535522937\n",
      "train loss:0.16970768222430813\n",
      "train loss:0.3104393915812083\n",
      "train loss:0.44890597409707184\n",
      "train loss:0.2302287012072092\n",
      "train loss:0.3299666051293099\n",
      "train loss:0.32605680024253425\n",
      "train loss:0.3001362589257922\n",
      "train loss:0.27708173522332663\n",
      "train loss:0.37612890916676284\n",
      "train loss:0.21905954388323357\n",
      "train loss:0.20087844172627153\n",
      "train loss:0.2723681500247777\n",
      "train loss:0.2165652997179258\n",
      "train loss:0.23236690202088872\n",
      "train loss:0.3150429451734741\n",
      "train loss:0.2318840529807692\n",
      "train loss:0.24253717772353403\n",
      "train loss:0.28178147933844594\n",
      "train loss:0.3570996673383588\n",
      "train loss:0.22978020869047844\n",
      "train loss:0.2938449924295016\n",
      "train loss:0.1787852469693313\n",
      "train loss:0.25612144459993186\n",
      "train loss:0.3483244753624197\n",
      "train loss:0.17661832791466986\n",
      "train loss:0.3260331554335004\n",
      "train loss:0.3339698946045824\n",
      "train loss:0.34189883661527753\n",
      "train loss:0.16767511956988687\n",
      "train loss:0.268437980255929\n",
      "train loss:0.17841304063968327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19534724302609227\n",
      "train loss:0.23690151065304252\n",
      "train loss:0.27585486295547207\n",
      "train loss:0.15218082961402485\n",
      "train loss:0.3188717014568369\n",
      "train loss:0.26914016982065847\n",
      "train loss:0.2748806633742198\n",
      "train loss:0.16138886303325306\n",
      "train loss:0.21417967833678675\n",
      "train loss:0.1711067362220046\n",
      "train loss:0.22876714348539337\n",
      "train loss:0.1971054914796428\n",
      "train loss:0.18514164840337785\n",
      "train loss:0.26783614014611207\n",
      "train loss:0.2092698605604314\n",
      "train loss:0.2630528445809724\n",
      "train loss:0.19825488383614281\n",
      "train loss:0.22387669016693923\n",
      "train loss:0.22071184472080788\n",
      "train loss:0.2405553135169628\n",
      "train loss:0.44513564879001777\n",
      "train loss:0.16000509458556578\n",
      "train loss:0.3676282634185858\n",
      "train loss:0.15771629601998155\n",
      "train loss:0.2228269737568646\n",
      "train loss:0.21791241357107388\n",
      "train loss:0.16475135440801403\n",
      "train loss:0.2478103155208581\n",
      "train loss:0.2879880607855321\n",
      "train loss:0.30284179144952766\n",
      "train loss:0.2363705536915644\n",
      "train loss:0.20658896929199153\n",
      "train loss:0.30449365575455617\n",
      "train loss:0.3150792696747469\n",
      "train loss:0.15932081706638407\n",
      "train loss:0.24538473697775742\n",
      "train loss:0.22713877236045615\n",
      "train loss:0.19568044486614883\n",
      "train loss:0.16673757922975876\n",
      "train loss:0.2370127008465246\n",
      "train loss:0.2416210737898399\n",
      "train loss:0.2729677143998633\n",
      "train loss:0.2565111247543039\n",
      "train loss:0.21105888121184793\n",
      "train loss:0.3434779186584486\n",
      "train loss:0.12112755095912933\n",
      "train loss:0.18556249588986617\n",
      "train loss:0.2470198767268786\n",
      "train loss:0.12413059364363634\n",
      "train loss:0.17889160070583132\n",
      "train loss:0.219556918999029\n",
      "train loss:0.20654900665926842\n",
      "train loss:0.1951880223623407\n",
      "train loss:0.15558598818721342\n",
      "train loss:0.3334183091161136\n",
      "train loss:0.11619130357363629\n",
      "train loss:0.3893470179920771\n",
      "train loss:0.13104659472418861\n",
      "train loss:0.2320134185504814\n",
      "train loss:0.20020442214876646\n",
      "train loss:0.19140267743662112\n",
      "train loss:0.2300222751457628\n",
      "train loss:0.2823371122695152\n",
      "train loss:0.2074083499452719\n",
      "train loss:0.18853699862775677\n",
      "train loss:0.14250418506138343\n",
      "train loss:0.28583380062003877\n",
      "train loss:0.19221974947398363\n",
      "train loss:0.18337425570623261\n",
      "train loss:0.1872861773092232\n",
      "train loss:0.12947423748764117\n",
      "train loss:0.17187866411137878\n",
      "train loss:0.2015156157492538\n",
      "train loss:0.36356814084652905\n",
      "train loss:0.2571308996667268\n",
      "train loss:0.14614530362845587\n",
      "train loss:0.09921877674668055\n",
      "train loss:0.1835876692248361\n",
      "train loss:0.1442514548407205\n",
      "train loss:0.1992989821322904\n",
      "train loss:0.22135499713576473\n",
      "train loss:0.17438038083302485\n",
      "train loss:0.2451372151458048\n",
      "train loss:0.14384014650512833\n",
      "train loss:0.1693099729084757\n",
      "train loss:0.39381930221821376\n",
      "train loss:0.16541260722382523\n",
      "train loss:0.2776168567039067\n",
      "train loss:0.2433660386747124\n",
      "train loss:0.1801672915066589\n",
      "train loss:0.22854714581830682\n",
      "train loss:0.20470853492875513\n",
      "train loss:0.16863414739714996\n",
      "train loss:0.17517760190232134\n",
      "train loss:0.16520552005905353\n",
      "train loss:0.20940112351939175\n",
      "train loss:0.2379213401278796\n",
      "train loss:0.12841635258325573\n",
      "train loss:0.33618382196588636\n",
      "train loss:0.16630494034506316\n",
      "train loss:0.27908861800869506\n",
      "train loss:0.2119014970298712\n",
      "train loss:0.23180104959338013\n",
      "train loss:0.18280807995399045\n",
      "train loss:0.24970142509723559\n",
      "train loss:0.22325498771106922\n",
      "train loss:0.27813396934774454\n",
      "train loss:0.2702723313826751\n",
      "train loss:0.16942588953564042\n",
      "train loss:0.16760050257727252\n",
      "train loss:0.13137781370462195\n",
      "train loss:0.25742764421055964\n",
      "train loss:0.17308982386378838\n",
      "train loss:0.1965445540871636\n",
      "train loss:0.2809949601222185\n",
      "train loss:0.19801965407176284\n",
      "train loss:0.20349565663123698\n",
      "train loss:0.0989774288090464\n",
      "train loss:0.10806041142125396\n",
      "train loss:0.32650905173642003\n",
      "train loss:0.4117406338305159\n",
      "train loss:0.2887963000632151\n",
      "train loss:0.14439337876908817\n",
      "train loss:0.19323687372723747\n",
      "train loss:0.15554989035827732\n",
      "train loss:0.13208868661576842\n",
      "train loss:0.27077798402008535\n",
      "train loss:0.12458918917824485\n",
      "train loss:0.18422378348820406\n",
      "train loss:0.2204261705639449\n",
      "train loss:0.1480238444846384\n",
      "train loss:0.14306797866084836\n",
      "train loss:0.15504056916871073\n",
      "train loss:0.28122024952075936\n",
      "train loss:0.14094031247399366\n",
      "train loss:0.15082078319705228\n",
      "train loss:0.1217006419151174\n",
      "train loss:0.22353988662474486\n",
      "train loss:0.12484149476855645\n",
      "train loss:0.20950831317385316\n",
      "train loss:0.10524181381314947\n",
      "train loss:0.10280749250251536\n",
      "train loss:0.15911372029289914\n",
      "train loss:0.23860144032310238\n",
      "train loss:0.2704514041317896\n",
      "train loss:0.2992133964849998\n",
      "train loss:0.22395248918182278\n",
      "train loss:0.14417255943836668\n",
      "train loss:0.16519260408668715\n",
      "train loss:0.1322305929770552\n",
      "train loss:0.21319366869490605\n",
      "train loss:0.22321716154415325\n",
      "train loss:0.1252726828918598\n",
      "train loss:0.1471591128194184\n",
      "train loss:0.1347173852891002\n",
      "train loss:0.23008746823007062\n",
      "train loss:0.18922828638057765\n",
      "train loss:0.095039088714928\n",
      "train loss:0.19733651851439302\n",
      "train loss:0.10456846527826562\n",
      "train loss:0.168286947263106\n",
      "train loss:0.2086151146093729\n",
      "train loss:0.2791401403522969\n",
      "train loss:0.08153551764648427\n",
      "train loss:0.15266482910213286\n",
      "train loss:0.2356439455423851\n",
      "train loss:0.18235875595619588\n",
      "train loss:0.06662126679539322\n",
      "train loss:0.16951133096077606\n",
      "train loss:0.16348342475871647\n",
      "train loss:0.1426077617804594\n",
      "train loss:0.14407009344262672\n",
      "train loss:0.14264322651573655\n",
      "train loss:0.14279954754359678\n",
      "train loss:0.1472411801539616\n",
      "train loss:0.22010172158437544\n",
      "train loss:0.2268703285213138\n",
      "train loss:0.09414796518339871\n",
      "train loss:0.14406536403910575\n",
      "train loss:0.2684814480556673\n",
      "train loss:0.16689687322036587\n",
      "train loss:0.30665491532090855\n",
      "train loss:0.11265319753027443\n",
      "train loss:0.07969905202149496\n",
      "train loss:0.1259526694305343\n",
      "train loss:0.11898485336322655\n",
      "train loss:0.13415277236515308\n",
      "train loss:0.11406094322900656\n",
      "train loss:0.08566691487908862\n",
      "train loss:0.08613827204604256\n",
      "train loss:0.2479604677791096\n",
      "train loss:0.15539074570994385\n",
      "train loss:0.13554530138489593\n",
      "train loss:0.13057120742661\n",
      "train loss:0.13415437895424762\n",
      "train loss:0.151152783910012\n",
      "train loss:0.19977394827185727\n",
      "train loss:0.2570892252005914\n",
      "train loss:0.09240787745323022\n",
      "train loss:0.13804505840113507\n",
      "train loss:0.208222797359749\n",
      "train loss:0.1765808613573486\n",
      "train loss:0.2088892611717562\n",
      "train loss:0.19056446699823376\n",
      "train loss:0.13027094844458958\n",
      "train loss:0.08184139321700623\n",
      "train loss:0.08096103107975088\n",
      "train loss:0.14112633792910406\n",
      "train loss:0.1852774705488391\n",
      "train loss:0.1778278419193981\n",
      "train loss:0.19432794007982412\n",
      "train loss:0.15343241930548027\n",
      "train loss:0.15221461457362656\n",
      "train loss:0.32275629679417983\n",
      "train loss:0.15642620046395803\n",
      "train loss:0.1350962637781077\n",
      "train loss:0.15895373059663953\n",
      "train loss:0.14989033395056983\n",
      "train loss:0.18053019523299427\n",
      "train loss:0.08620776787504844\n",
      "train loss:0.06828896105780377\n",
      "train loss:0.09713838333191145\n",
      "train loss:0.09708892814896336\n",
      "train loss:0.16340716894945215\n",
      "train loss:0.06926066162260697\n",
      "train loss:0.10932403003748474\n",
      "train loss:0.19964139257251762\n",
      "train loss:0.17463899428312005\n",
      "train loss:0.12290689623400661\n",
      "train loss:0.13485395292607555\n",
      "train loss:0.22305720390915376\n",
      "train loss:0.12869904521153702\n",
      "train loss:0.09443519266702437\n",
      "train loss:0.09904155056787176\n",
      "train loss:0.13002052814898482\n",
      "train loss:0.15355184416614576\n",
      "train loss:0.17730116395162787\n",
      "train loss:0.14830771618528035\n",
      "train loss:0.1643523135523283\n",
      "train loss:0.11049277338765132\n",
      "train loss:0.10616992098128826\n",
      "train loss:0.21791311858343512\n",
      "train loss:0.1476827236558112\n",
      "train loss:0.11106336149839649\n",
      "train loss:0.08904780015895783\n",
      "train loss:0.11666612724577816\n",
      "train loss:0.11615507060749473\n",
      "train loss:0.31203188663827935\n",
      "train loss:0.11527422267017202\n",
      "train loss:0.12861701860367258\n",
      "train loss:0.1712998990873783\n",
      "train loss:0.11268799324892463\n",
      "train loss:0.07966212333596345\n",
      "train loss:0.174553222365986\n",
      "train loss:0.14630793496429959\n",
      "train loss:0.11876616103832982\n",
      "train loss:0.1885736054500434\n",
      "train loss:0.2306543491594054\n",
      "train loss:0.27001909818170733\n",
      "train loss:0.14469267686032755\n",
      "train loss:0.08489127216867129\n",
      "train loss:0.16314713332668412\n",
      "train loss:0.1828418893752058\n",
      "train loss:0.09963927369088632\n",
      "train loss:0.09363444386978155\n",
      "train loss:0.08584598596742293\n",
      "train loss:0.06948446260381332\n",
      "train loss:0.08695429269272723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.26005343803578135\n",
      "train loss:0.22778466278308968\n",
      "train loss:0.1779623562671724\n",
      "train loss:0.20420175161617574\n",
      "train loss:0.1491695129363074\n",
      "train loss:0.2547354228511863\n",
      "train loss:0.11785908038951609\n",
      "train loss:0.10638069892472689\n",
      "train loss:0.13278636639399036\n",
      "train loss:0.08810705140251616\n",
      "train loss:0.05033584775220915\n",
      "train loss:0.08208554975586095\n",
      "train loss:0.17801038193841684\n",
      "train loss:0.14069061964213725\n",
      "train loss:0.09512521861355668\n",
      "train loss:0.14087062076266413\n",
      "train loss:0.14350368878492487\n",
      "train loss:0.17387256870230153\n",
      "train loss:0.12343026473022142\n",
      "train loss:0.1251315722647959\n",
      "train loss:0.09283702281337254\n",
      "train loss:0.1152312288063977\n",
      "train loss:0.127099661925094\n",
      "train loss:0.21879391509671456\n",
      "train loss:0.058527245276980694\n",
      "train loss:0.12558390806374753\n",
      "train loss:0.18249421751360922\n",
      "train loss:0.2332199036051571\n",
      "train loss:0.07058142705359019\n",
      "train loss:0.19558738355523225\n",
      "train loss:0.09097312174782561\n",
      "train loss:0.14090523142553116\n",
      "train loss:0.15836498596811438\n",
      "train loss:0.1408406335795754\n",
      "train loss:0.0904561144221148\n",
      "train loss:0.27285732470906604\n",
      "train loss:0.13114582509840422\n",
      "train loss:0.16125502279875498\n",
      "train loss:0.15600986420443422\n",
      "train loss:0.13520825669685363\n",
      "train loss:0.12394640512597224\n",
      "train loss:0.11372072145401604\n",
      "train loss:0.07348731491415422\n",
      "train loss:0.1478711980932065\n",
      "train loss:0.1737749482310341\n",
      "train loss:0.06242960817122122\n",
      "train loss:0.12074810837399655\n",
      "train loss:0.16487914481413518\n",
      "train loss:0.11292191416183613\n",
      "train loss:0.08908639019681502\n",
      "train loss:0.15238779780293352\n",
      "train loss:0.08786316991037538\n",
      "train loss:0.10108176660043738\n",
      "train loss:0.12138102035514234\n",
      "train loss:0.10544748637855218\n",
      "train loss:0.0843895588553447\n",
      "train loss:0.16066915335187792\n",
      "train loss:0.13104654093262733\n",
      "train loss:0.17745419368288412\n",
      "train loss:0.08744598314626789\n",
      "train loss:0.13342560988762334\n",
      "train loss:0.2075204758300805\n",
      "train loss:0.10968718413735871\n",
      "=== epoch:2, train acc:0.959, test acc:0.959 ===\n",
      "train loss:0.03138170100777416\n",
      "train loss:0.24221747065608315\n",
      "train loss:0.087677992727281\n",
      "train loss:0.035017764726033546\n",
      "train loss:0.09010738354044029\n",
      "train loss:0.13547168147928126\n",
      "train loss:0.15043281404777054\n",
      "train loss:0.21010041858022926\n",
      "train loss:0.03587520893933436\n",
      "train loss:0.17469309772362163\n",
      "train loss:0.18181709485817737\n",
      "train loss:0.10891290402518884\n",
      "train loss:0.10669342135828024\n",
      "train loss:0.14287246456569766\n",
      "train loss:0.1406453077595384\n",
      "train loss:0.15460748057986964\n",
      "train loss:0.0685031731760201\n",
      "train loss:0.0738684367515457\n",
      "train loss:0.04245539782452184\n",
      "train loss:0.13961843973256344\n",
      "train loss:0.15065150589966067\n",
      "train loss:0.14661699506646303\n",
      "train loss:0.15999881393200682\n",
      "train loss:0.25989936593023943\n",
      "train loss:0.1831672408890389\n",
      "train loss:0.07059049754170274\n",
      "train loss:0.08663328117066747\n",
      "train loss:0.1366794037042052\n",
      "train loss:0.1598336015038616\n",
      "train loss:0.1489200629769828\n",
      "train loss:0.10191257148058147\n",
      "train loss:0.12572543715787024\n",
      "train loss:0.10075674543882682\n",
      "train loss:0.07860737959513285\n",
      "train loss:0.11931964587157969\n",
      "train loss:0.10983594247030636\n",
      "train loss:0.0808203607426077\n",
      "train loss:0.12393080326463787\n",
      "train loss:0.1040054898868096\n",
      "train loss:0.2007190755948523\n",
      "train loss:0.14466442866478516\n",
      "train loss:0.15109657730976486\n",
      "train loss:0.13022581853088794\n",
      "train loss:0.10455659734119768\n",
      "train loss:0.06898373565732166\n",
      "train loss:0.23350683990812093\n",
      "train loss:0.0984205491693491\n",
      "train loss:0.07826508571987933\n",
      "train loss:0.14116841579598402\n",
      "train loss:0.05370895098395399\n",
      "train loss:0.07670540197491221\n",
      "train loss:0.10050953899961308\n",
      "train loss:0.2863060008355647\n",
      "train loss:0.1133190428523886\n",
      "train loss:0.1167779501962989\n",
      "train loss:0.1069977565194789\n",
      "train loss:0.15827056145044577\n",
      "train loss:0.17093432886037654\n",
      "train loss:0.17520216750529571\n",
      "train loss:0.07682270613546664\n",
      "train loss:0.10353198184404976\n",
      "train loss:0.08120666696259131\n",
      "train loss:0.08918551361950078\n",
      "train loss:0.1160853199796828\n",
      "train loss:0.18038474429651985\n",
      "train loss:0.1549361541890501\n",
      "train loss:0.14007922159474584\n",
      "train loss:0.1350494629140922\n",
      "train loss:0.12131476813105647\n",
      "train loss:0.15984292552635826\n",
      "train loss:0.0892964137883681\n",
      "train loss:0.17648213057141304\n",
      "train loss:0.03721787131258975\n",
      "train loss:0.09738373941769961\n",
      "train loss:0.09604347953871777\n",
      "train loss:0.1149673767766164\n",
      "train loss:0.11265532964037937\n",
      "train loss:0.21138696958347197\n",
      "train loss:0.17845953414320762\n",
      "train loss:0.15048800550887212\n",
      "train loss:0.10134606059395582\n",
      "train loss:0.10227989425186684\n",
      "train loss:0.17147823960152192\n",
      "train loss:0.18900174629802102\n",
      "train loss:0.05471790566162925\n",
      "train loss:0.19703960029794312\n",
      "train loss:0.08610712542194154\n",
      "train loss:0.09767702428499449\n",
      "train loss:0.0647608097066521\n",
      "train loss:0.07551921287994087\n",
      "train loss:0.0711648226386843\n",
      "train loss:0.08222024848320916\n",
      "train loss:0.08310973043886698\n",
      "train loss:0.04449508791300629\n",
      "train loss:0.0670383855278594\n",
      "train loss:0.10703374081359696\n",
      "train loss:0.0519752356705932\n",
      "train loss:0.09566610829023103\n",
      "train loss:0.16960693108605937\n",
      "train loss:0.08076350513258658\n",
      "train loss:0.1861489436579911\n",
      "train loss:0.09545054700484627\n",
      "train loss:0.13911362486668744\n",
      "train loss:0.10803654929170524\n",
      "train loss:0.15514364555280719\n",
      "train loss:0.1608663543968763\n",
      "train loss:0.1683701819743231\n",
      "train loss:0.14316095094307676\n",
      "train loss:0.1575351290349517\n",
      "train loss:0.04585467477683622\n",
      "train loss:0.07389520634733429\n",
      "train loss:0.18098118397437266\n",
      "train loss:0.06319345322660606\n",
      "train loss:0.10552676887563477\n",
      "train loss:0.12906853916493938\n",
      "train loss:0.0802447159583946\n",
      "train loss:0.18787604247586112\n",
      "train loss:0.13198899702092454\n",
      "train loss:0.05832710572479344\n",
      "train loss:0.16258939121701618\n",
      "train loss:0.13923382099329384\n",
      "train loss:0.1720681280994241\n",
      "train loss:0.11178134775389399\n",
      "train loss:0.08933166885427182\n",
      "train loss:0.11792030591122055\n",
      "train loss:0.1357473239294716\n",
      "train loss:0.11720328732878775\n",
      "train loss:0.08119579928563217\n",
      "train loss:0.08207905733406448\n",
      "train loss:0.09922567129314039\n",
      "train loss:0.04289262541192823\n",
      "train loss:0.05036259163055683\n",
      "train loss:0.10864558900937661\n",
      "train loss:0.0961983334688072\n",
      "train loss:0.12015305883119036\n",
      "train loss:0.08233730662637795\n",
      "train loss:0.16986495900571477\n",
      "train loss:0.1382888790953335\n",
      "train loss:0.11132003435921498\n",
      "train loss:0.0961890558447907\n",
      "train loss:0.14015207701715007\n",
      "train loss:0.11089388719317951\n",
      "train loss:0.056609475717152934\n",
      "train loss:0.09347073524785345\n",
      "train loss:0.08591073582906135\n",
      "train loss:0.08359616961837825\n",
      "train loss:0.052275014844823726\n",
      "train loss:0.128830108978437\n",
      "train loss:0.14079096997076354\n",
      "train loss:0.09614401792813107\n",
      "train loss:0.061531710114322076\n",
      "train loss:0.08982508820681705\n",
      "train loss:0.29335436317667046\n",
      "train loss:0.07230051562189324\n",
      "train loss:0.05979982915843917\n",
      "train loss:0.08932370999198282\n",
      "train loss:0.09938817321331186\n",
      "train loss:0.1421731317771735\n",
      "train loss:0.06622004340124\n",
      "train loss:0.05330427472366561\n",
      "train loss:0.06833639642874235\n",
      "train loss:0.05062103910405695\n",
      "train loss:0.08248235054447928\n",
      "train loss:0.16063861485711212\n",
      "train loss:0.10917550691724945\n",
      "train loss:0.08237491249161832\n",
      "train loss:0.0914562727314767\n",
      "train loss:0.18196157137626354\n",
      "train loss:0.0673539201421406\n",
      "train loss:0.09426693153521055\n",
      "train loss:0.0897476283369387\n",
      "train loss:0.2071553341757159\n",
      "train loss:0.15130377058207428\n",
      "train loss:0.07334119809988919\n",
      "train loss:0.09077403052407185\n",
      "train loss:0.1354140918738805\n",
      "train loss:0.16329317758326126\n",
      "train loss:0.04005215412310136\n",
      "train loss:0.04938095807513905\n",
      "train loss:0.07254282467310313\n",
      "train loss:0.05258872204584072\n",
      "train loss:0.131089084458859\n",
      "train loss:0.034438710429285535\n",
      "train loss:0.10112058759352742\n",
      "train loss:0.13797077743456387\n",
      "train loss:0.13003859705702567\n",
      "train loss:0.07273274568565445\n",
      "train loss:0.09129015995865451\n",
      "train loss:0.13333643092437777\n",
      "train loss:0.09207978583494286\n",
      "train loss:0.09391249853981477\n",
      "train loss:0.0651334042251795\n",
      "train loss:0.030996315037702685\n",
      "train loss:0.07731113051899996\n",
      "train loss:0.10353480070257261\n",
      "train loss:0.09017374483895052\n",
      "train loss:0.09820046103689893\n",
      "train loss:0.11496089929164893\n",
      "train loss:0.10270508664401103\n",
      "train loss:0.1279533784811627\n",
      "train loss:0.07559830809885779\n",
      "train loss:0.05632434965498164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0780871427614414\n",
      "train loss:0.1717873668770405\n",
      "train loss:0.05804914280178726\n",
      "train loss:0.11169297390605132\n",
      "train loss:0.08923500563921612\n",
      "train loss:0.13425260540112716\n",
      "train loss:0.15770000374104223\n",
      "train loss:0.07785801619044573\n",
      "train loss:0.10194161144164675\n",
      "train loss:0.07098300809424907\n",
      "train loss:0.03800165747170095\n",
      "train loss:0.1400624479723006\n",
      "train loss:0.3461621262040899\n",
      "train loss:0.09116396461148567\n",
      "train loss:0.167761032161172\n",
      "train loss:0.07159484503927929\n",
      "train loss:0.06769714511167395\n",
      "train loss:0.1762686599980824\n",
      "train loss:0.06163140048384801\n",
      "train loss:0.07784337347755813\n",
      "train loss:0.10731509721243189\n",
      "train loss:0.08794748432639626\n",
      "train loss:0.15013568319059442\n",
      "train loss:0.13054913373367039\n",
      "train loss:0.03270725275381548\n",
      "train loss:0.06054885652164766\n",
      "train loss:0.1112361265856507\n",
      "train loss:0.06962339803508258\n",
      "train loss:0.11355348747066335\n",
      "train loss:0.04445310976193692\n",
      "train loss:0.09756324684147062\n",
      "train loss:0.08597327015792708\n",
      "train loss:0.07342501170014956\n",
      "train loss:0.1783029934223886\n",
      "train loss:0.1093097723631179\n",
      "train loss:0.034374950441859904\n",
      "train loss:0.10171006415836831\n",
      "train loss:0.13167226296563111\n",
      "train loss:0.053151016590057394\n",
      "train loss:0.05310319272299826\n",
      "train loss:0.08402686344456388\n",
      "train loss:0.1112653071277688\n",
      "train loss:0.11411940312150605\n",
      "train loss:0.12047106042580008\n",
      "train loss:0.04463690765648934\n",
      "train loss:0.20356024036226736\n",
      "train loss:0.04522240776820457\n",
      "train loss:0.08581385092439714\n",
      "train loss:0.1667875149861054\n",
      "train loss:0.058786957149496416\n",
      "train loss:0.20008068387423555\n",
      "train loss:0.06667928994045635\n",
      "train loss:0.11945546295181632\n",
      "train loss:0.04473146219084416\n",
      "train loss:0.07585713063452747\n",
      "train loss:0.10037185441374419\n",
      "train loss:0.10517508911392792\n",
      "train loss:0.07599948987515906\n",
      "train loss:0.03243599877373226\n",
      "train loss:0.1480343396354212\n",
      "train loss:0.03574918869069446\n",
      "train loss:0.09124880057041805\n",
      "train loss:0.12031730325458763\n",
      "train loss:0.10514912164801965\n",
      "train loss:0.11256389090095141\n",
      "train loss:0.03368724252536714\n",
      "train loss:0.1347509984576179\n",
      "train loss:0.1265200424566414\n",
      "train loss:0.1181131946906794\n",
      "train loss:0.08725901420842776\n",
      "train loss:0.08286538324327898\n",
      "train loss:0.1383532616465799\n",
      "train loss:0.07292803120581995\n",
      "train loss:0.08920183603781044\n",
      "train loss:0.19187361391753935\n",
      "train loss:0.0665472017171752\n",
      "train loss:0.1054972973612525\n",
      "train loss:0.0827031784354916\n",
      "train loss:0.07554851886356026\n",
      "train loss:0.13858654426935277\n",
      "train loss:0.11355538828930536\n",
      "train loss:0.04703001590646307\n",
      "train loss:0.10360590831598093\n",
      "train loss:0.0604843744652183\n",
      "train loss:0.10671673328587905\n",
      "train loss:0.07435553709008358\n",
      "train loss:0.16343156381762217\n",
      "train loss:0.10998390005047325\n",
      "train loss:0.1263096099242029\n",
      "train loss:0.08765642674824287\n",
      "train loss:0.0417424493311129\n",
      "train loss:0.07863158154542461\n",
      "train loss:0.05844469993570206\n",
      "train loss:0.11733266688185949\n",
      "train loss:0.15545303987821857\n",
      "train loss:0.0683133810572314\n",
      "train loss:0.10192648621350141\n",
      "train loss:0.09158431251045998\n",
      "train loss:0.04482718162964497\n",
      "train loss:0.11854115725861203\n",
      "train loss:0.04691186091687013\n",
      "train loss:0.05096540344709811\n",
      "train loss:0.08938080725181603\n",
      "train loss:0.11117881286924172\n",
      "train loss:0.036546607841928716\n",
      "train loss:0.06936246293387328\n",
      "train loss:0.2167748380151351\n",
      "train loss:0.10585085168413794\n",
      "train loss:0.07202555618975297\n",
      "train loss:0.02600755671524535\n",
      "train loss:0.07158363793731891\n",
      "train loss:0.051313845611904406\n",
      "train loss:0.11686294051120655\n",
      "train loss:0.07674940620602788\n",
      "train loss:0.06363431929839908\n",
      "train loss:0.04176036663570905\n",
      "train loss:0.030336251245684655\n",
      "train loss:0.0342282501606939\n",
      "train loss:0.07626897876861173\n",
      "train loss:0.02779126652436889\n",
      "train loss:0.0477304850082822\n",
      "train loss:0.10781397870389194\n",
      "train loss:0.15990838970132534\n",
      "train loss:0.11218576664242398\n",
      "train loss:0.05734970764780802\n",
      "train loss:0.04510264315854631\n",
      "train loss:0.09421401361349617\n",
      "train loss:0.09143886803010033\n",
      "train loss:0.10877857293281246\n",
      "train loss:0.07789511325263784\n",
      "train loss:0.0867238902165945\n",
      "train loss:0.08513856603316067\n",
      "train loss:0.10435798753171646\n",
      "train loss:0.053691337174522895\n",
      "train loss:0.1400318686491975\n",
      "train loss:0.08442183381921865\n",
      "train loss:0.11510040304631008\n",
      "train loss:0.04340093450608093\n",
      "train loss:0.04441445381271222\n",
      "train loss:0.04456675623686243\n",
      "train loss:0.07754005140277245\n",
      "train loss:0.13220992923019753\n",
      "train loss:0.23652076026701543\n",
      "train loss:0.048973063708377236\n",
      "train loss:0.03414270872340661\n",
      "train loss:0.04172648089387551\n",
      "train loss:0.09056976960109915\n",
      "train loss:0.04644858861864418\n",
      "train loss:0.1159428972459395\n",
      "train loss:0.02279444176636947\n",
      "train loss:0.04250401927119451\n",
      "train loss:0.03117474337599438\n",
      "train loss:0.10665017602830629\n",
      "train loss:0.03373581620125218\n",
      "train loss:0.031701472491862635\n",
      "train loss:0.10322166961700528\n",
      "train loss:0.03344216458778174\n",
      "train loss:0.08398809155325461\n",
      "train loss:0.07840937518053373\n",
      "train loss:0.0866819907487442\n",
      "train loss:0.08046608996209915\n",
      "train loss:0.08504069639724504\n",
      "train loss:0.11029008523803946\n",
      "train loss:0.041020269397922686\n",
      "train loss:0.04439260584625643\n",
      "train loss:0.09582003180018106\n",
      "train loss:0.1337801797437522\n",
      "train loss:0.11057219916671084\n",
      "train loss:0.08840146054040898\n",
      "train loss:0.07299709458686236\n",
      "train loss:0.1558837509314963\n",
      "train loss:0.05673436601529867\n",
      "train loss:0.10773770521407715\n",
      "train loss:0.031980182898943214\n",
      "train loss:0.09859062506466941\n",
      "train loss:0.05848026464475014\n",
      "train loss:0.16524335229904158\n",
      "train loss:0.06311521230997282\n",
      "train loss:0.10697878296178269\n",
      "train loss:0.07281064805809428\n",
      "train loss:0.12558177077663854\n",
      "train loss:0.04418892279722227\n",
      "train loss:0.08320573356278403\n",
      "train loss:0.04250974346556637\n",
      "train loss:0.06605928221006958\n",
      "train loss:0.11099380321735997\n",
      "train loss:0.09355614897692936\n",
      "train loss:0.08088907068038419\n",
      "train loss:0.04085845408885624\n",
      "train loss:0.04638442977108826\n",
      "train loss:0.03659414174186042\n",
      "train loss:0.11250718903522701\n",
      "train loss:0.042849647591413714\n",
      "train loss:0.1335602525942276\n",
      "train loss:0.0573133517055559\n",
      "train loss:0.04758620155122661\n",
      "train loss:0.024297063742884935\n",
      "train loss:0.04625929286290581\n",
      "train loss:0.16014694716811972\n",
      "train loss:0.12140452384802287\n",
      "train loss:0.08137103717587908\n",
      "train loss:0.06659236005168923\n",
      "train loss:0.09993756755856766\n",
      "train loss:0.054056968066437075\n",
      "train loss:0.03740239543224445\n",
      "train loss:0.05401478071592849\n",
      "train loss:0.024230108870284327\n",
      "train loss:0.17739767299178064\n",
      "train loss:0.06585426449153348\n",
      "train loss:0.12889983772311076\n",
      "train loss:0.09574856876985142\n",
      "train loss:0.12844707605298616\n",
      "train loss:0.07131018459105186\n",
      "train loss:0.1486142662643201\n",
      "train loss:0.10621914591597795\n",
      "train loss:0.06887726678474246\n",
      "train loss:0.09470064596045205\n",
      "train loss:0.14782256953511114\n",
      "train loss:0.10285446571828212\n",
      "train loss:0.03342920546449355\n",
      "train loss:0.0463033533388825\n",
      "train loss:0.04890198372606633\n",
      "train loss:0.034501087994033\n",
      "train loss:0.03767347552522491\n",
      "train loss:0.05503098585702542\n",
      "train loss:0.06822145133278594\n",
      "train loss:0.1417235601031974\n",
      "train loss:0.06973531545755896\n",
      "train loss:0.02994245386761285\n",
      "train loss:0.08667971174132771\n",
      "train loss:0.04386925279817475\n",
      "train loss:0.021910803082600974\n",
      "train loss:0.041762297764920825\n",
      "train loss:0.05250635564159982\n",
      "train loss:0.1022072630070146\n",
      "train loss:0.07729008649170513\n",
      "train loss:0.19086455982308798\n",
      "train loss:0.07310179340356887\n",
      "train loss:0.046966654738753624\n",
      "train loss:0.1056435006886771\n",
      "train loss:0.07109602888740475\n",
      "train loss:0.07034283962681989\n",
      "train loss:0.0673271884863391\n",
      "train loss:0.014518011676149595\n",
      "train loss:0.16375659722006197\n",
      "train loss:0.041075105063782605\n",
      "train loss:0.03886840024032298\n",
      "train loss:0.053907172286405285\n",
      "train loss:0.05270230511392415\n",
      "train loss:0.02437119864846444\n",
      "train loss:0.08554946144952255\n",
      "train loss:0.019339547383266768\n",
      "train loss:0.05290122457722691\n",
      "train loss:0.11088816297695717\n",
      "train loss:0.07141313139418069\n",
      "train loss:0.059834355159308864\n",
      "train loss:0.07613535356882122\n",
      "train loss:0.08177817365331543\n",
      "train loss:0.16810827508090959\n",
      "train loss:0.08431772051634245\n",
      "train loss:0.05321852408392799\n",
      "train loss:0.034407023407126286\n",
      "train loss:0.06468762429207614\n",
      "train loss:0.042941116094536796\n",
      "train loss:0.19128191996904392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.09616397584551409\n",
      "train loss:0.02872019729307478\n",
      "train loss:0.18226201531148922\n",
      "train loss:0.05624828379230232\n",
      "train loss:0.14276888065233168\n",
      "train loss:0.0951005874691871\n",
      "train loss:0.09916740631587788\n",
      "train loss:0.03933248186068903\n",
      "train loss:0.070287756623908\n",
      "train loss:0.05903779297818212\n",
      "train loss:0.03803634097196289\n",
      "train loss:0.08565236236198563\n",
      "train loss:0.030410766969962068\n",
      "train loss:0.07610640762890426\n",
      "train loss:0.09121514331100343\n",
      "train loss:0.12362040032665661\n",
      "train loss:0.12110744372570931\n",
      "train loss:0.03362420493601092\n",
      "train loss:0.027175861237778112\n",
      "train loss:0.05985083869030612\n",
      "train loss:0.07364410360075538\n",
      "train loss:0.01438072166383376\n",
      "train loss:0.05992541443292351\n",
      "train loss:0.09871525358302179\n",
      "train loss:0.08021484709971849\n",
      "train loss:0.08722074868585387\n",
      "train loss:0.06502851912250641\n",
      "train loss:0.04394657729012375\n",
      "train loss:0.06500412673041986\n",
      "train loss:0.06553515263202149\n",
      "train loss:0.12061665271270168\n",
      "train loss:0.05061293422188802\n",
      "train loss:0.06845204799882558\n",
      "train loss:0.16625433228995978\n",
      "train loss:0.057231439032287765\n",
      "train loss:0.08263139701449156\n",
      "train loss:0.08899916728380827\n",
      "train loss:0.11752570975962354\n",
      "train loss:0.05371799630430012\n",
      "train loss:0.07187486222159836\n",
      "train loss:0.01276681100496638\n",
      "train loss:0.06191548639017709\n",
      "train loss:0.04339753706325337\n",
      "train loss:0.017779005144965648\n",
      "train loss:0.06282430242210191\n",
      "train loss:0.06950913315585858\n",
      "train loss:0.05901096043634595\n",
      "train loss:0.13627597500706387\n",
      "train loss:0.04178147550333783\n",
      "train loss:0.08766162878917964\n",
      "train loss:0.12133917637113462\n",
      "train loss:0.05245566749173098\n",
      "train loss:0.10107414425910694\n",
      "train loss:0.04424819307662152\n",
      "train loss:0.06249301353449877\n",
      "train loss:0.06089074073812148\n",
      "train loss:0.06390100258830295\n",
      "train loss:0.04861711790242528\n",
      "train loss:0.05593208472292661\n",
      "train loss:0.05273185012892633\n",
      "train loss:0.046053094414173774\n",
      "train loss:0.11107468126150791\n",
      "train loss:0.09537499804890956\n",
      "train loss:0.023313728839515865\n",
      "train loss:0.02583535600444327\n",
      "train loss:0.012204281701818425\n",
      "train loss:0.07872164946958554\n",
      "train loss:0.0631630977568456\n",
      "train loss:0.09061912991113934\n",
      "train loss:0.09446164073018495\n",
      "train loss:0.04194197394736951\n",
      "train loss:0.0962030904893438\n",
      "train loss:0.028144801018425366\n",
      "train loss:0.0671289329544611\n",
      "train loss:0.05523854250829892\n",
      "train loss:0.024827932072530902\n",
      "train loss:0.03042812796137298\n",
      "train loss:0.06253838802114979\n",
      "train loss:0.06252272786031991\n",
      "train loss:0.059195432035405296\n",
      "train loss:0.052089097185548765\n",
      "train loss:0.04694366858826548\n",
      "train loss:0.1058650615559962\n",
      "train loss:0.0881626088795764\n",
      "train loss:0.04997716094866014\n",
      "train loss:0.10317360525238929\n",
      "train loss:0.057371332271451525\n",
      "train loss:0.04063211759731134\n",
      "train loss:0.09175120723176015\n",
      "train loss:0.020556213119459675\n",
      "train loss:0.051903136289759635\n",
      "train loss:0.030439037604108345\n",
      "train loss:0.1413786505762722\n",
      "train loss:0.05830531473632718\n",
      "train loss:0.06496689736595569\n",
      "train loss:0.08337487183067567\n",
      "train loss:0.08350450045719386\n",
      "train loss:0.039390369153024477\n",
      "train loss:0.04807446900297771\n",
      "train loss:0.018735442197241766\n",
      "train loss:0.015333353890871553\n",
      "train loss:0.13405443761499172\n",
      "train loss:0.051196351954542155\n",
      "train loss:0.033926922178443425\n",
      "train loss:0.03313176988889054\n",
      "train loss:0.06743488712604226\n",
      "train loss:0.0505563542454074\n",
      "train loss:0.04329586254773617\n",
      "train loss:0.025989013263594294\n",
      "train loss:0.08225113974114617\n",
      "train loss:0.02438250946701162\n",
      "train loss:0.11634644713075656\n",
      "train loss:0.08090388126220774\n",
      "train loss:0.05661229338413744\n",
      "train loss:0.06296717784741947\n",
      "train loss:0.0481575048158157\n",
      "train loss:0.02566757451817864\n",
      "train loss:0.2615830302297573\n",
      "train loss:0.04516215490721352\n",
      "train loss:0.06523520022773162\n",
      "train loss:0.08250309827956283\n",
      "train loss:0.01647745066194317\n",
      "train loss:0.11923934823818398\n",
      "train loss:0.09213805413259368\n",
      "train loss:0.030029628637314783\n",
      "train loss:0.045847012675495104\n",
      "train loss:0.02368745495870076\n",
      "train loss:0.10131088391413703\n",
      "train loss:0.05297193621282574\n",
      "train loss:0.06671832023830877\n",
      "train loss:0.2037992249326365\n",
      "train loss:0.043178070734581055\n",
      "train loss:0.1264057328765709\n",
      "=== epoch:3, train acc:0.978, test acc:0.976 ===\n",
      "train loss:0.05046745497551764\n",
      "train loss:0.037424882690100365\n",
      "train loss:0.0526122901248245\n",
      "train loss:0.030737638703612714\n",
      "train loss:0.10033133410098367\n",
      "train loss:0.1302460004083084\n",
      "train loss:0.1344632973965415\n",
      "train loss:0.06039221501142764\n",
      "train loss:0.018061164693244997\n",
      "train loss:0.07958904251806724\n",
      "train loss:0.0609188778055569\n",
      "train loss:0.09701327162943929\n",
      "train loss:0.04414698552430278\n",
      "train loss:0.03850947627800626\n",
      "train loss:0.03713277379566423\n",
      "train loss:0.09034766299589933\n",
      "train loss:0.09550733223270239\n",
      "train loss:0.05898357310207415\n",
      "train loss:0.024873512708481572\n",
      "train loss:0.03281011178480357\n",
      "train loss:0.065976446588769\n",
      "train loss:0.06114450864316437\n",
      "train loss:0.06752216437165934\n",
      "train loss:0.062263924143293965\n",
      "train loss:0.09381875101207189\n",
      "train loss:0.1196371637676579\n",
      "train loss:0.06542293933595351\n",
      "train loss:0.11253575147345492\n",
      "train loss:0.071564475751906\n",
      "train loss:0.06385649342072518\n",
      "train loss:0.018798633576496818\n",
      "train loss:0.06250595224744968\n",
      "train loss:0.08731423388550887\n",
      "train loss:0.0757144580414503\n",
      "train loss:0.044593853711277755\n",
      "train loss:0.04025556416267053\n",
      "train loss:0.03618347409945723\n",
      "train loss:0.05044815004505246\n",
      "train loss:0.048412419655470426\n",
      "train loss:0.1261750359453403\n",
      "train loss:0.07194139576608304\n",
      "train loss:0.047501531800028786\n",
      "train loss:0.09641567228006716\n",
      "train loss:0.0874740985880495\n",
      "train loss:0.044186423783326774\n",
      "train loss:0.0560417064542201\n",
      "train loss:0.123595646544781\n",
      "train loss:0.02642190943162698\n",
      "train loss:0.07096826064296032\n",
      "train loss:0.02245148292181599\n",
      "train loss:0.06735552378948388\n",
      "train loss:0.055962754200657286\n",
      "train loss:0.04902494205502918\n",
      "train loss:0.0503643266291883\n",
      "train loss:0.049751955096331735\n",
      "train loss:0.026589488734196257\n",
      "train loss:0.050504093020495126\n",
      "train loss:0.16750278930458293\n",
      "train loss:0.03888001512573064\n",
      "train loss:0.023103506263480726\n",
      "train loss:0.03215065373187836\n",
      "train loss:0.08367105407069376\n",
      "train loss:0.026349887319995755\n",
      "train loss:0.0311817568063285\n",
      "train loss:0.030298643813689692\n",
      "train loss:0.04812253473723323\n",
      "train loss:0.0703568401346382\n",
      "train loss:0.08795808514314027\n",
      "train loss:0.026039937260585747\n",
      "train loss:0.04522269710848163\n",
      "train loss:0.06464989459762763\n",
      "train loss:0.0613688478191883\n",
      "train loss:0.026892780987420685\n",
      "train loss:0.010928264035896647\n",
      "train loss:0.039290531512250405\n",
      "train loss:0.13451126451853668\n",
      "train loss:0.049910544243266707\n",
      "train loss:0.04001188217674408\n",
      "train loss:0.01791262104095216\n",
      "train loss:0.02297287385439527\n",
      "train loss:0.10898761647976171\n",
      "train loss:0.042561728664716976\n",
      "train loss:0.065785875320596\n",
      "train loss:0.03121860468306419\n",
      "train loss:0.06746856128416424\n",
      "train loss:0.039148139817609444\n",
      "train loss:0.03407730626266445\n",
      "train loss:0.035145169179827476\n",
      "train loss:0.10616925600263336\n",
      "train loss:0.06198298038374531\n",
      "train loss:0.06258087891202409\n",
      "train loss:0.03997838373644573\n",
      "train loss:0.02125509526928572\n",
      "train loss:0.06406055444364105\n",
      "train loss:0.062345876140334024\n",
      "train loss:0.024311930620159145\n",
      "train loss:0.04245813384183548\n",
      "train loss:0.050432282933790165\n",
      "train loss:0.06264150940833943\n",
      "train loss:0.009478357570132885\n",
      "train loss:0.08001800320763613\n",
      "train loss:0.05132434929272067\n",
      "train loss:0.036824568698123415\n",
      "train loss:0.18638800126000657\n",
      "train loss:0.0702715122212633\n",
      "train loss:0.06847997845593604\n",
      "train loss:0.09613842612546428\n",
      "train loss:0.05607004638003299\n",
      "train loss:0.10603021872821097\n",
      "train loss:0.038336870370508286\n",
      "train loss:0.023483524667839803\n",
      "train loss:0.05293182309403094\n",
      "train loss:0.05078918568342065\n",
      "train loss:0.02290499483256565\n",
      "train loss:0.05743535114514356\n",
      "train loss:0.03740597378896155\n",
      "train loss:0.10987106143182108\n",
      "train loss:0.01916397401405478\n",
      "train loss:0.0223903441105006\n",
      "train loss:0.01351128734625972\n",
      "train loss:0.08620302511020367\n",
      "train loss:0.02989351830346475\n",
      "train loss:0.09260804441146718\n",
      "train loss:0.08521852439309702\n",
      "train loss:0.056479221361904974\n",
      "train loss:0.044466937965252716\n",
      "train loss:0.05096252525700382\n",
      "train loss:0.08194081272142867\n",
      "train loss:0.09545979845206802\n",
      "train loss:0.014121809665863665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.042105656309848485\n",
      "train loss:0.04316780476122381\n",
      "train loss:0.045361277653150234\n",
      "train loss:0.02423654881586051\n",
      "train loss:0.11228956656318022\n",
      "train loss:0.13409470348963554\n",
      "train loss:0.046786903723509576\n",
      "train loss:0.04822147205791945\n",
      "train loss:0.10831788866314147\n",
      "train loss:0.040342116664131594\n",
      "train loss:0.016421519539137987\n",
      "train loss:0.10811754672656418\n",
      "train loss:0.05564469791951963\n",
      "train loss:0.06700450719099307\n",
      "train loss:0.10921256931798506\n",
      "train loss:0.06844925880709223\n",
      "train loss:0.02458819993422128\n",
      "train loss:0.045119593584598834\n",
      "train loss:0.01297678852866742\n",
      "train loss:0.04673248069654619\n",
      "train loss:0.0342494040109069\n",
      "train loss:0.016106120443596782\n",
      "train loss:0.05729915080468163\n",
      "train loss:0.12412760000491145\n",
      "train loss:0.04835078510193538\n",
      "train loss:0.05616909331830704\n",
      "train loss:0.017511651320622965\n",
      "train loss:0.06218934291702518\n",
      "train loss:0.032046161524699454\n",
      "train loss:0.09299756056993345\n",
      "train loss:0.024503860523624157\n",
      "train loss:0.07116766221641817\n",
      "train loss:0.04182210915016973\n",
      "train loss:0.04959378446287526\n",
      "train loss:0.06286250999633669\n",
      "train loss:0.11911321690760081\n",
      "train loss:0.08741231000711601\n",
      "train loss:0.047537292133446506\n",
      "train loss:0.025774397779613007\n",
      "train loss:0.06346043392813856\n",
      "train loss:0.09565418693181808\n",
      "train loss:0.05029841996478769\n",
      "train loss:0.0327790386058985\n",
      "train loss:0.1039481618297515\n",
      "train loss:0.1084040184218873\n",
      "train loss:0.13797883794326382\n",
      "train loss:0.09776167732612845\n",
      "train loss:0.0345927404266642\n",
      "train loss:0.06724892519097496\n",
      "train loss:0.04207027471780278\n",
      "train loss:0.044299698373317334\n",
      "train loss:0.15056765596892654\n",
      "train loss:0.04031639142626877\n",
      "train loss:0.05788768199077955\n",
      "train loss:0.06898618532949788\n",
      "train loss:0.06252451151591092\n",
      "train loss:0.07652643425343798\n",
      "train loss:0.05459191684487026\n",
      "train loss:0.023707215391943162\n",
      "train loss:0.04464720275612646\n",
      "train loss:0.0791392921446864\n",
      "train loss:0.03544124248362927\n",
      "train loss:0.022999290382217888\n",
      "train loss:0.03717301654800275\n",
      "train loss:0.07971371219067105\n",
      "train loss:0.04073530689052408\n",
      "train loss:0.01421299980898544\n",
      "train loss:0.061381453748660046\n",
      "train loss:0.061881602884070304\n",
      "train loss:0.025076321273190025\n",
      "train loss:0.04882726517780269\n",
      "train loss:0.023113674342126803\n",
      "train loss:0.04129809955791404\n",
      "train loss:0.015833260555504144\n",
      "train loss:0.0518343685062674\n",
      "train loss:0.03368868558297593\n",
      "train loss:0.07978435472062569\n",
      "train loss:0.0495442030729391\n",
      "train loss:0.03440732481405856\n",
      "train loss:0.10718879016928973\n",
      "train loss:0.12181406263789922\n",
      "train loss:0.03371867705546483\n",
      "train loss:0.0326261011616914\n",
      "train loss:0.022671478562555997\n",
      "train loss:0.03411397498894401\n",
      "train loss:0.0505389006939905\n",
      "train loss:0.04528431849003774\n",
      "train loss:0.021952437293163915\n",
      "train loss:0.028953723504035453\n",
      "train loss:0.05427586053476248\n",
      "train loss:0.05524947025770437\n",
      "train loss:0.03378963732488593\n",
      "train loss:0.0613078182198494\n",
      "train loss:0.08405428300888791\n",
      "train loss:0.021232686980542138\n",
      "train loss:0.06918840848067961\n",
      "train loss:0.01747356092816028\n",
      "train loss:0.016970942967653696\n",
      "train loss:0.04233183424366653\n",
      "train loss:0.03245353558698894\n",
      "train loss:0.04101697789788172\n",
      "train loss:0.0401710512818676\n",
      "train loss:0.06276407039881318\n",
      "train loss:0.020572142567740696\n",
      "train loss:0.036071564985826574\n",
      "train loss:0.027449917142530766\n",
      "train loss:0.04542017077179579\n",
      "train loss:0.1178265922781629\n",
      "train loss:0.04070714331721772\n",
      "train loss:0.03846256989226088\n",
      "train loss:0.05187157922790247\n",
      "train loss:0.06542520680128719\n",
      "train loss:0.04147432618805147\n",
      "train loss:0.07544655660944871\n",
      "train loss:0.12099169030273421\n",
      "train loss:0.030660104272583123\n",
      "train loss:0.04179145890762739\n",
      "train loss:0.0454610640426044\n",
      "train loss:0.03030402027472458\n",
      "train loss:0.033226374517762475\n",
      "train loss:0.03441081380729425\n",
      "train loss:0.021239113988564363\n",
      "train loss:0.01944530046104377\n",
      "train loss:0.029076706338839842\n",
      "train loss:0.021376191300367556\n",
      "train loss:0.036770534914258614\n",
      "train loss:0.03219730237788585\n",
      "train loss:0.07152916062334637\n",
      "train loss:0.1092680667850434\n",
      "train loss:0.0613700430713544\n",
      "train loss:0.019321034158178377\n",
      "train loss:0.03553132802522911\n",
      "train loss:0.052675505869843244\n",
      "train loss:0.04613883304844821\n",
      "train loss:0.006765315125066728\n",
      "train loss:0.024959613466896367\n",
      "train loss:0.0334470554139131\n",
      "train loss:0.010714513971711978\n",
      "train loss:0.07802904489637291\n",
      "train loss:0.034195904698969215\n",
      "train loss:0.12698784760199416\n",
      "train loss:0.10504461873858859\n",
      "train loss:0.04336532844991368\n",
      "train loss:0.052227237121072766\n",
      "train loss:0.08750121380255507\n",
      "train loss:0.023108972368201353\n",
      "train loss:0.047542154758983025\n",
      "train loss:0.015484286140131684\n",
      "train loss:0.03344877682500378\n",
      "train loss:0.050179668779256066\n",
      "train loss:0.05204837197862869\n",
      "train loss:0.062117328219431556\n",
      "train loss:0.0639743016273266\n",
      "train loss:0.025029221948704668\n",
      "train loss:0.04798692208376268\n",
      "train loss:0.061733541096261\n",
      "train loss:0.026949431886201424\n",
      "train loss:0.0572684514204834\n",
      "train loss:0.0316781693331039\n",
      "train loss:0.06819732632991862\n",
      "train loss:0.059788870211985534\n",
      "train loss:0.08987992933392688\n",
      "train loss:0.020407027315773086\n",
      "train loss:0.011738783030084052\n",
      "train loss:0.08289931544914513\n",
      "train loss:0.07413668700008419\n",
      "train loss:0.050874164723100065\n",
      "train loss:0.07650173440644585\n",
      "train loss:0.09845713979777936\n",
      "train loss:0.04999145256448334\n",
      "train loss:0.04571765092416552\n",
      "train loss:0.04638470514953988\n",
      "train loss:0.044448429905462744\n",
      "train loss:0.061515852446060205\n",
      "train loss:0.048116728492278986\n",
      "train loss:0.022212559200900893\n",
      "train loss:0.12334339122874778\n",
      "train loss:0.033991800837435054\n",
      "train loss:0.041198950042306164\n",
      "train loss:0.07535958350185229\n",
      "train loss:0.08272011519385679\n",
      "train loss:0.02918707055731408\n",
      "train loss:0.0673857799556361\n",
      "train loss:0.16648660395581302\n",
      "train loss:0.01967381659113774\n",
      "train loss:0.015038392141948305\n",
      "train loss:0.060855378278115956\n",
      "train loss:0.009842225286399404\n",
      "train loss:0.09451426016615011\n",
      "train loss:0.02074807232831855\n",
      "train loss:0.09349766214401407\n",
      "train loss:0.05748996937244245\n",
      "train loss:0.07607643825971037\n",
      "train loss:0.05050193914303244\n",
      "train loss:0.1908353462039939\n",
      "train loss:0.0289486511493857\n",
      "train loss:0.06691894979908365\n",
      "train loss:0.03448792208532973\n",
      "train loss:0.022435726973638635\n",
      "train loss:0.04852404547887861\n",
      "train loss:0.1569501262102345\n",
      "train loss:0.031776772404226515\n",
      "train loss:0.10107369262026122\n",
      "train loss:0.02238874374345705\n",
      "train loss:0.08816718273511827\n",
      "train loss:0.2009380217658931\n",
      "train loss:0.03695281078840079\n",
      "train loss:0.04516227708221915\n",
      "train loss:0.11002792528042091\n",
      "train loss:0.02724943817840604\n",
      "train loss:0.05876488327449851\n",
      "train loss:0.04535833048302241\n",
      "train loss:0.10216302040720503\n",
      "train loss:0.02922513793130255\n",
      "train loss:0.03401772409383071\n",
      "train loss:0.23316943879351426\n",
      "train loss:0.0532553407097164\n",
      "train loss:0.03639951069004955\n",
      "train loss:0.06799943800148336\n",
      "train loss:0.04997041638820233\n",
      "train loss:0.038354094881973166\n",
      "train loss:0.010346132745469803\n",
      "train loss:0.055055802566124835\n",
      "train loss:0.05740600198788514\n",
      "train loss:0.0923706706655885\n",
      "train loss:0.04871957073450214\n",
      "train loss:0.025769628005625763\n",
      "train loss:0.05766587689420508\n",
      "train loss:0.10285461593703481\n",
      "train loss:0.10196005967341827\n",
      "train loss:0.017772317472339094\n",
      "train loss:0.03970370242104582\n",
      "train loss:0.0368239300114938\n",
      "train loss:0.0430960202597429\n",
      "train loss:0.010299532779344436\n",
      "train loss:0.06636658556050044\n",
      "train loss:0.022881882933626488\n",
      "train loss:0.07135677717941341\n",
      "train loss:0.040804949125537525\n",
      "train loss:0.059935649050944464\n",
      "train loss:0.0547446255427144\n",
      "train loss:0.04810098441339937\n",
      "train loss:0.06627663851109897\n",
      "train loss:0.09303619880468278\n",
      "train loss:0.05624154241564676\n",
      "train loss:0.04551833974572641\n",
      "train loss:0.09574519858225365\n",
      "train loss:0.01667486310050831\n",
      "train loss:0.036096175935160305\n",
      "train loss:0.014647673534451034\n",
      "train loss:0.007835079614374072\n",
      "train loss:0.04990150270811208\n",
      "train loss:0.024371784448354254\n",
      "train loss:0.02988620870838881\n",
      "train loss:0.06648278985412095\n",
      "train loss:0.051165779453538986\n",
      "train loss:0.05913732506290853\n",
      "train loss:0.10377653732425136\n",
      "train loss:0.05018920256013059\n",
      "train loss:0.015143824461639935\n",
      "train loss:0.12314002865267083\n",
      "train loss:0.0181180384074613\n",
      "train loss:0.0580726035636241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.025539322581010944\n",
      "train loss:0.03526472633068285\n",
      "train loss:0.06691968256362886\n",
      "train loss:0.006484206728179784\n",
      "train loss:0.10134642394636026\n",
      "train loss:0.05530719985036554\n",
      "train loss:0.06844563673626342\n",
      "train loss:0.04380544248249273\n",
      "train loss:0.03397887670952133\n",
      "train loss:0.07682073805903335\n",
      "train loss:0.05704085353750764\n",
      "train loss:0.08815242459443415\n",
      "train loss:0.029019107095547697\n",
      "train loss:0.12622447353943145\n",
      "train loss:0.03377259701893399\n",
      "train loss:0.06934767702508014\n",
      "train loss:0.0608917923968121\n",
      "train loss:0.026604184776346015\n",
      "train loss:0.044112541971246054\n",
      "train loss:0.06593128508275774\n",
      "train loss:0.0222635457228652\n",
      "train loss:0.06936847473657663\n",
      "train loss:0.06822822111390668\n",
      "train loss:0.022840804031988637\n",
      "train loss:0.02786570619112313\n",
      "train loss:0.09038056939140368\n",
      "train loss:0.03695760140651809\n",
      "train loss:0.06343314214837377\n",
      "train loss:0.026832262762739038\n",
      "train loss:0.047046358425639596\n",
      "train loss:0.018262765975979717\n",
      "train loss:0.056274176481887685\n",
      "train loss:0.06409079722778144\n",
      "train loss:0.09948863383566302\n",
      "train loss:0.026795301941267727\n",
      "train loss:0.1979740507870163\n",
      "train loss:0.06643196006663749\n",
      "train loss:0.06183964471903988\n",
      "train loss:0.016517791111075007\n",
      "train loss:0.07632638692286314\n",
      "train loss:0.023281727425307198\n",
      "train loss:0.1639815625859717\n",
      "train loss:0.035930304273898955\n",
      "train loss:0.03471906764772997\n",
      "train loss:0.04990097872677624\n",
      "train loss:0.017067767013007832\n",
      "train loss:0.019107304159474467\n",
      "train loss:0.03538921627855348\n",
      "train loss:0.07563361089897767\n",
      "train loss:0.05833515864796202\n",
      "train loss:0.052088232797898065\n",
      "train loss:0.03543094649003253\n",
      "train loss:0.13328522011362878\n",
      "train loss:0.06720017877245481\n",
      "train loss:0.05357240337462955\n",
      "train loss:0.09539603422058401\n",
      "train loss:0.05877825256729583\n",
      "train loss:0.024567373798029313\n",
      "train loss:0.04868816952301816\n",
      "train loss:0.03379536988913091\n",
      "train loss:0.030608098322890798\n",
      "train loss:0.019780566766749098\n",
      "train loss:0.08062701359762219\n",
      "train loss:0.04036883099624692\n",
      "train loss:0.03311041455283951\n",
      "train loss:0.028026037281758388\n",
      "train loss:0.03537276058057006\n",
      "train loss:0.06522064034545563\n",
      "train loss:0.11067649643404014\n",
      "train loss:0.04256875013833714\n",
      "train loss:0.01519705071718342\n",
      "train loss:0.12040133688007554\n",
      "train loss:0.030507405114373505\n",
      "train loss:0.040965796330918784\n",
      "train loss:0.0688764269263991\n",
      "train loss:0.06493653782476608\n",
      "train loss:0.025072496336285964\n",
      "train loss:0.09776230850221843\n",
      "train loss:0.07234891337240276\n",
      "train loss:0.06789697893639628\n",
      "train loss:0.02547881671115429\n",
      "train loss:0.05798027669355235\n",
      "train loss:0.01976755010331348\n",
      "train loss:0.05197092522205653\n",
      "train loss:0.10746989338175938\n",
      "train loss:0.032632562685834546\n",
      "train loss:0.016574194993625394\n",
      "train loss:0.051173195419426144\n",
      "train loss:0.020337605168942913\n",
      "train loss:0.07029747700843253\n",
      "train loss:0.042122898644436406\n",
      "train loss:0.04413626496426482\n",
      "train loss:0.014152734773783789\n",
      "train loss:0.04669140460381193\n",
      "train loss:0.09232154648307828\n",
      "train loss:0.08236427072005972\n",
      "train loss:0.054292010380923454\n",
      "train loss:0.03593015884928278\n",
      "train loss:0.04226924490796754\n",
      "train loss:0.01713474600966678\n",
      "train loss:0.019042714470827074\n",
      "train loss:0.0590718452911996\n",
      "train loss:0.06955987729338561\n",
      "train loss:0.04314044973770444\n",
      "train loss:0.11924046775648628\n",
      "train loss:0.07380684220691709\n",
      "train loss:0.01457707972713964\n",
      "train loss:0.03877535581314719\n",
      "train loss:0.05747934846125852\n",
      "train loss:0.02919979601363604\n",
      "train loss:0.021106406117151817\n",
      "train loss:0.035114208717488396\n",
      "train loss:0.08274365845995249\n",
      "train loss:0.05158487946978249\n",
      "train loss:0.020933978180708145\n",
      "train loss:0.02479609050092051\n",
      "train loss:0.052323575770611634\n",
      "train loss:0.03526701163166422\n",
      "train loss:0.02670588631473719\n",
      "train loss:0.04577680008651916\n",
      "train loss:0.05675831288513954\n",
      "train loss:0.028200082567650577\n",
      "train loss:0.049383947098681526\n",
      "train loss:0.08926378494831604\n",
      "train loss:0.07141513686876111\n",
      "train loss:0.05226218915734121\n",
      "train loss:0.06114998039070153\n",
      "train loss:0.0342772367598294\n",
      "train loss:0.06716282637070224\n",
      "train loss:0.03571503777625358\n",
      "train loss:0.01997656378128277\n",
      "train loss:0.009041107868712732\n",
      "train loss:0.09613445665475066\n",
      "train loss:0.06606760888470437\n",
      "train loss:0.012661448701806188\n",
      "train loss:0.022378478639322484\n",
      "train loss:0.016387801576800833\n",
      "train loss:0.04365309611656445\n",
      "train loss:0.03704890137847804\n",
      "train loss:0.024557624176603392\n",
      "train loss:0.017040774852861776\n",
      "train loss:0.0457289973981296\n",
      "train loss:0.044595071863466\n",
      "train loss:0.02273810105624125\n",
      "train loss:0.020646831058578154\n",
      "train loss:0.005364789714546194\n",
      "train loss:0.1167043493381021\n",
      "train loss:0.10889833887236776\n",
      "train loss:0.07316333928881154\n",
      "train loss:0.01668019841392363\n",
      "train loss:0.04957985827745914\n",
      "train loss:0.04505487687504654\n",
      "train loss:0.1480248010236005\n",
      "train loss:0.04313848441026816\n",
      "train loss:0.03891067391981378\n",
      "train loss:0.017207442382314145\n",
      "train loss:0.053120520093025404\n",
      "train loss:0.021807186203753562\n",
      "train loss:0.07107684952667669\n",
      "train loss:0.04184838988605519\n",
      "train loss:0.04182407073923968\n",
      "train loss:0.16452133445686484\n",
      "train loss:0.05837103869613793\n",
      "train loss:0.04255436850458076\n",
      "train loss:0.018700920217775484\n",
      "train loss:0.014460394833348218\n",
      "train loss:0.07363062837537226\n",
      "train loss:0.043197915998653934\n",
      "train loss:0.02993267663419693\n",
      "train loss:0.025420285570917796\n",
      "train loss:0.00816226351017806\n",
      "train loss:0.027498055823255072\n",
      "train loss:0.014522237627680217\n",
      "train loss:0.04976615263422313\n",
      "train loss:0.023891974489715532\n",
      "train loss:0.024337348532816643\n",
      "train loss:0.019131913772936122\n",
      "train loss:0.026822542568835823\n",
      "train loss:0.018742040685473818\n",
      "train loss:0.032826650285201216\n",
      "train loss:0.04246034052425631\n",
      "train loss:0.017839137343978694\n",
      "train loss:0.015428331976599563\n",
      "train loss:0.01882975288979638\n",
      "train loss:0.03868373042849335\n",
      "train loss:0.02191291979661648\n",
      "train loss:0.02729250008035493\n",
      "train loss:0.0701349637780552\n",
      "train loss:0.013907289029340747\n",
      "train loss:0.023347651386955288\n",
      "train loss:0.026921933625789974\n",
      "train loss:0.03949908551028887\n",
      "train loss:0.04130067342680581\n",
      "train loss:0.08081998204091008\n",
      "train loss:0.0605009795508815\n",
      "train loss:0.00900530228088947\n",
      "train loss:0.06862482471798521\n",
      "train loss:0.10848206133068224\n",
      "train loss:0.01498029941702879\n",
      "train loss:0.08116078791682713\n",
      "train loss:0.07319793773350843\n",
      "train loss:0.03750311922471485\n",
      "train loss:0.023729655659658747\n",
      "train loss:0.021189420308621143\n",
      "train loss:0.04175313239819564\n",
      "train loss:0.05004916976592007\n",
      "train loss:0.0354013598739747\n",
      "=== epoch:4, train acc:0.98, test acc:0.978 ===\n",
      "train loss:0.020244772989843486\n",
      "train loss:0.016050754703853972\n",
      "train loss:0.060471992934080815\n",
      "train loss:0.07856705590806494\n",
      "train loss:0.021696727760089782\n",
      "train loss:0.02957093723503328\n",
      "train loss:0.07849077814189226\n",
      "train loss:0.034538917807507216\n",
      "train loss:0.022130189553445007\n",
      "train loss:0.014468505652796226\n",
      "train loss:0.021357932499169275\n",
      "train loss:0.027437629803203013\n",
      "train loss:0.057987805662306234\n",
      "train loss:0.044619813020320656\n",
      "train loss:0.025094603425518825\n",
      "train loss:0.06647554861566529\n",
      "train loss:0.04965916651034301\n",
      "train loss:0.010266352899444\n",
      "train loss:0.011876066104455163\n",
      "train loss:0.17516030322952625\n",
      "train loss:0.013530540895069885\n",
      "train loss:0.022930068531926952\n",
      "train loss:0.040405390936118994\n",
      "train loss:0.20185377255075598\n",
      "train loss:0.013590190748679063\n",
      "train loss:0.025205929166977455\n",
      "train loss:0.03024543054296967\n",
      "train loss:0.07480820368159063\n",
      "train loss:0.03922125369423018\n",
      "train loss:0.04175749711864639\n",
      "train loss:0.049748439542266654\n",
      "train loss:0.09409051827401482\n",
      "train loss:0.018963824511396596\n",
      "train loss:0.03682637143092291\n",
      "train loss:0.028542961160290023\n",
      "train loss:0.011581654684386789\n",
      "train loss:0.07349258580089717\n",
      "train loss:0.05332201340354299\n",
      "train loss:0.02817032384456882\n",
      "train loss:0.09575931455375261\n",
      "train loss:0.05084388086734157\n",
      "train loss:0.043268041723203615\n",
      "train loss:0.03444509375124169\n",
      "train loss:0.07728676111926612\n",
      "train loss:0.054935419418010244\n",
      "train loss:0.03451061146819858\n",
      "train loss:0.034253276358482146\n",
      "train loss:0.034348347740932365\n",
      "train loss:0.04922466744588456\n",
      "train loss:0.054288912707150014\n",
      "train loss:0.037324896153421765\n",
      "train loss:0.03356977493966169\n",
      "train loss:0.018453211720131528\n",
      "train loss:0.09929341143269711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022778661336126483\n",
      "train loss:0.009826687202304707\n",
      "train loss:0.05877288413319308\n",
      "train loss:0.07057534448065012\n",
      "train loss:0.07051517305817956\n",
      "train loss:0.018128662467781928\n",
      "train loss:0.05191119434628754\n",
      "train loss:0.027906435409800073\n",
      "train loss:0.029841674001484724\n",
      "train loss:0.04455141667116232\n",
      "train loss:0.020481942307433883\n",
      "train loss:0.0540057524923311\n",
      "train loss:0.07605106573528352\n",
      "train loss:0.049468982749933596\n",
      "train loss:0.028005712963898657\n",
      "train loss:0.032222772680784564\n",
      "train loss:0.06971898217081847\n",
      "train loss:0.051066483912334586\n",
      "train loss:0.008076397866037777\n",
      "train loss:0.043577028770697905\n",
      "train loss:0.011571157334143812\n",
      "train loss:0.036918498692164334\n",
      "train loss:0.014997007015890552\n",
      "train loss:0.0381570966350381\n",
      "train loss:0.06322914233292228\n",
      "train loss:0.031247114522166247\n",
      "train loss:0.018277951218656233\n",
      "train loss:0.07528043395525567\n",
      "train loss:0.13380158457860622\n",
      "train loss:0.0443055037051806\n",
      "train loss:0.09014132334939541\n",
      "train loss:0.020416501477526577\n",
      "train loss:0.04014679392700564\n",
      "train loss:0.06707374578531577\n",
      "train loss:0.04000999016655716\n",
      "train loss:0.02978687304642187\n",
      "train loss:0.030957050099597424\n",
      "train loss:0.017275711460201702\n",
      "train loss:0.026778045322476508\n",
      "train loss:0.030106235253235733\n",
      "train loss:0.01971655884607807\n",
      "train loss:0.0744939120063936\n",
      "train loss:0.006932130533323752\n",
      "train loss:0.030055554405775564\n",
      "train loss:0.014972742973075007\n",
      "train loss:0.06007011961153966\n",
      "train loss:0.030245007793010367\n",
      "train loss:0.03293553202773766\n",
      "train loss:0.10976727046761141\n",
      "train loss:0.035690014119759694\n",
      "train loss:0.0243115512943801\n",
      "train loss:0.05140952982589999\n",
      "train loss:0.02499424082788533\n",
      "train loss:0.027791015203795993\n",
      "train loss:0.03564676070859066\n",
      "train loss:0.05273980373442269\n",
      "train loss:0.07735168895177505\n",
      "train loss:0.026177090181826297\n",
      "train loss:0.0061237214200601416\n",
      "train loss:0.03140946920395037\n",
      "train loss:0.14826894369413465\n",
      "train loss:0.011856758988024916\n",
      "train loss:0.05481352371133082\n",
      "train loss:0.04146638621007492\n",
      "train loss:0.03752341899328324\n",
      "train loss:0.039664127696084905\n",
      "train loss:0.01515885073457782\n",
      "train loss:0.021950810066012273\n",
      "train loss:0.035789864583991304\n",
      "train loss:0.05522021700719448\n",
      "train loss:0.012994808419738803\n",
      "train loss:0.012636426585176629\n",
      "train loss:0.027169544259631587\n",
      "train loss:0.06391093919053388\n",
      "train loss:0.055772213014987145\n",
      "train loss:0.044176043450101954\n",
      "train loss:0.015809906233777503\n",
      "train loss:0.04050082860168167\n",
      "train loss:0.030544349733401317\n",
      "train loss:0.05400628954619371\n",
      "train loss:0.03503841455483285\n",
      "train loss:0.06348689619068057\n",
      "train loss:0.0539263311189357\n",
      "train loss:0.05742330198315781\n",
      "train loss:0.032299735509514566\n",
      "train loss:0.041132865853963925\n",
      "train loss:0.06217307061945764\n",
      "train loss:0.04238759396802498\n",
      "train loss:0.08432143388024681\n",
      "train loss:0.009312356217026172\n",
      "train loss:0.032161203515539145\n",
      "train loss:0.07052839335419896\n",
      "train loss:0.028139216901406992\n",
      "train loss:0.03827282087666505\n",
      "train loss:0.03367148415999127\n",
      "train loss:0.026468686574174338\n",
      "train loss:0.008555648779344891\n",
      "train loss:0.03971310864445122\n",
      "train loss:0.019835849430672473\n",
      "train loss:0.0276469610699866\n",
      "train loss:0.009991808013567922\n",
      "train loss:0.03132413689140397\n",
      "train loss:0.016981809846895034\n",
      "train loss:0.026932981768753958\n",
      "train loss:0.041812013323771484\n",
      "train loss:0.042007358474515824\n",
      "train loss:0.015812101009086837\n",
      "train loss:0.08190289966336119\n",
      "train loss:0.08319846596811932\n",
      "train loss:0.03329756127568948\n",
      "train loss:0.03231761601383628\n",
      "train loss:0.051111962429158414\n",
      "train loss:0.03936641276095745\n",
      "train loss:0.03299125084841133\n",
      "train loss:0.061248800463042125\n",
      "train loss:0.030194232419728774\n",
      "train loss:0.0642696387897771\n",
      "train loss:0.04171863795380289\n",
      "train loss:0.12135984164615678\n",
      "train loss:0.07270667809566345\n",
      "train loss:0.04371147402679999\n",
      "train loss:0.02815486461937964\n",
      "train loss:0.0646826423243229\n",
      "train loss:0.02425827811172693\n",
      "train loss:0.04402235028413447\n",
      "train loss:0.07470229275327815\n",
      "train loss:0.019433483789222068\n",
      "train loss:0.03782183994058278\n",
      "train loss:0.016506990352841783\n",
      "train loss:0.014424433097097091\n",
      "train loss:0.09647994191446746\n",
      "train loss:0.0143671801596104\n",
      "train loss:0.005224745601667909\n",
      "train loss:0.009148098312110128\n",
      "train loss:0.022659772959992313\n",
      "train loss:0.03625507883842588\n",
      "train loss:0.02362989452942491\n",
      "train loss:0.04320275488594707\n",
      "train loss:0.04273424888617676\n",
      "train loss:0.13457683977163964\n",
      "train loss:0.021191101229839276\n",
      "train loss:0.10505295981656142\n",
      "train loss:0.09626545833083937\n",
      "train loss:0.020179292525902844\n",
      "train loss:0.029173603351716478\n",
      "train loss:0.04017743678825633\n",
      "train loss:0.03568132040590206\n",
      "train loss:0.014690086026412016\n",
      "train loss:0.03362660395615351\n",
      "train loss:0.07786665292968728\n",
      "train loss:0.01197058597382945\n",
      "train loss:0.04677639867596078\n",
      "train loss:0.04113060766392896\n",
      "train loss:0.031209244435551297\n",
      "train loss:0.03618843455289083\n",
      "train loss:0.06707426501584464\n",
      "train loss:0.17433310425252446\n",
      "train loss:0.11919499865661519\n",
      "train loss:0.03228138745801962\n",
      "train loss:0.03354423013937812\n",
      "train loss:0.05123997100487661\n",
      "train loss:0.07898156047225138\n",
      "train loss:0.02985801238823564\n",
      "train loss:0.03350635146059852\n",
      "train loss:0.09254985775536761\n",
      "train loss:0.04723879733779219\n",
      "train loss:0.11220090051819544\n",
      "train loss:0.006359602001809952\n",
      "train loss:0.0451906188193757\n",
      "train loss:0.07125500104474258\n",
      "train loss:0.03136965943447021\n",
      "train loss:0.01828299756302111\n",
      "train loss:0.01606253246375422\n",
      "train loss:0.08204193926485566\n",
      "train loss:0.028693344471495123\n",
      "train loss:0.019606441141694398\n",
      "train loss:0.03316238112444634\n",
      "train loss:0.01663509745224116\n",
      "train loss:0.005602347998016101\n",
      "train loss:0.06351823988553865\n",
      "train loss:0.023669424227932077\n",
      "train loss:0.04002691592711645\n",
      "train loss:0.032065342994953665\n",
      "train loss:0.057946997230586765\n",
      "train loss:0.08440258281395473\n",
      "train loss:0.03914125453769301\n",
      "train loss:0.021428982936013263\n",
      "train loss:0.04206204568814728\n",
      "train loss:0.021228711432504682\n",
      "train loss:0.06350540875623181\n",
      "train loss:0.0941683378846274\n",
      "train loss:0.029807165792345155\n",
      "train loss:0.007318123931436818\n",
      "train loss:0.01220734396352428\n",
      "train loss:0.04591940927659265\n",
      "train loss:0.060448397601009056\n",
      "train loss:0.029190104455469403\n",
      "train loss:0.02578078670986357\n",
      "train loss:0.028395456813844745\n",
      "train loss:0.05120862185199739\n",
      "train loss:0.027918010720187503\n",
      "train loss:0.10620197289267157\n",
      "train loss:0.03881190508235582\n",
      "train loss:0.04627355487739884\n",
      "train loss:0.0871900699778615\n",
      "train loss:0.015243258770522622\n",
      "train loss:0.021869452015926747\n",
      "train loss:0.007527017310346831\n",
      "train loss:0.08571694135689112\n",
      "train loss:0.03230645267522538\n",
      "train loss:0.03160054127401945\n",
      "train loss:0.012533015963918738\n",
      "train loss:0.024165380528276274\n",
      "train loss:0.018796928597660908\n",
      "train loss:0.010908085920594557\n",
      "train loss:0.06155519415267461\n",
      "train loss:0.019293511044678344\n",
      "train loss:0.013400581061504959\n",
      "train loss:0.008692770989605221\n",
      "train loss:0.029769648141475865\n",
      "train loss:0.05949123097724075\n",
      "train loss:0.026407075469818388\n",
      "train loss:0.02815706483312313\n",
      "train loss:0.04151281963274311\n",
      "train loss:0.011717711829386522\n",
      "train loss:0.019486579788726584\n",
      "train loss:0.034511585281467826\n",
      "train loss:0.023178582207522103\n",
      "train loss:0.05818616727158824\n",
      "train loss:0.019653581323823274\n",
      "train loss:0.033608688426399184\n",
      "train loss:0.10571899353460151\n",
      "train loss:0.016443188343412653\n",
      "train loss:0.005361619520020507\n",
      "train loss:0.043108974812916125\n",
      "train loss:0.019936737734332143\n",
      "train loss:0.019364685751991392\n",
      "train loss:0.017882852368544023\n",
      "train loss:0.04821000384978265\n",
      "train loss:0.014259016201985067\n",
      "train loss:0.021743652378823922\n",
      "train loss:0.11525640955876108\n",
      "train loss:0.027916374006581757\n",
      "train loss:0.03455161997383004\n",
      "train loss:0.05014628049030215\n",
      "train loss:0.0310656437553207\n",
      "train loss:0.010282625109986628\n",
      "train loss:0.09417505521440873\n",
      "train loss:0.0036865313973186275\n",
      "train loss:0.08516729462108605\n",
      "train loss:0.020092224660382237\n",
      "train loss:0.02831622536223758\n",
      "train loss:0.03910754837111952\n",
      "train loss:0.09764511160446906\n",
      "train loss:0.04273769431405344\n",
      "train loss:0.006017427634720261\n",
      "train loss:0.020950868680360245\n",
      "train loss:0.14162890999483055\n",
      "train loss:0.02504002213816657\n",
      "train loss:0.03204058985074313\n",
      "train loss:0.05473589243116218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.025421249939326204\n",
      "train loss:0.0777800988298998\n",
      "train loss:0.01672631556289845\n",
      "train loss:0.01675119268061035\n",
      "train loss:0.017622147455494393\n",
      "train loss:0.021576796152408654\n",
      "train loss:0.012905067638097102\n",
      "train loss:0.012614038147974705\n",
      "train loss:0.08153614724193568\n",
      "train loss:0.06129390450528174\n",
      "train loss:0.035766982045014745\n",
      "train loss:0.04648164525208246\n",
      "train loss:0.06735273873182708\n",
      "train loss:0.04848798955557035\n",
      "train loss:0.016107110008933716\n",
      "train loss:0.014516510241592222\n",
      "train loss:0.06678478489519096\n",
      "train loss:0.08409161939423716\n",
      "train loss:0.018415787730687038\n",
      "train loss:0.04038749679368063\n",
      "train loss:0.0362755723349558\n",
      "train loss:0.022736663926001998\n",
      "train loss:0.0659474499706451\n",
      "train loss:0.02990703698764048\n",
      "train loss:0.03659080308862889\n",
      "train loss:0.048550577889642996\n",
      "train loss:0.011370258195915042\n",
      "train loss:0.016483887016999994\n",
      "train loss:0.032047433605401056\n",
      "train loss:0.008154401773028296\n",
      "train loss:0.07298071462594095\n",
      "train loss:0.02667063397567377\n",
      "train loss:0.011610557067252829\n",
      "train loss:0.034520956224179854\n",
      "train loss:0.040244184928197084\n",
      "train loss:0.0729494739239068\n",
      "train loss:0.010329966603421305\n",
      "train loss:0.02085326121910049\n",
      "train loss:0.02516572903223237\n",
      "train loss:0.03486068885899182\n",
      "train loss:0.057709131069172484\n",
      "train loss:0.02157414494351599\n",
      "train loss:0.03820365169730176\n",
      "train loss:0.018485009271985698\n",
      "train loss:0.03110023235868341\n",
      "train loss:0.03063128137422877\n",
      "train loss:0.043374809647756536\n",
      "train loss:0.11350632112837301\n",
      "train loss:0.04412519759449083\n",
      "train loss:0.026747496257094286\n",
      "train loss:0.026044654140125977\n",
      "train loss:0.02427314088916252\n",
      "train loss:0.03511225076173905\n",
      "train loss:0.00939701046772811\n",
      "train loss:0.03425233267954205\n",
      "train loss:0.08292868613836811\n",
      "train loss:0.039242258104109355\n",
      "train loss:0.0157641593170841\n",
      "train loss:0.04080311324510458\n",
      "train loss:0.06474868781540577\n",
      "train loss:0.020779681616521665\n",
      "train loss:0.02755191899505414\n",
      "train loss:0.07236067307775676\n",
      "train loss:0.009390974559759508\n",
      "train loss:0.015325679675553048\n",
      "train loss:0.038559532716010404\n",
      "train loss:0.05813519878405796\n",
      "train loss:0.12598179753761263\n",
      "train loss:0.034016778781407256\n",
      "train loss:0.030047389763799198\n",
      "train loss:0.014134784109958798\n",
      "train loss:0.012928755239086749\n",
      "train loss:0.05010739578308015\n",
      "train loss:0.015239956361364701\n",
      "train loss:0.04791790236598636\n",
      "train loss:0.02889968763259999\n",
      "train loss:0.030640275394646484\n",
      "train loss:0.04425474815771664\n",
      "train loss:0.03452961414796071\n",
      "train loss:0.01612365024075534\n",
      "train loss:0.018833904999040037\n",
      "train loss:0.017644054646007167\n",
      "train loss:0.025196209170944527\n",
      "train loss:0.019418156116539867\n",
      "train loss:0.10748098182181932\n",
      "train loss:0.029867866610709445\n",
      "train loss:0.08324126603199579\n",
      "train loss:0.18932711221632834\n",
      "train loss:0.014083443108350161\n",
      "train loss:0.020093142279265466\n",
      "train loss:0.040498354400050424\n",
      "train loss:0.040748891748966176\n",
      "train loss:0.05172146349514865\n",
      "train loss:0.05797050562094697\n",
      "train loss:0.008660649993972157\n",
      "train loss:0.005171336990836883\n",
      "train loss:0.0321378477222418\n",
      "train loss:0.06170456231434609\n",
      "train loss:0.07881276279035594\n",
      "train loss:0.07504147327129913\n",
      "train loss:0.06058533103637289\n",
      "train loss:0.01891789220547338\n",
      "train loss:0.03163869901804874\n",
      "train loss:0.14276685326757535\n",
      "train loss:0.011437903732720942\n",
      "train loss:0.09332250091560958\n",
      "train loss:0.024080585422042226\n",
      "train loss:0.11995772519064715\n",
      "train loss:0.008493166081057778\n",
      "train loss:0.03315332143421384\n",
      "train loss:0.017887640360519284\n",
      "train loss:0.059934431761097855\n",
      "train loss:0.05574629313602518\n",
      "train loss:0.015941988057157505\n",
      "train loss:0.11755502991680043\n",
      "train loss:0.05639206095074086\n",
      "train loss:0.015282318340909005\n",
      "train loss:0.03761178683065075\n",
      "train loss:0.07023104331138107\n",
      "train loss:0.03151277660529651\n",
      "train loss:0.017181883941301032\n",
      "train loss:0.008917968726701243\n",
      "train loss:0.013569092878510875\n",
      "train loss:0.025898521014748436\n",
      "train loss:0.034453176406753945\n",
      "train loss:0.02692992107270461\n",
      "train loss:0.03496523698115365\n",
      "train loss:0.05093906376384913\n",
      "train loss:0.026093580679209864\n",
      "train loss:0.0437962216639899\n",
      "train loss:0.027475453481323374\n",
      "train loss:0.03509715044827222\n",
      "train loss:0.015538883835653978\n",
      "train loss:0.018309727865168872\n",
      "train loss:0.048215811687579484\n",
      "train loss:0.038064175695043875\n",
      "train loss:0.10084490368682063\n",
      "train loss:0.02104397573659824\n",
      "train loss:0.0908887159791339\n",
      "train loss:0.03381989043809719\n",
      "train loss:0.0290047457916813\n",
      "train loss:0.08325316333395989\n",
      "train loss:0.021586273251049445\n",
      "train loss:0.030083154579349528\n",
      "train loss:0.02825780332167914\n",
      "train loss:0.00410686907544865\n",
      "train loss:0.0297358059215373\n",
      "train loss:0.01054460039215211\n",
      "train loss:0.026488643075255048\n",
      "train loss:0.01527883666200225\n",
      "train loss:0.08076363445236442\n",
      "train loss:0.04085003736699818\n",
      "train loss:0.011265607722220248\n",
      "train loss:0.017545052273190385\n",
      "train loss:0.032408437096814756\n",
      "train loss:0.03713974811284069\n",
      "train loss:0.03856435462226021\n",
      "train loss:0.06916795901611074\n",
      "train loss:0.01216746972004606\n",
      "train loss:0.02931773309448271\n",
      "train loss:0.07274496919019319\n",
      "train loss:0.09049329853185153\n",
      "train loss:0.05941712287762819\n",
      "train loss:0.04744771020483292\n",
      "train loss:0.014709010196950813\n",
      "train loss:0.03821389251753886\n",
      "train loss:0.008228455032904487\n",
      "train loss:0.012257681999920273\n",
      "train loss:0.03933690732927346\n",
      "train loss:0.04205499688851377\n",
      "train loss:0.009588476629315801\n",
      "train loss:0.00824070865830816\n",
      "train loss:0.00963502907838926\n",
      "train loss:0.030714376200527055\n",
      "train loss:0.028854247206150135\n",
      "train loss:0.01763935636114006\n",
      "train loss:0.02163718610967255\n",
      "train loss:0.012191171589768426\n",
      "train loss:0.04652162883143103\n",
      "train loss:0.06553578690890843\n",
      "train loss:0.026014443720296054\n",
      "train loss:0.027538357076857017\n",
      "train loss:0.04780301139248335\n",
      "train loss:0.08731651812278785\n",
      "train loss:0.040315120862746356\n",
      "train loss:0.038445556876804815\n",
      "train loss:0.04637462579506752\n",
      "train loss:0.006597113955238288\n",
      "train loss:0.037278827744840995\n",
      "train loss:0.03487924677639529\n",
      "train loss:0.04344772421646338\n",
      "train loss:0.13013233145505432\n",
      "train loss:0.019119493426348593\n",
      "train loss:0.012215872746527358\n",
      "train loss:0.013560285924018806\n",
      "train loss:0.02044340718652144\n",
      "train loss:0.033072616767964996\n",
      "train loss:0.02423718616789846\n",
      "train loss:0.007785253003903664\n",
      "train loss:0.0685464849575669\n",
      "train loss:0.02995270721704354\n",
      "train loss:0.007023021885504078\n",
      "train loss:0.021734608218569974\n",
      "train loss:0.010732950396416809\n",
      "train loss:0.015356933755532216\n",
      "train loss:0.023717443967994058\n",
      "train loss:0.010879349594826514\n",
      "train loss:0.13667521374364738\n",
      "train loss:0.04829494489288808\n",
      "train loss:0.059159767360681084\n",
      "train loss:0.07761708331195649\n",
      "train loss:0.0717433595942675\n",
      "train loss:0.017113643786263122\n",
      "train loss:0.02906412459073552\n",
      "train loss:0.01719944535913463\n",
      "train loss:0.020622078027486442\n",
      "train loss:0.022957242077058806\n",
      "train loss:0.008443857459038091\n",
      "train loss:0.021597338844584143\n",
      "train loss:0.01635525968208381\n",
      "train loss:0.017031577776160017\n",
      "train loss:0.039454254580030476\n",
      "train loss:0.021654167838242554\n",
      "train loss:0.040939711091205984\n",
      "train loss:0.07346767691204403\n",
      "train loss:0.05531167490478075\n",
      "train loss:0.02882513201514933\n",
      "train loss:0.02469375780187707\n",
      "train loss:0.012361687111937518\n",
      "train loss:0.08692030975828949\n",
      "train loss:0.005985461563047869\n",
      "train loss:0.00571672178224116\n",
      "train loss:0.06518785135636333\n",
      "train loss:0.014997726236126257\n",
      "train loss:0.029234070385656334\n",
      "train loss:0.06660657296904338\n",
      "train loss:0.015158671833146942\n",
      "train loss:0.017826911064267967\n",
      "train loss:0.04168587340943734\n",
      "train loss:0.032319486708110155\n",
      "train loss:0.013908576709478346\n",
      "train loss:0.046058628505409184\n",
      "train loss:0.0074269545598351205\n",
      "train loss:0.03749634242079046\n",
      "train loss:0.017020246729846207\n",
      "train loss:0.041490242480749576\n",
      "train loss:0.06937479417918198\n",
      "train loss:0.034334670287089315\n",
      "train loss:0.034557814318495625\n",
      "train loss:0.012354033541956437\n",
      "train loss:0.016227703322653126\n",
      "train loss:0.008431049546375689\n",
      "train loss:0.02529472015274088\n",
      "train loss:0.015149198448088055\n",
      "train loss:0.007528585645327343\n",
      "train loss:0.03753205801492633\n",
      "train loss:0.021395250384540928\n",
      "train loss:0.020964209726553825\n",
      "train loss:0.01986158123917705\n",
      "train loss:0.01819067785978715\n",
      "train loss:0.0644232924456735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07848091701804343\n",
      "train loss:0.044782092602534726\n",
      "train loss:0.03254689145042136\n",
      "train loss:0.0068176045606861005\n",
      "train loss:0.028278725602370994\n",
      "train loss:0.007630920456563228\n",
      "train loss:0.053519011199801854\n",
      "train loss:0.020231644426948546\n",
      "train loss:0.06494861610569008\n",
      "train loss:0.04693985035496385\n",
      "train loss:0.01428240933880234\n",
      "train loss:0.014435153126858382\n",
      "train loss:0.054536492749154945\n",
      "train loss:0.0322712519517306\n",
      "train loss:0.026489650860934338\n",
      "train loss:0.03558102463639451\n",
      "train loss:0.030958888145897815\n",
      "train loss:0.013945561544951603\n",
      "train loss:0.008591437324475409\n",
      "train loss:0.017019218249882406\n",
      "train loss:0.018098859493413604\n",
      "train loss:0.011822197491232806\n",
      "train loss:0.06964539678730915\n",
      "train loss:0.04941329626675098\n",
      "=== epoch:5, train acc:0.985, test acc:0.979 ===\n",
      "train loss:0.018287233806075807\n",
      "train loss:0.05177401641264977\n",
      "train loss:0.01921475349777924\n",
      "train loss:0.03131962037634606\n",
      "train loss:0.03577573483005353\n",
      "train loss:0.018940133746686762\n",
      "train loss:0.012057702780535957\n",
      "train loss:0.01585141997039393\n",
      "train loss:0.0239984943525192\n",
      "train loss:0.02911186774371119\n",
      "train loss:0.013370303916709316\n",
      "train loss:0.018684639451011967\n",
      "train loss:0.06075215599574859\n",
      "train loss:0.035591791164886734\n",
      "train loss:0.006987919693784468\n",
      "train loss:0.03012522010043261\n",
      "train loss:0.07300387577713523\n",
      "train loss:0.030642135748697535\n",
      "train loss:0.004803860950851757\n",
      "train loss:0.03767537743777959\n",
      "train loss:0.07154912498134734\n",
      "train loss:0.036248547225328165\n",
      "train loss:0.03211417826407599\n",
      "train loss:0.025542572027067063\n",
      "train loss:0.0034611320010289807\n",
      "train loss:0.01470262693825456\n",
      "train loss:0.022223522889200393\n",
      "train loss:0.009956877453983977\n",
      "train loss:0.023833964206200306\n",
      "train loss:0.010391416727709664\n",
      "train loss:0.051451847409047645\n",
      "train loss:0.07419634120862847\n",
      "train loss:0.02216392336747181\n",
      "train loss:0.06528182869500236\n",
      "train loss:0.11857524747261863\n",
      "train loss:0.05392186652888701\n",
      "train loss:0.010617684135506164\n",
      "train loss:0.01969126718725057\n",
      "train loss:0.04731861372479238\n",
      "train loss:0.0399143954031256\n",
      "train loss:0.02574873592206207\n",
      "train loss:0.021206181096286487\n",
      "train loss:0.006662030746570374\n",
      "train loss:0.008962375549747435\n",
      "train loss:0.030191656106380034\n",
      "train loss:0.06955000448130917\n",
      "train loss:0.04242483529381093\n",
      "train loss:0.005290721493196745\n",
      "train loss:0.016088997023336115\n",
      "train loss:0.009967983167432602\n",
      "train loss:0.01574635115687695\n",
      "train loss:0.008808642700847193\n",
      "train loss:0.013471885023200774\n",
      "train loss:0.014272254495400783\n",
      "train loss:0.008875462535108883\n",
      "train loss:0.030512264264181414\n",
      "train loss:0.03409615859032406\n",
      "train loss:0.056358540904110764\n",
      "train loss:0.03314165457806282\n",
      "train loss:0.024162913198465762\n",
      "train loss:0.053423110086926656\n",
      "train loss:0.04672609200286168\n",
      "train loss:0.030460588117974533\n",
      "train loss:0.007888006707624417\n",
      "train loss:0.02709591687474982\n",
      "train loss:0.020673780558792133\n",
      "train loss:0.04978898187461044\n",
      "train loss:0.04013818619208951\n",
      "train loss:0.021939888441671926\n",
      "train loss:0.05311624933872574\n",
      "train loss:0.016687038084931383\n",
      "train loss:0.024065032583482786\n",
      "train loss:0.030540038592112167\n",
      "train loss:0.15406789756329278\n",
      "train loss:0.05800615088115629\n",
      "train loss:0.06525121164475318\n",
      "train loss:0.12509706847493468\n",
      "train loss:0.03459938308252501\n",
      "train loss:0.030791066174505898\n",
      "train loss:0.17563513716334703\n",
      "train loss:0.010436234790272917\n",
      "train loss:0.02569834365725132\n",
      "train loss:0.015745422744151336\n",
      "train loss:0.1315935019916816\n",
      "train loss:0.028382996932316735\n",
      "train loss:0.020857973975103833\n",
      "train loss:0.04991349969630663\n",
      "train loss:0.06432239317205561\n",
      "train loss:0.00965908880781313\n",
      "train loss:0.007799629312885105\n",
      "train loss:0.01175054794611057\n",
      "train loss:0.08540541218219175\n",
      "train loss:0.02505443211058018\n",
      "train loss:0.045383101528043354\n",
      "train loss:0.011859860641890546\n",
      "train loss:0.06498439101227887\n",
      "train loss:0.023909998559994157\n",
      "train loss:0.03703490525641517\n",
      "train loss:0.04515456389073931\n",
      "train loss:0.028106078946166548\n",
      "train loss:0.027939624443649794\n",
      "train loss:0.013619300070183112\n",
      "train loss:0.025109602441562445\n",
      "train loss:0.03462616482568023\n",
      "train loss:0.028401346033481177\n",
      "train loss:0.03415391136351788\n",
      "train loss:0.01039548757474552\n",
      "train loss:0.013768564923194402\n",
      "train loss:0.006071590159841298\n",
      "train loss:0.05404909162160878\n",
      "train loss:0.016261684256500798\n",
      "train loss:0.015876064746430486\n",
      "train loss:0.015838664697264443\n",
      "train loss:0.0848580663940659\n",
      "train loss:0.01860140726297365\n",
      "train loss:0.04074520651943184\n",
      "train loss:0.02503849761768538\n",
      "train loss:0.05246755069291943\n",
      "train loss:0.01871817907648881\n",
      "train loss:0.013007642440307561\n",
      "train loss:0.01957139462729654\n",
      "train loss:0.018445825626327753\n",
      "train loss:0.07901662870050895\n",
      "train loss:0.021732884465594363\n",
      "train loss:0.0075308567512846715\n",
      "train loss:0.04081159457755778\n",
      "train loss:0.01924625532568762\n",
      "train loss:0.05219955358366924\n",
      "train loss:0.06631003015501989\n",
      "train loss:0.04485537070880987\n",
      "train loss:0.009363563603829997\n",
      "train loss:0.011262476320199692\n",
      "train loss:0.010489004986797956\n",
      "train loss:0.018503050661525713\n",
      "train loss:0.011618051058460001\n",
      "train loss:0.007491190387303068\n",
      "train loss:0.029086250665054506\n",
      "train loss:0.002805505961087822\n",
      "train loss:0.004610303682437118\n",
      "train loss:0.04549196731826658\n",
      "train loss:0.009537492312718818\n",
      "train loss:0.02764650545567696\n",
      "train loss:0.0044756654735637605\n",
      "train loss:0.0335256487029214\n",
      "train loss:0.04227050993917415\n",
      "train loss:0.009798033768156293\n",
      "train loss:0.020740738514040343\n",
      "train loss:0.040909041613107544\n",
      "train loss:0.05357520906637938\n",
      "train loss:0.022314060532370998\n",
      "train loss:0.03495552945632384\n",
      "train loss:0.007798852515109934\n",
      "train loss:0.02615659455706692\n",
      "train loss:0.06267654377710286\n",
      "train loss:0.011161103036181008\n",
      "train loss:0.12377905695184259\n",
      "train loss:0.009399688074056207\n",
      "train loss:0.018410133939927652\n",
      "train loss:0.004418975731119171\n",
      "train loss:0.02888051623458547\n",
      "train loss:0.08075181342341102\n",
      "train loss:0.09293747854777192\n",
      "train loss:0.026174081112724675\n",
      "train loss:0.02875797743902028\n",
      "train loss:0.009052514311412675\n",
      "train loss:0.045056312044030766\n",
      "train loss:0.031401913878962046\n",
      "train loss:0.04322320855205877\n",
      "train loss:0.05104699541486396\n",
      "train loss:0.06623309693233265\n",
      "train loss:0.03647095073165051\n",
      "train loss:0.04543444485373354\n",
      "train loss:0.06709217543620373\n",
      "train loss:0.07827301863197393\n",
      "train loss:0.018077745091230817\n",
      "train loss:0.013647668541577984\n",
      "train loss:0.01173003794112783\n",
      "train loss:0.00953250783201121\n",
      "train loss:0.014611190813101957\n",
      "train loss:0.023768209779411895\n",
      "train loss:0.03244581520419946\n",
      "train loss:0.024178446612544768\n",
      "train loss:0.01545232644579747\n",
      "train loss:0.021879726863326194\n",
      "train loss:0.03949561511200067\n",
      "train loss:0.01729898859855864\n",
      "train loss:0.025924139937004168\n",
      "train loss:0.08167068866749143\n",
      "train loss:0.013061961610440001\n",
      "train loss:0.00834812530660078\n",
      "train loss:0.01867023112075267\n",
      "train loss:0.024593495526231135\n",
      "train loss:0.022434552830292956\n",
      "train loss:0.00867675736207635\n",
      "train loss:0.05653338104595381\n",
      "train loss:0.010894221734577712\n",
      "train loss:0.008596415940062075\n",
      "train loss:0.048973031521612996\n",
      "train loss:0.02254967195329887\n",
      "train loss:0.046308782542982076\n",
      "train loss:0.012384634335955068\n",
      "train loss:0.02967478729859077\n",
      "train loss:0.0408094580969549\n",
      "train loss:0.018577802329411378\n",
      "train loss:0.037712776185627045\n",
      "train loss:0.0782400989306733\n",
      "train loss:0.03683364241707903\n",
      "train loss:0.017095789254785675\n",
      "train loss:0.011235508401498739\n",
      "train loss:0.012697701533923475\n",
      "train loss:0.015420931255026884\n",
      "train loss:0.06032897543245347\n",
      "train loss:0.012173181875506634\n",
      "train loss:0.018717831666841163\n",
      "train loss:0.02927828278037437\n",
      "train loss:0.028872104836623086\n",
      "train loss:0.03538453628553515\n",
      "train loss:0.025246478428867777\n",
      "train loss:0.004905206184884545\n",
      "train loss:0.011517231688233662\n",
      "train loss:0.009481678497903939\n",
      "train loss:0.060076637429063384\n",
      "train loss:0.043291668976045264\n",
      "train loss:0.039264527009722786\n",
      "train loss:0.02108363572194269\n",
      "train loss:0.031163990716660903\n",
      "train loss:0.03466692040614436\n",
      "train loss:0.017987611858934244\n",
      "train loss:0.027687533490441195\n",
      "train loss:0.028740016133270156\n",
      "train loss:0.014985442183722449\n",
      "train loss:0.020122871982995318\n",
      "train loss:0.032669451354918576\n",
      "train loss:0.018973284140546897\n",
      "train loss:0.020339469552038955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1470481414868987\n",
      "train loss:0.030641369822038866\n",
      "train loss:0.013332500447077478\n",
      "train loss:0.030444845623397266\n",
      "train loss:0.011029936933974936\n",
      "train loss:0.02527849576478648\n",
      "train loss:0.014104365346272796\n",
      "train loss:0.09012683307126954\n",
      "train loss:0.03228455673324469\n",
      "train loss:0.0070952931514862505\n",
      "train loss:0.04391542384284363\n",
      "train loss:0.009018945505242433\n",
      "train loss:0.03568305232886241\n",
      "train loss:0.03885857879888154\n",
      "train loss:0.03314655471989261\n",
      "train loss:0.028374237348499424\n",
      "train loss:0.040942427698384846\n",
      "train loss:0.008475687888600673\n",
      "train loss:0.03998459018364132\n",
      "train loss:0.020294273124633767\n",
      "train loss:0.03189573715321905\n",
      "train loss:0.005503046844046019\n",
      "train loss:0.07623738682354958\n",
      "train loss:0.017696781227274805\n",
      "train loss:0.012571720297350947\n",
      "train loss:0.11012316324968965\n",
      "train loss:0.022540408187015405\n",
      "train loss:0.025172626816623758\n",
      "train loss:0.021395397081986546\n",
      "train loss:0.01910404938621094\n",
      "train loss:0.09425366058241641\n",
      "train loss:0.04554890062323313\n",
      "train loss:0.05099502750040129\n",
      "train loss:0.04692986983098128\n",
      "train loss:0.0396921314665359\n",
      "train loss:0.013719471996553044\n",
      "train loss:0.016988393174935626\n",
      "train loss:0.08495933516991633\n",
      "train loss:0.024272855220775016\n",
      "train loss:0.04785209746060799\n",
      "train loss:0.014489528300981637\n",
      "train loss:0.04135985991552207\n",
      "train loss:0.0702368557309959\n",
      "train loss:0.022817509735893342\n",
      "train loss:0.038651331938536294\n",
      "train loss:0.053161473099121184\n",
      "train loss:0.046510562239042194\n",
      "train loss:0.057127304209739264\n",
      "train loss:0.01023706470775252\n",
      "train loss:0.05060600795231029\n",
      "train loss:0.01169876803712874\n",
      "train loss:0.020462872237502462\n",
      "train loss:0.020834383910920642\n",
      "train loss:0.02918310317276316\n",
      "train loss:0.03213867895190991\n",
      "train loss:0.00862195140097199\n",
      "train loss:0.007335524701080823\n",
      "train loss:0.046885892941544764\n",
      "train loss:0.017059136230867578\n",
      "train loss:0.040978171148582314\n",
      "train loss:0.03189017084745267\n",
      "train loss:0.012863653194518664\n",
      "train loss:0.01743260211515999\n",
      "train loss:0.01653492421167697\n",
      "train loss:0.025943829411449203\n",
      "train loss:0.019765513936299575\n",
      "train loss:0.010648332842231524\n",
      "train loss:0.015611826516222827\n",
      "train loss:0.04473241721967214\n",
      "train loss:0.01078650652602112\n",
      "train loss:0.0035652227633070415\n",
      "train loss:0.045448648183709466\n",
      "train loss:0.02341133273115239\n",
      "train loss:0.02465342551736001\n",
      "train loss:0.006868677645964443\n",
      "train loss:0.008155337099398096\n",
      "train loss:0.027300353292259324\n",
      "train loss:0.032524621045578725\n",
      "train loss:0.049702688652374025\n",
      "train loss:0.07222515134292838\n",
      "train loss:0.029721512012623477\n",
      "train loss:0.02068985611083488\n",
      "train loss:0.022147348370967067\n",
      "train loss:0.05065804992204075\n",
      "train loss:0.05287773582739518\n",
      "train loss:0.04469418850341051\n",
      "train loss:0.00665347009274516\n",
      "train loss:0.026889681853167466\n",
      "train loss:0.03354863891484591\n",
      "train loss:0.008219817436909449\n",
      "train loss:0.033537508711371754\n",
      "train loss:0.03083856651321577\n",
      "train loss:0.06162744181059526\n",
      "train loss:0.014825656842573478\n",
      "train loss:0.043462156148993215\n",
      "train loss:0.00301337572017012\n",
      "train loss:0.0177314960382909\n",
      "train loss:0.02792177484628979\n",
      "train loss:0.027938815467595385\n",
      "train loss:0.013308870972655746\n",
      "train loss:0.007482734586929059\n",
      "train loss:0.012646743843629666\n",
      "train loss:0.012921307635635591\n",
      "train loss:0.009395526334613548\n",
      "train loss:0.07493490007227872\n",
      "train loss:0.08756810749331191\n",
      "train loss:0.04779146063762932\n",
      "train loss:0.034018479163547416\n",
      "train loss:0.07415377440701412\n",
      "train loss:0.005584142952269926\n",
      "train loss:0.008064630111680357\n",
      "train loss:0.031621961714986\n",
      "train loss:0.041292184151843395\n",
      "train loss:0.021590571295230444\n",
      "train loss:0.005621617357880418\n",
      "train loss:0.05699905516806589\n",
      "train loss:0.02313009935765092\n",
      "train loss:0.05306035675498551\n",
      "train loss:0.05614853568897736\n",
      "train loss:0.07536191646877584\n",
      "train loss:0.08828087224252443\n",
      "train loss:0.01637872815690425\n",
      "train loss:0.008237281967622911\n",
      "train loss:0.007367385477402507\n",
      "train loss:0.03251913961410276\n",
      "train loss:0.03181502903219593\n",
      "train loss:0.07405818967381018\n",
      "train loss:0.0075860634106714505\n",
      "train loss:0.06960168940863691\n",
      "train loss:0.02208449738548798\n",
      "train loss:0.02160073736474208\n",
      "train loss:0.0882180884014779\n",
      "train loss:0.0779444609069715\n",
      "train loss:0.027703775182371472\n",
      "train loss:0.05184205148865069\n",
      "train loss:0.035787212945402325\n",
      "train loss:0.032248994232263156\n",
      "train loss:0.013964473111309342\n",
      "train loss:0.07450905237958788\n",
      "train loss:0.02461849533623441\n",
      "train loss:0.015632419513069384\n",
      "train loss:0.02027575738783782\n",
      "train loss:0.01803276449689323\n",
      "train loss:0.04746572210430648\n",
      "train loss:0.06859621416592095\n",
      "train loss:0.057184976879035884\n",
      "train loss:0.05594750321358027\n",
      "train loss:0.03856218696708214\n",
      "train loss:0.021840154071581776\n",
      "train loss:0.012502809129070489\n",
      "train loss:0.019038765257708614\n",
      "train loss:0.06498946433446985\n",
      "train loss:0.029485815157036167\n",
      "train loss:0.01861053375035959\n",
      "train loss:0.016227363193739054\n",
      "train loss:0.05612414163131855\n",
      "train loss:0.03685525878952715\n",
      "train loss:0.021404656418131194\n",
      "train loss:0.02177055597076126\n",
      "train loss:0.037401138302159846\n",
      "train loss:0.03475747028295075\n",
      "train loss:0.019344484606846932\n",
      "train loss:0.011095817604805745\n",
      "train loss:0.06156866363028089\n",
      "train loss:0.025268903483580886\n",
      "train loss:0.07508334598157168\n",
      "train loss:0.012196903748413692\n",
      "train loss:0.025456109895733516\n",
      "train loss:0.006415364385236481\n",
      "train loss:0.030500161352806258\n",
      "train loss:0.056516071952837345\n",
      "train loss:0.021466190383265204\n",
      "train loss:0.010335951908926161\n",
      "train loss:0.043377934352376364\n",
      "train loss:0.04191731097371609\n",
      "train loss:0.03311087588810007\n",
      "train loss:0.00714314023985807\n",
      "train loss:0.005853580112387785\n",
      "train loss:0.0208767299611951\n",
      "train loss:0.0172770075577789\n",
      "train loss:0.01782417815665386\n",
      "train loss:0.02708821808805301\n",
      "train loss:0.011813310855830574\n",
      "train loss:0.05636589397144962\n",
      "train loss:0.019217517498618112\n",
      "train loss:0.004655881572352036\n",
      "train loss:0.01020466377106516\n",
      "train loss:0.00908647248563088\n",
      "train loss:0.015988807106819644\n",
      "train loss:0.011433889233873906\n",
      "train loss:0.01695922253120965\n",
      "train loss:0.007743949672435138\n",
      "train loss:0.01739082382743999\n",
      "train loss:0.08358873782253431\n",
      "train loss:0.0052355686610730656\n",
      "train loss:0.005305791939007477\n",
      "train loss:0.005547636493805316\n",
      "train loss:0.022191773874329034\n",
      "train loss:0.005871272601559068\n",
      "train loss:0.010439484592291165\n",
      "train loss:0.035680437628221\n",
      "train loss:0.017873734059236347\n",
      "train loss:0.056452542303533686\n",
      "train loss:0.008964825291365872\n",
      "train loss:0.008641405154022824\n",
      "train loss:0.01840548161080035\n",
      "train loss:0.0759130811404476\n",
      "train loss:0.00860522908010085\n",
      "train loss:0.012720301827109102\n",
      "train loss:0.005424854149083759\n",
      "train loss:0.0036796959139183696\n",
      "train loss:0.11065067567495096\n",
      "train loss:0.012982842742863255\n",
      "train loss:0.01037333277870242\n",
      "train loss:0.027615472384618093\n",
      "train loss:0.08529338284452713\n",
      "train loss:0.013247072920835181\n",
      "train loss:0.0653834221713872\n",
      "train loss:0.01269354859086641\n",
      "train loss:0.013431640544957641\n",
      "train loss:0.014869799421149094\n",
      "train loss:0.007974105516540177\n",
      "train loss:0.016450001599165397\n",
      "train loss:0.015136865351323409\n",
      "train loss:0.016442466017646845\n",
      "train loss:0.01489671414045893\n",
      "train loss:0.033961831990908645\n",
      "train loss:0.0324470232105826\n",
      "train loss:0.03490911765073859\n",
      "train loss:0.03762861494833858\n",
      "train loss:0.03832990985229023\n",
      "train loss:0.01305939202096875\n",
      "train loss:0.027977478544321092\n",
      "train loss:0.008291574151571356\n",
      "train loss:0.010924458039623013\n",
      "train loss:0.011985004463615978\n",
      "train loss:0.03343433537012742\n",
      "train loss:0.03288302200846715\n",
      "train loss:0.05357051886424981\n",
      "train loss:0.02265823079989564\n",
      "train loss:0.019495817432869534\n",
      "train loss:0.04968323679073627\n",
      "train loss:0.03917465211091781\n",
      "train loss:0.03916783360340931\n",
      "train loss:0.015122901111459102\n",
      "train loss:0.021900416608798552\n",
      "train loss:0.0099488339358101\n",
      "train loss:0.006314272542806941\n",
      "train loss:0.12708263301546638\n",
      "train loss:0.043188902595119594\n",
      "train loss:0.018420705757707875\n",
      "train loss:0.012970248196399158\n",
      "train loss:0.051249527488798574\n",
      "train loss:0.05703084040857621\n",
      "train loss:0.05522588074572272\n",
      "train loss:0.029013933989942613\n",
      "train loss:0.07800100067565796\n",
      "train loss:0.02311339431010777\n",
      "train loss:0.01897639878957162\n",
      "train loss:0.09686447047561829\n",
      "train loss:0.022940354647861455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1329475217385091\n",
      "train loss:0.02684324807312404\n",
      "train loss:0.008594043149717664\n",
      "train loss:0.05746263900400298\n",
      "train loss:0.03589429891304324\n",
      "train loss:0.004843926561833852\n",
      "train loss:0.01424685324947663\n",
      "train loss:0.009117994486010434\n",
      "train loss:0.03333018680468367\n",
      "train loss:0.02619161377936092\n",
      "train loss:0.08092176815388155\n",
      "train loss:0.0291133731796484\n",
      "train loss:0.024375752238355117\n",
      "train loss:0.03520711277561968\n",
      "train loss:0.017171760117164175\n",
      "train loss:0.012190850642574184\n",
      "train loss:0.013015074126381159\n",
      "train loss:0.07830065378234213\n",
      "train loss:0.03899621118227167\n",
      "train loss:0.017869017135034346\n",
      "train loss:0.015006989279868927\n",
      "train loss:0.016218389230983742\n",
      "train loss:0.02818857521502273\n",
      "train loss:0.022073971930693874\n",
      "train loss:0.014045051581203328\n",
      "train loss:0.0564177995158503\n",
      "train loss:0.07608361871351244\n",
      "train loss:0.034103975471760334\n",
      "train loss:0.007045245103306539\n",
      "train loss:0.01576992463017915\n",
      "train loss:0.01985980107203935\n",
      "train loss:0.019709054145463305\n",
      "train loss:0.004908836478802898\n",
      "train loss:0.04210363146718945\n",
      "train loss:0.005691459622134004\n",
      "train loss:0.038746178705730216\n",
      "train loss:0.0021339499303067253\n",
      "train loss:0.0405353008465212\n",
      "train loss:0.04599048693307981\n",
      "train loss:0.036501098602803636\n",
      "train loss:0.01493227646879341\n",
      "train loss:0.035882496738152386\n",
      "train loss:0.12821069149676054\n",
      "train loss:0.03165031935254149\n",
      "train loss:0.05316336829958149\n",
      "train loss:0.014789325929365079\n",
      "train loss:0.03360745038523799\n",
      "train loss:0.03955664353353122\n",
      "train loss:0.023976855109250392\n",
      "train loss:0.014026655314816205\n",
      "train loss:0.013699546650172492\n",
      "train loss:0.037111011916729574\n",
      "train loss:0.11040057672977018\n",
      "train loss:0.007123876421942741\n",
      "train loss:0.024918475311229406\n",
      "train loss:0.040680554797645846\n",
      "train loss:0.01882513898626775\n",
      "train loss:0.06905390874144819\n",
      "train loss:0.010270036150191458\n",
      "train loss:0.14549315260872855\n",
      "train loss:0.024849945585700264\n",
      "train loss:0.03826948204667444\n",
      "train loss:0.022550577653068067\n",
      "train loss:0.02958004458478006\n",
      "train loss:0.05254509705196725\n",
      "train loss:0.06579375539426618\n",
      "train loss:0.013567186620325355\n",
      "train loss:0.05039597427505013\n",
      "train loss:0.012605029395522757\n",
      "train loss:0.03369877757449985\n",
      "train loss:0.004350209810096775\n",
      "train loss:0.029906581037791962\n",
      "train loss:0.058863367767973275\n",
      "train loss:0.040724157774875265\n",
      "train loss:0.029030806178284563\n",
      "train loss:0.018260471363344483\n",
      "train loss:0.047083302448354084\n",
      "train loss:0.02804453396261467\n",
      "train loss:0.02825842423660138\n",
      "train loss:0.010545735320925436\n",
      "train loss:0.02498459764781366\n",
      "train loss:0.017689023876907625\n",
      "train loss:0.03874349570088824\n",
      "train loss:0.007717181298489029\n",
      "train loss:0.025663341521558313\n",
      "train loss:0.01398728401274028\n",
      "train loss:0.028785891653797416\n",
      "train loss:0.06521728296585652\n",
      "train loss:0.007334536982202039\n",
      "train loss:0.032559264268623093\n",
      "train loss:0.03734972574028102\n",
      "train loss:0.02160017685480369\n",
      "train loss:0.02079348764497397\n",
      "train loss:0.019984997947084016\n",
      "train loss:0.021145701687898654\n",
      "train loss:0.02147832585003343\n",
      "train loss:0.005554653816618229\n",
      "train loss:0.02556732088524782\n",
      "train loss:0.028651307073381812\n",
      "train loss:0.05556120573749903\n",
      "train loss:0.028198853932451157\n",
      "train loss:0.04034383949053596\n",
      "train loss:0.021779674649120832\n",
      "train loss:0.036730122214885814\n",
      "=== epoch:6, train acc:0.985, test acc:0.986 ===\n",
      "train loss:0.004611336997613611\n",
      "train loss:0.03615767602793476\n",
      "train loss:0.04610828928287547\n",
      "train loss:0.05963651420638349\n",
      "train loss:0.012827442607258906\n",
      "train loss:0.011128733890424932\n",
      "train loss:0.019231039166449762\n",
      "train loss:0.045608296439527546\n",
      "train loss:0.009197608568776522\n",
      "train loss:0.008579684581815367\n",
      "train loss:0.014461321701268539\n",
      "train loss:0.016008458487853715\n",
      "train loss:0.05360785094128642\n",
      "train loss:0.02285080446622124\n",
      "train loss:0.006536061515361181\n",
      "train loss:0.031494946766591043\n",
      "train loss:0.011703800386566616\n",
      "train loss:0.003188069173694071\n",
      "train loss:0.025626187823113312\n",
      "train loss:0.015243763958917508\n",
      "train loss:0.014447613365599491\n",
      "train loss:0.010595843463241016\n",
      "train loss:0.008127604765535385\n",
      "train loss:0.01691043405626226\n",
      "train loss:0.03387855040450012\n",
      "train loss:0.011577304376350663\n",
      "train loss:0.08366464520634612\n",
      "train loss:0.026025622083271544\n",
      "train loss:0.015436381998678408\n",
      "train loss:0.02386719972819966\n",
      "train loss:0.06459523151308239\n",
      "train loss:0.004569192290005591\n",
      "train loss:0.03337270905428889\n",
      "train loss:0.01632489212404115\n",
      "train loss:0.01734493571301111\n",
      "train loss:0.008300783365413119\n",
      "train loss:0.004389757347873896\n",
      "train loss:0.07778888400849433\n",
      "train loss:0.022485899572107095\n",
      "train loss:0.01327261809012748\n",
      "train loss:0.01504173225983461\n",
      "train loss:0.0347265148607113\n",
      "train loss:0.019453814387430216\n",
      "train loss:0.017868345739660643\n",
      "train loss:0.03982971895969285\n",
      "train loss:0.013212013444409608\n",
      "train loss:0.031639269097654306\n",
      "train loss:0.06400174970637455\n",
      "train loss:0.05229400291516979\n",
      "train loss:0.00951390408388847\n",
      "train loss:0.019011527492694535\n",
      "train loss:0.05788403137929228\n",
      "train loss:0.008948631376804328\n",
      "train loss:0.008469697926913518\n",
      "train loss:0.06705240413346539\n",
      "train loss:0.048355707458688606\n",
      "train loss:0.016092459250952516\n",
      "train loss:0.01501252071501869\n",
      "train loss:0.0336683770648111\n",
      "train loss:0.029183965128503922\n",
      "train loss:0.027973532286202425\n",
      "train loss:0.0037706504773577384\n",
      "train loss:0.018265894966240252\n",
      "train loss:0.01411510234656601\n",
      "train loss:0.007945925219122381\n",
      "train loss:0.037171265322530664\n",
      "train loss:0.055604089734427535\n",
      "train loss:0.04218792163833356\n",
      "train loss:0.012726910667056683\n",
      "train loss:0.01691359859174966\n",
      "train loss:0.006016754746529831\n",
      "train loss:0.04897590659491267\n",
      "train loss:0.021255241625363235\n",
      "train loss:0.03230694114010384\n",
      "train loss:0.01639603328936687\n",
      "train loss:0.03363944663759277\n",
      "train loss:0.029865993228719176\n",
      "train loss:0.020944654008725538\n",
      "train loss:0.011950260252246363\n",
      "train loss:0.01970711406673913\n",
      "train loss:0.03044329788170497\n",
      "train loss:0.01646934865483064\n",
      "train loss:0.08138989318718647\n",
      "train loss:0.030909916101095822\n",
      "train loss:0.014050259031721891\n",
      "train loss:0.01003776097033555\n",
      "train loss:0.008486984377693563\n",
      "train loss:0.02381862620131745\n",
      "train loss:0.08303208595529776\n",
      "train loss:0.0502967906922669\n",
      "train loss:0.01369285799230715\n",
      "train loss:0.05703911966720383\n",
      "train loss:0.012028054147043674\n",
      "train loss:0.010686798627393745\n",
      "train loss:0.03772153524338106\n",
      "train loss:0.01049495308075143\n",
      "train loss:0.005382782766349791\n",
      "train loss:0.01449560576093461\n",
      "train loss:0.01603235264713492\n",
      "train loss:0.022140368194201874\n",
      "train loss:0.03715348438694798\n",
      "train loss:0.004814715041050114\n",
      "train loss:0.01204830011710763\n",
      "train loss:0.008937859746605853\n",
      "train loss:0.041344655257908765\n",
      "train loss:0.008420800508885273\n",
      "train loss:0.048585356523378004\n",
      "train loss:0.011942378199118045\n",
      "train loss:0.013288513590100642\n",
      "train loss:0.00814514783993177\n",
      "train loss:0.010767640260291174\n",
      "train loss:0.039693799251430864\n",
      "train loss:0.050543578244006106\n",
      "train loss:0.008460260041359984\n",
      "train loss:0.008430468769318305\n",
      "train loss:0.021659211936211672\n",
      "train loss:0.05682520775537418\n",
      "train loss:0.003169491193941312\n",
      "train loss:0.027585139460151377\n",
      "train loss:0.057990530718907134\n",
      "train loss:0.02639461337588434\n",
      "train loss:0.01442504285259004\n",
      "train loss:0.010982063105837804\n",
      "train loss:0.012405013338645337\n",
      "train loss:0.014165345874140525\n",
      "train loss:0.0130775882292057\n",
      "train loss:0.003399061075994527\n",
      "train loss:0.03766916508430237\n",
      "train loss:0.004155539452412574\n",
      "train loss:0.019057161187676582\n",
      "train loss:0.017501486540145092\n",
      "train loss:0.01050973535010246\n",
      "train loss:0.028098334850944595\n",
      "train loss:0.03883159480499151\n",
      "train loss:0.010679151725236336\n",
      "train loss:0.0025675916524711706\n",
      "train loss:0.018810587550789598\n",
      "train loss:0.016916945525863133\n",
      "train loss:0.06493721658695067\n",
      "train loss:0.010272060506613351\n",
      "train loss:0.03207177817602096\n",
      "train loss:0.01036897736930422\n",
      "train loss:0.010206344886264387\n",
      "train loss:0.011222554173489576\n",
      "train loss:0.051751246235338784\n",
      "train loss:0.06352750296569626\n",
      "train loss:0.011060706072298\n",
      "train loss:0.03312860672761213\n",
      "train loss:0.0048458521286258\n",
      "train loss:0.01480009721749138\n",
      "train loss:0.017385319211206025\n",
      "train loss:0.0254752728757646\n",
      "train loss:0.007369879562124324\n",
      "train loss:0.060546490631030056\n",
      "train loss:0.04903987299461007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07274596449018322\n",
      "train loss:0.009469379007594075\n",
      "train loss:0.080762340711297\n",
      "train loss:0.01292793858342681\n",
      "train loss:0.009123737631488405\n",
      "train loss:0.009947513479724727\n",
      "train loss:0.00881012182323972\n",
      "train loss:0.006037206501482233\n",
      "train loss:0.03739104878912904\n",
      "train loss:0.021401821972414567\n",
      "train loss:0.02056022974391258\n",
      "train loss:0.057354294198971124\n",
      "train loss:0.0031624770994215083\n",
      "train loss:0.012605118483578592\n",
      "train loss:0.00626652940327588\n",
      "train loss:0.010665314873625941\n",
      "train loss:0.01405765604339013\n",
      "train loss:0.018232106319211593\n",
      "train loss:0.0075968587697988026\n",
      "train loss:0.02859838830008294\n",
      "train loss:0.02085431370857891\n",
      "train loss:0.014898083469424166\n",
      "train loss:0.019291434471145612\n",
      "train loss:0.023008096850882297\n",
      "train loss:0.02053311203325565\n",
      "train loss:0.005156829004362331\n",
      "train loss:0.02885313683484243\n",
      "train loss:0.07486044527508634\n",
      "train loss:0.023945358766728618\n",
      "train loss:0.01596017869804526\n",
      "train loss:0.007800647203003108\n",
      "train loss:0.009112741587828967\n",
      "train loss:0.010709421842120368\n",
      "train loss:0.008770834666940728\n",
      "train loss:0.06405571068417204\n",
      "train loss:0.017702988327370075\n",
      "train loss:0.03142254112293185\n",
      "train loss:0.005126251066066221\n",
      "train loss:0.03401963429041179\n",
      "train loss:0.00889269312725642\n",
      "train loss:0.05383478409499318\n",
      "train loss:0.009055177311477475\n",
      "train loss:0.025107761607984436\n",
      "train loss:0.007916772176136537\n",
      "train loss:0.07372786940223947\n",
      "train loss:0.03877032551150483\n",
      "train loss:0.01759421572481016\n",
      "train loss:0.008321712620679158\n",
      "train loss:0.02182305856098779\n",
      "train loss:0.02851522160309004\n",
      "train loss:0.08383196352688736\n",
      "train loss:0.017316257024485155\n",
      "train loss:0.05956892951383215\n",
      "train loss:0.011865769090204939\n",
      "train loss:0.005007880409006823\n",
      "train loss:0.02381116176081267\n",
      "train loss:0.00947377967420994\n",
      "train loss:0.005805363477024732\n",
      "train loss:0.01178550110001066\n",
      "train loss:0.05171861504829223\n",
      "train loss:0.05821787496041213\n",
      "train loss:0.017097501365618845\n",
      "train loss:0.05686534159748189\n",
      "train loss:0.022067125466485614\n",
      "train loss:0.05893765961902995\n",
      "train loss:0.02671192294036578\n",
      "train loss:0.028645433022615973\n",
      "train loss:0.0038035331028390836\n",
      "train loss:0.00736222596740715\n",
      "train loss:0.007703635560925081\n",
      "train loss:0.050657087428489705\n",
      "train loss:0.10034069803878666\n",
      "train loss:0.011120347735699086\n",
      "train loss:0.046219097515840836\n",
      "train loss:0.024471800075059752\n",
      "train loss:0.0170175203448089\n",
      "train loss:0.032851623246036694\n",
      "train loss:0.00667481339641313\n",
      "train loss:0.035606627290202815\n",
      "train loss:0.005501269758745942\n",
      "train loss:0.0064969857385631736\n",
      "train loss:0.014764148030532944\n",
      "train loss:0.018964025271969928\n",
      "train loss:0.10531302484036269\n",
      "train loss:0.01850683266839283\n",
      "train loss:0.014242902344249122\n",
      "train loss:0.011155478872726695\n",
      "train loss:0.015806666637137902\n",
      "train loss:0.03204319617873261\n",
      "train loss:0.028271861620534668\n",
      "train loss:0.04132459873438969\n",
      "train loss:0.008251296876161872\n",
      "train loss:0.04323424319999026\n",
      "train loss:0.06956665278398205\n",
      "train loss:0.018800798991042852\n",
      "train loss:0.0067177577785751605\n",
      "train loss:0.017343372780189565\n",
      "train loss:0.02711670414502038\n",
      "train loss:0.03463462731565943\n",
      "train loss:0.008029560086642525\n",
      "train loss:0.015567683839465834\n",
      "train loss:0.015901414700424093\n",
      "train loss:0.016959084217329213\n",
      "train loss:0.012425598929910669\n",
      "train loss:0.054574314957278866\n",
      "train loss:0.04073056573571236\n",
      "train loss:0.007457002449596128\n",
      "train loss:0.02425197092261212\n",
      "train loss:0.10968354154168432\n",
      "train loss:0.046194195352852886\n",
      "train loss:0.015553757581055457\n",
      "train loss:0.023332399567893812\n",
      "train loss:0.06651894294744798\n",
      "train loss:0.02704498693482849\n",
      "train loss:0.015788794096101944\n",
      "train loss:0.01160490803147686\n",
      "train loss:0.004529349100264391\n",
      "train loss:0.05222804641953637\n",
      "train loss:0.0026624317028652905\n",
      "train loss:0.04357359247514729\n",
      "train loss:0.04570316091467575\n",
      "train loss:0.026113898002580883\n",
      "train loss:0.0683509813670787\n",
      "train loss:0.04002920890171355\n",
      "train loss:0.09314569896011352\n",
      "train loss:0.05817618828524416\n",
      "train loss:0.026899241513289623\n",
      "train loss:0.02957745188625286\n",
      "train loss:0.014048219789051998\n",
      "train loss:0.04624989057498518\n",
      "train loss:0.010478831501382464\n",
      "train loss:0.008635968798574352\n",
      "train loss:0.003979207194320707\n",
      "train loss:0.01771925206185831\n",
      "train loss:0.004334152486731854\n",
      "train loss:0.059743372349000075\n",
      "train loss:0.031314016871475094\n",
      "train loss:0.041115398775732837\n",
      "train loss:0.009109131868270707\n",
      "train loss:0.024472051894582025\n",
      "train loss:0.028308846584106574\n",
      "train loss:0.009789655220201102\n",
      "train loss:0.008499702203257577\n",
      "train loss:0.006707664188938965\n",
      "train loss:0.01569619348610244\n",
      "train loss:0.02761443465231348\n",
      "train loss:0.028842024625151876\n",
      "train loss:0.0580448783617738\n",
      "train loss:0.02920905088941122\n",
      "train loss:0.01770783585558309\n",
      "train loss:0.009437646824201246\n",
      "train loss:0.033499456628800287\n",
      "train loss:0.043428872118824347\n",
      "train loss:0.018586510901696246\n",
      "train loss:0.027338766993950925\n",
      "train loss:0.017105719280617885\n",
      "train loss:0.007032228693226677\n",
      "train loss:0.028886159882952508\n",
      "train loss:0.01917624641087667\n",
      "train loss:0.011875880737750947\n",
      "train loss:0.020290655100530745\n",
      "train loss:0.024520517819730567\n",
      "train loss:0.015259717464690604\n",
      "train loss:0.03910472538431592\n",
      "train loss:0.0165831995930386\n",
      "train loss:0.03711154203303701\n",
      "train loss:0.05594489372965504\n",
      "train loss:0.0536951937614953\n",
      "train loss:0.0014740353655511062\n",
      "train loss:0.017427235629234945\n",
      "train loss:0.03089049250899538\n",
      "train loss:0.010117917487425594\n",
      "train loss:0.01729403487129895\n",
      "train loss:0.0167967127460633\n",
      "train loss:0.014026028107277154\n",
      "train loss:0.010166258654300599\n",
      "train loss:0.0806210288194771\n",
      "train loss:0.004555284033848396\n",
      "train loss:0.05966531528530279\n",
      "train loss:0.0978284493506851\n",
      "train loss:0.023150627547733383\n",
      "train loss:0.07782473389395426\n",
      "train loss:0.03395667113264281\n",
      "train loss:0.06138001497042158\n",
      "train loss:0.022639675212143648\n",
      "train loss:0.015795703793110915\n",
      "train loss:0.01326983261763881\n",
      "train loss:0.07890734279344529\n",
      "train loss:0.04460761175775155\n",
      "train loss:0.007048772415403783\n",
      "train loss:0.039833474379032244\n",
      "train loss:0.01225832089124393\n",
      "train loss:0.0037503546645765214\n",
      "train loss:0.010073150707663302\n",
      "train loss:0.03780608580963171\n",
      "train loss:0.045274603540082996\n",
      "train loss:0.021722541704379057\n",
      "train loss:0.024816509227482846\n",
      "train loss:0.022369596100028515\n",
      "train loss:0.02213517792862923\n",
      "train loss:0.011189369956585966\n",
      "train loss:0.006511255885792221\n",
      "train loss:0.010981763265412012\n",
      "train loss:0.04430379125532284\n",
      "train loss:0.02209044660320292\n",
      "train loss:0.046810455096532096\n",
      "train loss:0.027026875166573445\n",
      "train loss:0.025258303771365186\n",
      "train loss:0.021297727715955627\n",
      "train loss:0.03412864474125773\n",
      "train loss:0.013462924478582479\n",
      "train loss:0.020524376634290454\n",
      "train loss:0.009147481427587754\n",
      "train loss:0.018533725562349494\n",
      "train loss:0.031936657148691816\n",
      "train loss:0.02087975470543844\n",
      "train loss:0.00820130222869231\n",
      "train loss:0.03944115301784792\n",
      "train loss:0.0047499793666359825\n",
      "train loss:0.009690124085815347\n",
      "train loss:0.04001091356518459\n",
      "train loss:0.019098066964631653\n",
      "train loss:0.013262636425813141\n",
      "train loss:0.012999559945043506\n",
      "train loss:0.016570726815934946\n",
      "train loss:0.004593974780152923\n",
      "train loss:0.018275106833989533\n",
      "train loss:0.026381612039424393\n",
      "train loss:0.02676545479163904\n",
      "train loss:0.009444695445156255\n",
      "train loss:0.0323949419451946\n",
      "train loss:0.023924134656187465\n",
      "train loss:0.03603835299608169\n",
      "train loss:0.004176984241219358\n",
      "train loss:0.03645022027648708\n",
      "train loss:0.04460750067345018\n",
      "train loss:0.01652825843489553\n",
      "train loss:0.050568014621955676\n",
      "train loss:0.11237188478166722\n",
      "train loss:0.002461001217032581\n",
      "train loss:0.018698327786276236\n",
      "train loss:0.02656210728364451\n",
      "train loss:0.011577373199339045\n",
      "train loss:0.009103599907881533\n",
      "train loss:0.011907648350999752\n",
      "train loss:0.029939216685189556\n",
      "train loss:0.021190816124514122\n",
      "train loss:0.02213023218972939\n",
      "train loss:0.015392723612411254\n",
      "train loss:0.01721936256707184\n",
      "train loss:0.05564677465486152\n",
      "train loss:0.02832590664807812\n",
      "train loss:0.006511694749796909\n",
      "train loss:0.03430696946999016\n",
      "train loss:0.0036243785195232536\n",
      "train loss:0.006015335336238377\n",
      "train loss:0.026454750960717286\n",
      "train loss:0.03380273770570729\n",
      "train loss:0.006837394484569969\n",
      "train loss:0.0011414756321114054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015553733201509825\n",
      "train loss:0.04020075576432573\n",
      "train loss:0.017255062511982822\n",
      "train loss:0.010130709567286454\n",
      "train loss:0.02545111684768635\n",
      "train loss:0.023015725715218007\n",
      "train loss:0.006201906918642593\n",
      "train loss:0.005281982585674955\n",
      "train loss:0.1460196703315726\n",
      "train loss:0.03876954192696104\n",
      "train loss:0.016188494150628986\n",
      "train loss:0.01862159954350778\n",
      "train loss:0.027112860928815593\n",
      "train loss:0.06472980471421211\n",
      "train loss:0.05388308992323422\n",
      "train loss:0.04854357698044181\n",
      "train loss:0.007330686721566529\n",
      "train loss:0.029309775533191775\n",
      "train loss:0.057842821609364076\n",
      "train loss:0.05466097021316292\n",
      "train loss:0.007527815782927026\n",
      "train loss:0.022878853273319018\n",
      "train loss:0.015295062201348216\n",
      "train loss:0.03340883303033769\n",
      "train loss:0.0031568401928523055\n",
      "train loss:0.0343535485066693\n",
      "train loss:0.006053649024530875\n",
      "train loss:0.028588314441231336\n",
      "train loss:0.058821478274669436\n",
      "train loss:0.06044422723707379\n",
      "train loss:0.010837564792941526\n",
      "train loss:0.03251895633451124\n",
      "train loss:0.015514040921927567\n",
      "train loss:0.015419528397856763\n",
      "train loss:0.07829876259422433\n",
      "train loss:0.03430109776948933\n",
      "train loss:0.021644222594716496\n",
      "train loss:0.012139752006770468\n",
      "train loss:0.022271984478975475\n",
      "train loss:0.01947034557457409\n",
      "train loss:0.050444340519937604\n",
      "train loss:0.002656186651962687\n",
      "train loss:0.009568483996748253\n",
      "train loss:0.017606183938927784\n",
      "train loss:0.09955551525113383\n",
      "train loss:0.021865076956715804\n",
      "train loss:0.009707252293783828\n",
      "train loss:0.00992866003518864\n",
      "train loss:0.05270505249477398\n",
      "train loss:0.052763184171373566\n",
      "train loss:0.016071524204614863\n",
      "train loss:0.009475691576287389\n",
      "train loss:0.01283185408049875\n",
      "train loss:0.009867062772783321\n",
      "train loss:0.0195020232259409\n",
      "train loss:0.006283149484823018\n",
      "train loss:0.007881971471569093\n",
      "train loss:0.09972130654610577\n",
      "train loss:0.027988395742697913\n",
      "train loss:0.005857908661138893\n",
      "train loss:0.03100415705453225\n",
      "train loss:0.013497895232154033\n",
      "train loss:0.009074685415733075\n",
      "train loss:0.06677383182898937\n",
      "train loss:0.012801920625351841\n",
      "train loss:0.021316130659569978\n",
      "train loss:0.011949267365056589\n",
      "train loss:0.0068446946884022745\n",
      "train loss:0.09955287918629488\n",
      "train loss:0.01946487587127773\n",
      "train loss:0.017637658001873096\n",
      "train loss:0.026243128586877003\n",
      "train loss:0.03037514751989773\n",
      "train loss:0.06387011042519258\n",
      "train loss:0.010965302718328787\n",
      "train loss:0.008153750691478369\n",
      "train loss:0.0047267212857133875\n",
      "train loss:0.014142656755825555\n",
      "train loss:0.017142535905687137\n",
      "train loss:0.021782424566614375\n",
      "train loss:0.03387519707050933\n",
      "train loss:0.002577023411681364\n",
      "train loss:0.025108855831358093\n",
      "train loss:0.008001223445115408\n",
      "train loss:0.03073354818678328\n",
      "train loss:0.0066960219068236\n",
      "train loss:0.07394823070589587\n",
      "train loss:0.013602003979415054\n",
      "train loss:0.016328964923723342\n",
      "train loss:0.026300829174327998\n",
      "train loss:0.03313776183978208\n",
      "train loss:0.010874300165333634\n",
      "train loss:0.007227749967562219\n",
      "train loss:0.03647729939669537\n",
      "train loss:0.0058178373536510375\n",
      "train loss:0.015800969147784238\n",
      "train loss:0.010558616193926467\n",
      "train loss:0.017606126590601158\n",
      "train loss:0.022420910786544335\n",
      "train loss:0.008935272624214853\n",
      "train loss:0.016027077452521566\n",
      "train loss:0.004763142758915073\n",
      "train loss:0.09499459179854125\n",
      "train loss:0.008486332672658903\n",
      "train loss:0.06290408460240107\n",
      "train loss:0.016419807477825135\n",
      "train loss:0.015248943580014395\n",
      "train loss:0.02150785344683174\n",
      "train loss:0.005906820149427243\n",
      "train loss:0.017968748130437428\n",
      "train loss:0.009448528581492147\n",
      "train loss:0.008287457613625634\n",
      "train loss:0.01717727872961374\n",
      "train loss:0.08851936434606854\n",
      "train loss:0.012473362517035626\n",
      "train loss:0.008820366529996503\n",
      "train loss:0.07224889918592975\n",
      "train loss:0.045582695266862185\n",
      "train loss:0.011207037790083361\n",
      "train loss:0.009545905263426217\n",
      "train loss:0.035497107801433\n",
      "train loss:0.009818910275260242\n",
      "train loss:0.06540173231031408\n",
      "train loss:0.05352293084094491\n",
      "train loss:0.09348563562554865\n",
      "train loss:0.021544877939598757\n",
      "train loss:0.00921605846029861\n",
      "train loss:0.005975909397298229\n",
      "train loss:0.05775803114263713\n",
      "train loss:0.008772431024598508\n",
      "train loss:0.016087227133765286\n",
      "train loss:0.028778092659323157\n",
      "train loss:0.05655148706996951\n",
      "train loss:0.029137806323022285\n",
      "train loss:0.01147208461874649\n",
      "train loss:0.08094034404359877\n",
      "train loss:0.07797095124070924\n",
      "train loss:0.004069520179314107\n",
      "train loss:0.013456192812129444\n",
      "train loss:0.042992304290833054\n",
      "train loss:0.05664665725399264\n",
      "train loss:0.006799241664608647\n",
      "train loss:0.009443330872892291\n",
      "train loss:0.02257774726461262\n",
      "train loss:0.020274440647575477\n",
      "train loss:0.03125033952662213\n",
      "train loss:0.00941225858323044\n",
      "train loss:0.025153030985602093\n",
      "train loss:0.015830602955978525\n",
      "train loss:0.01684996698342596\n",
      "train loss:0.014771997055592621\n",
      "train loss:0.04730092094458502\n",
      "train loss:0.005021111978552209\n",
      "train loss:0.013154590354262762\n",
      "train loss:0.03537253596974197\n",
      "train loss:0.018862679515495015\n",
      "train loss:0.006544301990834735\n",
      "train loss:0.005480035128671992\n",
      "train loss:0.032421588851202346\n",
      "train loss:0.01034324251856477\n",
      "train loss:0.011752643183494458\n",
      "train loss:0.03877519279407591\n",
      "train loss:0.05506580974458591\n",
      "train loss:0.012733020368165326\n",
      "train loss:0.005864712809279188\n",
      "train loss:0.02354907388495853\n",
      "train loss:0.011462936603441148\n",
      "train loss:0.012965164021639577\n",
      "train loss:0.00847687634934453\n",
      "train loss:0.0045843652484346\n",
      "train loss:0.016755042167191318\n",
      "train loss:0.02181346622810151\n",
      "train loss:0.008646463265809656\n",
      "train loss:0.011931396028428305\n",
      "train loss:0.027833090592385784\n",
      "train loss:0.016739710235092718\n",
      "train loss:0.03492047556631852\n",
      "train loss:0.015432860766755221\n",
      "train loss:0.05723567651428601\n",
      "train loss:0.005889072612747054\n",
      "train loss:0.056846153503386045\n",
      "train loss:0.008250688375992936\n",
      "train loss:0.11201483426659521\n",
      "train loss:0.00876023755216212\n",
      "train loss:0.02694811262389667\n",
      "=== epoch:7, train acc:0.987, test acc:0.99 ===\n",
      "train loss:0.010010296750130723\n",
      "train loss:0.012331719141092363\n",
      "train loss:0.008007292385678346\n",
      "train loss:0.02418730216431883\n",
      "train loss:0.015925333107553525\n",
      "train loss:0.010845977291127016\n",
      "train loss:0.009475158860337656\n",
      "train loss:0.006752115509948261\n",
      "train loss:0.00822441204669147\n",
      "train loss:0.061186344712787735\n",
      "train loss:0.003354548412810336\n",
      "train loss:0.048001548292205654\n",
      "train loss:0.015384510055369213\n",
      "train loss:0.007852160621671581\n",
      "train loss:0.013156370860073199\n",
      "train loss:0.009479527909807476\n",
      "train loss:0.0089938439897766\n",
      "train loss:0.014852855627166173\n",
      "train loss:0.01293889845201681\n",
      "train loss:0.004489493835641919\n",
      "train loss:0.014534178986646249\n",
      "train loss:0.04610596455430768\n",
      "train loss:0.0181850894348847\n",
      "train loss:0.03585517980450021\n",
      "train loss:0.011734231195050723\n",
      "train loss:0.06215658031125546\n",
      "train loss:0.05591087200040988\n",
      "train loss:0.013823728296133726\n",
      "train loss:0.03818629568735199\n",
      "train loss:0.01144789667134969\n",
      "train loss:0.02997095340947981\n",
      "train loss:0.00676053409225669\n",
      "train loss:0.01235326800005209\n",
      "train loss:0.056234217910243904\n",
      "train loss:0.014953539948224896\n",
      "train loss:0.014565951375736583\n",
      "train loss:0.04097715233443502\n",
      "train loss:0.019347618914387556\n",
      "train loss:0.005681687924729071\n",
      "train loss:0.010753952930899223\n",
      "train loss:0.06547079126091729\n",
      "train loss:0.032522327869250474\n",
      "train loss:0.013237904849877542\n",
      "train loss:0.0141357908425604\n",
      "train loss:0.012691183992718577\n",
      "train loss:0.014207091269671289\n",
      "train loss:0.02164511687143768\n",
      "train loss:0.0366424890289299\n",
      "train loss:0.004646470533843997\n",
      "train loss:0.045121338198371476\n",
      "train loss:0.020951791068599377\n",
      "train loss:0.018975435702363888\n",
      "train loss:0.014959473180889093\n",
      "train loss:0.0034154821992759695\n",
      "train loss:0.005368307666782492\n",
      "train loss:0.0224889692541723\n",
      "train loss:0.032508863244197585\n",
      "train loss:0.02614109681860832\n",
      "train loss:0.009821895422015059\n",
      "train loss:0.022368247962144566\n",
      "train loss:0.022423397534723465\n",
      "train loss:0.01093161921785332\n",
      "train loss:0.04848101947232282\n",
      "train loss:0.02736611653283004\n",
      "train loss:0.010377308952172086\n",
      "train loss:0.0059574919828829466\n",
      "train loss:0.04972081688779133\n",
      "train loss:0.016328562731727253\n",
      "train loss:0.023636289943373003\n",
      "train loss:0.00873427854135306\n",
      "train loss:0.0174326556714108\n",
      "train loss:0.09123653624142998\n",
      "train loss:0.013832405835558982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008537440807892684\n",
      "train loss:0.022258469654176567\n",
      "train loss:0.010481512551341186\n",
      "train loss:0.015157811626670244\n",
      "train loss:0.006446205339012867\n",
      "train loss:0.01488991483920766\n",
      "train loss:0.006449290888147926\n",
      "train loss:0.033879722920204886\n",
      "train loss:0.015363075261584971\n",
      "train loss:0.009343000103798219\n",
      "train loss:0.016995895927664005\n",
      "train loss:0.025323068787388454\n",
      "train loss:0.0041431200900520805\n",
      "train loss:0.01888725799606867\n",
      "train loss:0.04055119431441051\n",
      "train loss:0.02113165718610845\n",
      "train loss:0.006675406990028176\n",
      "train loss:0.02162927213232594\n",
      "train loss:0.0019811744960032576\n",
      "train loss:0.01939801234428952\n",
      "train loss:0.017089456712380977\n",
      "train loss:0.010298425450565838\n",
      "train loss:0.0050666140499223125\n",
      "train loss:0.03730655271273973\n",
      "train loss:0.036511803473120684\n",
      "train loss:0.0075752045705676455\n",
      "train loss:0.05833331756703014\n",
      "train loss:0.047301734944399196\n",
      "train loss:0.07297217134487925\n",
      "train loss:0.01753471256894435\n",
      "train loss:0.04888731048128104\n",
      "train loss:0.006366740087756736\n",
      "train loss:0.013723447673469034\n",
      "train loss:0.003022615078523779\n",
      "train loss:0.006371745207634726\n",
      "train loss:0.008245173497734607\n",
      "train loss:0.02863998771180739\n",
      "train loss:0.027314235567505472\n",
      "train loss:0.036395336677428995\n",
      "train loss:0.004208451807161754\n",
      "train loss:0.04488805534671334\n",
      "train loss:0.04698656371897716\n",
      "train loss:0.00909975419421144\n",
      "train loss:0.06339613299997932\n",
      "train loss:0.005678315740852591\n",
      "train loss:0.015381713247006334\n",
      "train loss:0.028944917268143903\n",
      "train loss:0.010446377530420803\n",
      "train loss:0.009561523747198342\n",
      "train loss:0.04884305817007293\n",
      "train loss:0.003175379352623149\n",
      "train loss:0.012108515784484858\n",
      "train loss:0.05670411265168682\n",
      "train loss:0.019181226957931827\n",
      "train loss:0.018242520355051424\n",
      "train loss:0.008262577073609868\n",
      "train loss:0.004182951604319951\n",
      "train loss:0.012887281293868534\n",
      "train loss:0.0034660840098177516\n",
      "train loss:0.01612922042771762\n",
      "train loss:0.008526509713113556\n",
      "train loss:0.014549307872724692\n",
      "train loss:0.03833377537577684\n",
      "train loss:0.018207674552838494\n",
      "train loss:0.008317393967531908\n",
      "train loss:0.013966415794820714\n",
      "train loss:0.009278639321282941\n",
      "train loss:0.04892336441974333\n",
      "train loss:0.034984317816465445\n",
      "train loss:0.007385946013481018\n",
      "train loss:0.016083755053020368\n",
      "train loss:0.004599021278567687\n",
      "train loss:0.024189207851284276\n",
      "train loss:0.008067605063073906\n",
      "train loss:0.0016293793278262026\n",
      "train loss:0.018776634504362094\n",
      "train loss:0.013686020823876394\n",
      "train loss:0.017934488925015896\n",
      "train loss:0.004955505197519059\n",
      "train loss:0.026555396639402824\n",
      "train loss:0.06416598555366722\n",
      "train loss:0.047492596662642085\n",
      "train loss:0.01684501845890429\n",
      "train loss:0.005374868585093361\n",
      "train loss:0.01630767366931931\n",
      "train loss:0.008516854834575023\n",
      "train loss:0.006790297777645305\n",
      "train loss:0.020018755200387418\n",
      "train loss:0.01938325427307678\n",
      "train loss:0.08381322278038843\n",
      "train loss:0.00960932316817337\n",
      "train loss:0.03168567986955154\n",
      "train loss:0.019158326626118594\n",
      "train loss:0.022547266242590708\n",
      "train loss:0.006314842942197318\n",
      "train loss:0.026303473381074142\n",
      "train loss:0.01408382489090083\n",
      "train loss:0.0032904479295843116\n",
      "train loss:0.015221160582816579\n",
      "train loss:0.008742898453241716\n",
      "train loss:0.00869959896018373\n",
      "train loss:0.008373923832222612\n",
      "train loss:0.011564240775750063\n",
      "train loss:0.016181127251289496\n",
      "train loss:0.015870190112988788\n",
      "train loss:0.014922110782954676\n",
      "train loss:0.08621303700924737\n",
      "train loss:0.08639939827477452\n",
      "train loss:0.09936654021371703\n",
      "train loss:0.009435294860222381\n",
      "train loss:0.02358786645817014\n",
      "train loss:0.018135333028593915\n",
      "train loss:0.08947352776540499\n",
      "train loss:0.0376788816014886\n",
      "train loss:0.007562863222500362\n",
      "train loss:0.010315953641138942\n",
      "train loss:0.0050542736193160956\n",
      "train loss:0.10428979890381379\n",
      "train loss:0.05735891667965957\n",
      "train loss:0.042706937669026494\n",
      "train loss:0.005334871752972819\n",
      "train loss:0.011124102352716199\n",
      "train loss:0.011364913649454278\n",
      "train loss:0.09002460311136343\n",
      "train loss:0.024299456436954456\n",
      "train loss:0.11152092751420857\n",
      "train loss:0.049620212938931624\n",
      "train loss:0.025132615121186395\n",
      "train loss:0.0146497500927885\n",
      "train loss:0.013956246931597256\n",
      "train loss:0.043487238352731\n",
      "train loss:0.0030856407144817448\n",
      "train loss:0.013010726303385022\n",
      "train loss:0.007319811728758816\n",
      "train loss:0.011497627715432028\n",
      "train loss:0.025138688331696985\n",
      "train loss:0.013199791134362688\n",
      "train loss:0.019140362824906786\n",
      "train loss:0.02910947169253435\n",
      "train loss:0.01464901986544795\n",
      "train loss:0.006468210131750906\n",
      "train loss:0.022072710888455634\n",
      "train loss:0.023086208972833935\n",
      "train loss:0.0638077936051052\n",
      "train loss:0.002754570704834613\n",
      "train loss:0.005536542856934171\n",
      "train loss:0.007927666436316608\n",
      "train loss:0.040615753877782164\n",
      "train loss:0.04856350986418944\n",
      "train loss:0.012856192896008017\n",
      "train loss:0.046974642740995096\n",
      "train loss:0.005634004912421384\n",
      "train loss:0.013576608753971812\n",
      "train loss:0.04053112764870792\n",
      "train loss:0.012094022249443585\n",
      "train loss:0.01601195205910836\n",
      "train loss:0.018438185595406817\n",
      "train loss:0.009929711816066899\n",
      "train loss:0.005210104524464934\n",
      "train loss:0.008290342281048248\n",
      "train loss:0.028228808248346827\n",
      "train loss:0.010947808350766964\n",
      "train loss:0.023680197382358194\n",
      "train loss:0.014524545798552436\n",
      "train loss:0.009250844594154007\n",
      "train loss:0.02854920983936262\n",
      "train loss:0.027374357259522232\n",
      "train loss:0.004660249734842064\n",
      "train loss:0.005938685017841893\n",
      "train loss:0.012196655691881211\n",
      "train loss:0.011451716274827647\n",
      "train loss:0.015868280753658776\n",
      "train loss:0.014822534169682227\n",
      "train loss:0.04081807511931394\n",
      "train loss:0.005194879411858018\n",
      "train loss:0.017749397455904307\n",
      "train loss:0.03950857819673033\n",
      "train loss:0.03944724877436257\n",
      "train loss:0.018913667362823704\n",
      "train loss:0.006953938572766672\n",
      "train loss:0.06444551095701036\n",
      "train loss:0.018511820897490018\n",
      "train loss:0.00792600201105409\n",
      "train loss:0.006401015762975424\n",
      "train loss:0.0054164983019958255\n",
      "train loss:0.011262864780105426\n",
      "train loss:0.022345125742743607\n",
      "train loss:0.004396731645213194\n",
      "train loss:0.01041279497425783\n",
      "train loss:0.043076348478503695\n",
      "train loss:0.0176148179867134\n",
      "train loss:0.04534081507674956\n",
      "train loss:0.005571347965434609\n",
      "train loss:0.0813723832471283\n",
      "train loss:0.03200089845680119\n",
      "train loss:0.0055018303776147755\n",
      "train loss:0.011589216009944165\n",
      "train loss:0.03655076189593833\n",
      "train loss:0.01727502285963409\n",
      "train loss:0.023750559127739834\n",
      "train loss:0.03005959220587391\n",
      "train loss:0.022962434059822727\n",
      "train loss:0.00484415578584029\n",
      "train loss:0.03877724443981581\n",
      "train loss:0.010087256477321602\n",
      "train loss:0.0077799825239069755\n",
      "train loss:0.007264636294379082\n",
      "train loss:0.00514948553972412\n",
      "train loss:0.005523361839721522\n",
      "train loss:0.019388644320543953\n",
      "train loss:0.03267602468725965\n",
      "train loss:0.0016475247533287696\n",
      "train loss:0.028918228985220853\n",
      "train loss:0.04621410564532657\n",
      "train loss:0.004610538464231789\n",
      "train loss:0.013942824766418687\n",
      "train loss:0.03442158280410626\n",
      "train loss:0.01455961228697249\n",
      "train loss:0.0036711821396842137\n",
      "train loss:0.0027495068354738634\n",
      "train loss:0.018340629204778403\n",
      "train loss:0.023941261107651494\n",
      "train loss:0.013011542812292397\n",
      "train loss:0.004973834395414152\n",
      "train loss:0.008417019592417667\n",
      "train loss:0.0463383087998369\n",
      "train loss:0.031372426523417075\n",
      "train loss:0.008194207310629403\n",
      "train loss:0.024976949874678547\n",
      "train loss:0.009320679704986578\n",
      "train loss:0.018454074115575127\n",
      "train loss:0.02407056738855763\n",
      "train loss:0.05551363626324376\n",
      "train loss:0.004952497394629204\n",
      "train loss:0.06018594320979234\n",
      "train loss:0.0637243685233009\n",
      "train loss:0.005793287258972027\n",
      "train loss:0.07005776243768341\n",
      "train loss:0.015644357512763798\n",
      "train loss:0.08705657377372292\n",
      "train loss:0.02044348002893795\n",
      "train loss:0.008544058132278175\n",
      "train loss:0.011158488569671778\n",
      "train loss:0.002301354574326461\n",
      "train loss:0.02356903536576833\n",
      "train loss:0.04072356339296407\n",
      "train loss:0.01616055114480591\n",
      "train loss:0.009510569419700497\n",
      "train loss:0.05511673166508937\n",
      "train loss:0.019399795553062357\n",
      "train loss:0.02121984464506908\n",
      "train loss:0.009549044410853445\n",
      "train loss:0.0025671712595263774\n",
      "train loss:0.0038000498966947716\n",
      "train loss:0.02478609488902249\n",
      "train loss:0.00507184776225043\n",
      "train loss:0.003112277271309939\n",
      "train loss:0.039809014401519224\n",
      "train loss:0.015110238059537994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0033014001981459505\n",
      "train loss:0.046239410810120674\n",
      "train loss:0.005609015855959774\n",
      "train loss:0.027161082938990805\n",
      "train loss:0.017424648166773804\n",
      "train loss:0.040474366999662115\n",
      "train loss:0.08012740361989859\n",
      "train loss:0.05675028286828052\n",
      "train loss:0.0036225886135377422\n",
      "train loss:0.02779015142852475\n",
      "train loss:0.04220653646023646\n",
      "train loss:0.03757829077056926\n",
      "train loss:0.05060959231062712\n",
      "train loss:0.04377145002981773\n",
      "train loss:0.015028888091532591\n",
      "train loss:0.008742000977610572\n",
      "train loss:0.034225878666777114\n",
      "train loss:0.050245463279041384\n",
      "train loss:0.010141077940203311\n",
      "train loss:0.020829337796771576\n",
      "train loss:0.05049955440639704\n",
      "train loss:0.022034173927581363\n",
      "train loss:0.006325118361080426\n",
      "train loss:0.009834545590623037\n",
      "train loss:0.013218488249622701\n",
      "train loss:0.031125020753136542\n",
      "train loss:0.06595076148499635\n",
      "train loss:0.014555276633420138\n",
      "train loss:0.011492355023718474\n",
      "train loss:0.019614110216567508\n",
      "train loss:0.015129484546482377\n",
      "train loss:0.00860640585851946\n",
      "train loss:0.011662252632419346\n",
      "train loss:0.0327733806320422\n",
      "train loss:0.010013607359807499\n",
      "train loss:0.012570098958300807\n",
      "train loss:0.03151077124977095\n",
      "train loss:0.030992052958804264\n",
      "train loss:0.013195784924949628\n",
      "train loss:0.024291911718381215\n",
      "train loss:0.022742229742327473\n",
      "train loss:0.07237855815764624\n",
      "train loss:0.027964132732597874\n",
      "train loss:0.009810212527824044\n",
      "train loss:0.015856604222656622\n",
      "train loss:0.009064909524222276\n",
      "train loss:0.008017856429955401\n",
      "train loss:0.02479828225438698\n",
      "train loss:0.014227995137583944\n",
      "train loss:0.015896412273105842\n",
      "train loss:0.011141020433880669\n",
      "train loss:0.048198273609345456\n",
      "train loss:0.049769298214716304\n",
      "train loss:0.0025822284132269906\n",
      "train loss:0.030478137924384145\n",
      "train loss:0.013971751742241842\n",
      "train loss:0.007333611973916004\n",
      "train loss:0.04101346622771792\n",
      "train loss:0.025052688693501128\n",
      "train loss:0.016487322612132396\n",
      "train loss:0.006020665047798735\n",
      "train loss:0.018370071349088534\n",
      "train loss:0.018997335646241363\n",
      "train loss:0.01916755683095673\n",
      "train loss:0.018161542074390878\n",
      "train loss:0.06989508182339799\n",
      "train loss:0.005398830522521986\n",
      "train loss:0.02950794966092128\n",
      "train loss:0.02657538585640801\n",
      "train loss:0.004620423300280681\n",
      "train loss:0.005116290741319143\n",
      "train loss:0.027466632047516853\n",
      "train loss:0.05124936855187613\n",
      "train loss:0.01855682111156213\n",
      "train loss:0.013777086950364717\n",
      "train loss:0.08905606364757858\n",
      "train loss:0.025178330404271535\n",
      "train loss:0.022597437361883604\n",
      "train loss:0.0219175325766267\n",
      "train loss:0.00599799567745076\n",
      "train loss:0.010749350260652163\n",
      "train loss:0.008079860048902637\n",
      "train loss:0.017469444687626817\n",
      "train loss:0.019057295017123617\n",
      "train loss:0.009464773906977563\n",
      "train loss:0.017806533219733772\n",
      "train loss:0.007972863686228937\n",
      "train loss:0.015078413586988599\n",
      "train loss:0.02792739760065337\n",
      "train loss:0.005206690199774385\n",
      "train loss:0.028627005265184243\n",
      "train loss:0.06812399159311475\n",
      "train loss:0.03524448501274003\n",
      "train loss:0.015377548841330323\n",
      "train loss:0.003460744726010641\n",
      "train loss:0.00934728827373093\n",
      "train loss:0.00814328383945489\n",
      "train loss:0.0045442794570958985\n",
      "train loss:0.08931498129733706\n",
      "train loss:0.03167746928590632\n",
      "train loss:0.022191431112030785\n",
      "train loss:0.004779112820531816\n",
      "train loss:0.035672628665363276\n",
      "train loss:0.004173810266450153\n",
      "train loss:0.020834839633235472\n",
      "train loss:0.019253490381078125\n",
      "train loss:0.015821923812862633\n",
      "train loss:0.015330626633260595\n",
      "train loss:0.010008297446152345\n",
      "train loss:0.05095142923771901\n",
      "train loss:0.01150580640444205\n",
      "train loss:0.024910689532594156\n",
      "train loss:0.014856957687944405\n",
      "train loss:0.014903357580647337\n",
      "train loss:0.022946284471995836\n",
      "train loss:0.017399970157365545\n",
      "train loss:0.04508650730784166\n",
      "train loss:0.022699120196757162\n",
      "train loss:0.03255635374331765\n",
      "train loss:0.04936584664461693\n",
      "train loss:0.04234492168335441\n",
      "train loss:0.011991319834449227\n",
      "train loss:0.011174395960278511\n",
      "train loss:0.0058761783746573495\n",
      "train loss:0.015721440022674223\n",
      "train loss:0.0036360299412970948\n",
      "train loss:0.006067954750447187\n",
      "train loss:0.004666731316810872\n",
      "train loss:0.008148891772286193\n",
      "train loss:0.01163617954739543\n",
      "train loss:0.004371477095092969\n",
      "train loss:0.009123735171361757\n",
      "train loss:0.015908095140668977\n",
      "train loss:0.010816137576673102\n",
      "train loss:0.01158994658147441\n",
      "train loss:0.024706070351882183\n",
      "train loss:0.004624128097108107\n",
      "train loss:0.005426824155956174\n",
      "train loss:0.011721037553158736\n",
      "train loss:0.003980992529149287\n",
      "train loss:0.012663319920388829\n",
      "train loss:0.005075810901841529\n",
      "train loss:0.004435254458734127\n",
      "train loss:0.021934760657553592\n",
      "train loss:0.007580859328722311\n",
      "train loss:0.0027896755810972867\n",
      "train loss:0.017672369795580862\n",
      "train loss:0.033656601168909756\n",
      "train loss:0.00930416185615731\n",
      "train loss:0.050499866249992795\n",
      "train loss:0.00900412878046669\n",
      "train loss:0.012375996783379375\n",
      "train loss:0.004840500680209491\n",
      "train loss:0.052268678896164315\n",
      "train loss:0.012904408125969925\n",
      "train loss:0.005250947483330191\n",
      "train loss:0.03591908124565544\n",
      "train loss:0.04884910945180958\n",
      "train loss:0.02985040282725064\n",
      "train loss:0.0053383500090083014\n",
      "train loss:0.02929974100575299\n",
      "train loss:0.021196181905430905\n",
      "train loss:0.006982613630327563\n",
      "train loss:0.004522533897366764\n",
      "train loss:0.01445645313179024\n",
      "train loss:0.0204397482368638\n",
      "train loss:0.04473625022674379\n",
      "train loss:0.011130803996090248\n",
      "train loss:0.008966247975602075\n",
      "train loss:0.01744703505490222\n",
      "train loss:0.014511148768399177\n",
      "train loss:0.004488303344763497\n",
      "train loss:0.02125330030320852\n",
      "train loss:0.004038224296971253\n",
      "train loss:0.022254201854036308\n",
      "train loss:0.024472248024666063\n",
      "train loss:0.010995230735770025\n",
      "train loss:0.018489680526838536\n",
      "train loss:0.0029472662575716034\n",
      "train loss:0.003232658406720432\n",
      "train loss:0.018163411849975875\n",
      "train loss:0.07772539248226652\n",
      "train loss:0.003807701723559242\n",
      "train loss:0.019586396663806915\n",
      "train loss:0.024048470315517014\n",
      "train loss:0.021512758804063833\n",
      "train loss:0.021844867109059193\n",
      "train loss:0.008761606242453973\n",
      "train loss:0.15292396098412162\n",
      "train loss:0.01775674088477855\n",
      "train loss:0.038738730899506434\n",
      "train loss:0.017372727472002688\n",
      "train loss:0.008499595660196113\n",
      "train loss:0.02409146320756537\n",
      "train loss:0.02100988076319646\n",
      "train loss:0.06687240244037686\n",
      "train loss:0.002550628689884744\n",
      "train loss:0.01468122644640879\n",
      "train loss:0.012193968376540701\n",
      "train loss:0.01652190322264312\n",
      "train loss:0.009599615857402311\n",
      "train loss:0.005856051004141269\n",
      "train loss:0.06177379909682492\n",
      "train loss:0.027684362433652555\n",
      "train loss:0.02685125031715474\n",
      "train loss:0.007731094825494118\n",
      "train loss:0.002211492109005268\n",
      "train loss:0.008877029737876263\n",
      "train loss:0.0045565037379976\n",
      "train loss:0.006258148133941231\n",
      "train loss:0.007482636691851499\n",
      "train loss:0.007236724804734562\n",
      "train loss:0.0043118109049833445\n",
      "train loss:0.01521816174574957\n",
      "train loss:0.0031063786788387403\n",
      "train loss:0.011769604930235671\n",
      "train loss:0.04703502689134275\n",
      "train loss:0.01942029515544419\n",
      "train loss:0.0791829512217041\n",
      "train loss:0.05586760681091163\n",
      "train loss:0.013689159269905543\n",
      "train loss:0.02868290145814286\n",
      "train loss:0.0049351524822578595\n",
      "train loss:0.01875565490560995\n",
      "train loss:0.035781411645490764\n",
      "train loss:0.013102660339074486\n",
      "train loss:0.033370925317318945\n",
      "train loss:0.01480779054502898\n",
      "train loss:0.021466998105834495\n",
      "train loss:0.008419040192654815\n",
      "train loss:0.00311388604035198\n",
      "train loss:0.016389018007269857\n",
      "train loss:0.007157637082289755\n",
      "train loss:0.07043567539298894\n",
      "train loss:0.004864505750321266\n",
      "train loss:0.012663932887643298\n",
      "train loss:0.05230758611236294\n",
      "train loss:0.06371434362323888\n",
      "train loss:0.010860914276854339\n",
      "train loss:0.06898965383054145\n",
      "train loss:0.005512853520175228\n",
      "train loss:0.006225080509755592\n",
      "train loss:0.007542734538557616\n",
      "train loss:0.002220283851296924\n",
      "train loss:0.014667085677915647\n",
      "train loss:0.055006378605131766\n",
      "train loss:0.04530844568476034\n",
      "train loss:0.03337259988306579\n",
      "train loss:0.009973415734384263\n",
      "train loss:0.004457272877197976\n",
      "train loss:0.03729315313505825\n",
      "train loss:0.0018438550687944737\n",
      "train loss:0.03558889014159319\n",
      "train loss:0.003057548075408349\n",
      "train loss:0.027751206335132058\n",
      "train loss:0.01967908014156078\n",
      "train loss:0.01981336479250177\n",
      "train loss:0.0024007936703520395\n",
      "train loss:0.005182464284524742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008892548453437616\n",
      "train loss:0.002835207288630858\n",
      "train loss:0.008115202458826604\n",
      "train loss:0.03259136822237689\n",
      "train loss:0.004320238769128511\n",
      "train loss:0.02136431073287308\n",
      "train loss:0.0166467002720091\n",
      "train loss:0.013376277176860827\n",
      "train loss:0.04230534906038839\n",
      "=== epoch:8, train acc:0.99, test acc:0.988 ===\n",
      "train loss:0.02090787557972619\n",
      "train loss:0.012843562242863139\n",
      "train loss:0.07884486221991298\n",
      "train loss:0.008141351255428917\n",
      "train loss:0.058351361595167635\n",
      "train loss:0.017552883676229834\n",
      "train loss:0.00447177434938823\n",
      "train loss:0.011020918635378874\n",
      "train loss:0.017770720273642435\n",
      "train loss:0.02192175219996781\n",
      "train loss:0.01980318291717224\n",
      "train loss:0.02406605925954924\n",
      "train loss:0.008144315890573673\n",
      "train loss:0.004193551070182435\n",
      "train loss:0.0041534827671104325\n",
      "train loss:0.03942143813208231\n",
      "train loss:0.017456841819432273\n",
      "train loss:0.003970656139325539\n",
      "train loss:0.004686269643848769\n",
      "train loss:0.04044951968580692\n",
      "train loss:0.006459258246570613\n",
      "train loss:0.005059558770149981\n",
      "train loss:0.014114319244096058\n",
      "train loss:0.025553351917316607\n",
      "train loss:0.024762786822962735\n",
      "train loss:0.05197901823792897\n",
      "train loss:0.008442131075396691\n",
      "train loss:0.0022576846374707023\n",
      "train loss:0.03220835068906758\n",
      "train loss:0.004592880506976352\n",
      "train loss:0.07498395489833651\n",
      "train loss:0.006535021780617257\n",
      "train loss:0.013709691707960357\n",
      "train loss:0.02421997075059357\n",
      "train loss:0.02694059942322816\n",
      "train loss:0.012493985961779959\n",
      "train loss:0.01612174436682446\n",
      "train loss:0.011200708342533222\n",
      "train loss:0.021437092063965366\n",
      "train loss:0.016931459887105912\n",
      "train loss:0.005444603940666528\n",
      "train loss:0.019954462188004996\n",
      "train loss:0.03374484159195665\n",
      "train loss:0.0015955704592449718\n",
      "train loss:0.014793841822888095\n",
      "train loss:0.03538921879733807\n",
      "train loss:0.0013381006681258995\n",
      "train loss:0.04849216845688188\n",
      "train loss:0.006797598589301993\n",
      "train loss:0.07784102219401934\n",
      "train loss:0.015206505510914146\n",
      "train loss:0.011776035098034161\n",
      "train loss:0.02372432310912994\n",
      "train loss:0.021547804971275276\n",
      "train loss:0.010677517563869072\n",
      "train loss:0.018644368133404234\n",
      "train loss:0.005215996403019242\n",
      "train loss:0.012938245306063268\n",
      "train loss:0.011007877197753941\n",
      "train loss:0.02408899374004076\n",
      "train loss:0.006191326068102226\n",
      "train loss:0.058482699319154834\n",
      "train loss:0.011960701170769049\n",
      "train loss:0.04811856818879267\n",
      "train loss:0.0017330050482455518\n",
      "train loss:0.0060816059286428895\n",
      "train loss:0.030746171319257054\n",
      "train loss:0.019909852915637568\n",
      "train loss:0.0352441430853293\n",
      "train loss:0.0321870485758555\n",
      "train loss:0.01784302206511772\n",
      "train loss:0.02752738483076248\n",
      "train loss:0.034392498579532936\n",
      "train loss:0.03730828693905586\n",
      "train loss:0.031730658748091514\n",
      "train loss:0.015228072784752508\n",
      "train loss:0.018922807098776896\n",
      "train loss:0.0286027809301718\n",
      "train loss:0.0020993018148763743\n",
      "train loss:0.018343669543064493\n",
      "train loss:0.021713097371251364\n",
      "train loss:0.02649201095372968\n",
      "train loss:0.015792863674821037\n",
      "train loss:0.026648426479424038\n",
      "train loss:0.03807895868584858\n",
      "train loss:0.01388321377703909\n",
      "train loss:0.006214411501057429\n",
      "train loss:0.005015997620778503\n",
      "train loss:0.008001933718355819\n",
      "train loss:0.05858718136681599\n",
      "train loss:0.027301035589382808\n",
      "train loss:0.0037128783130376693\n",
      "train loss:0.07096345426585643\n",
      "train loss:0.05683517142625209\n",
      "train loss:0.02864205790083723\n",
      "train loss:0.005569626730217104\n",
      "train loss:0.02016743863818512\n",
      "train loss:0.015866622397696633\n",
      "train loss:0.012466580296380245\n",
      "train loss:0.03136855082636684\n",
      "train loss:0.007232399631043392\n",
      "train loss:0.010456541143336676\n",
      "train loss:0.013022375825722445\n",
      "train loss:0.020643200176596318\n",
      "train loss:0.004553683948451138\n",
      "train loss:0.0042708173996813485\n",
      "train loss:0.005061264295330152\n",
      "train loss:0.016688100172352883\n",
      "train loss:0.01096999777445387\n",
      "train loss:0.030884103684377374\n",
      "train loss:0.017797685783376028\n",
      "train loss:0.0021920946052591565\n",
      "train loss:0.012002570262409243\n",
      "train loss:0.005756649676081756\n",
      "train loss:0.016596908396052622\n",
      "train loss:0.014076183057157899\n",
      "train loss:0.004285286257366602\n",
      "train loss:0.04097599976373759\n",
      "train loss:0.009464627776488196\n",
      "train loss:0.03533539665932826\n",
      "train loss:0.003987866000429567\n",
      "train loss:0.004152279882689953\n",
      "train loss:0.00902595040683417\n",
      "train loss:0.012453138716320871\n",
      "train loss:0.002844262665881781\n",
      "train loss:0.03875256090798346\n",
      "train loss:0.004935457830115795\n",
      "train loss:0.011355063389169175\n",
      "train loss:0.007903123761636774\n",
      "train loss:0.03058422713368786\n",
      "train loss:0.0034631314388277653\n",
      "train loss:0.02752211049110393\n",
      "train loss:0.0024944279230918864\n",
      "train loss:0.0028442850045327333\n",
      "train loss:0.02109479812243709\n",
      "train loss:0.025951903191241396\n",
      "train loss:0.009844209674175262\n",
      "train loss:0.009942437907830727\n",
      "train loss:0.04638579053170771\n",
      "train loss:0.04049917086852387\n",
      "train loss:0.005735193468379564\n",
      "train loss:0.008873770874024215\n",
      "train loss:0.029901015707183932\n",
      "train loss:0.006867680222285807\n",
      "train loss:0.009658114173011777\n",
      "train loss:0.026785970028348937\n",
      "train loss:0.029685610392420226\n",
      "train loss:0.03758521767046618\n",
      "train loss:0.018910993621003833\n",
      "train loss:0.00963002902062134\n",
      "train loss:0.0028020319058623244\n",
      "train loss:0.004944697162904292\n",
      "train loss:0.002811224817781453\n",
      "train loss:0.008161574320480133\n",
      "train loss:0.007749836532813541\n",
      "train loss:0.02770652607696904\n",
      "train loss:0.007290136416460773\n",
      "train loss:0.01917877932300243\n",
      "train loss:0.013057186891848784\n",
      "train loss:0.0097652967284146\n",
      "train loss:0.011845288674576453\n",
      "train loss:0.004592790678676608\n",
      "train loss:0.034876386283271235\n",
      "train loss:0.027502345510081162\n",
      "train loss:0.01634133394031666\n",
      "train loss:0.02095310869996481\n",
      "train loss:0.011350334282737686\n",
      "train loss:0.006072931095165594\n",
      "train loss:0.010667316723921015\n",
      "train loss:0.02061468200464496\n",
      "train loss:0.009189888871212238\n",
      "train loss:0.03809182548075633\n",
      "train loss:0.0098631066743086\n",
      "train loss:0.05125080607434022\n",
      "train loss:0.021268920468417937\n",
      "train loss:0.012073451879816859\n",
      "train loss:0.004566396822130325\n",
      "train loss:0.010580251561303872\n",
      "train loss:0.00396147814423479\n",
      "train loss:0.17773046058103809\n",
      "train loss:0.01003585660791638\n",
      "train loss:0.002410135102884928\n",
      "train loss:0.001288544983974435\n",
      "train loss:0.028036059523283398\n",
      "train loss:0.014833785583107738\n",
      "train loss:0.00319302533309996\n",
      "train loss:0.010762971390558483\n",
      "train loss:0.0456891869998548\n",
      "train loss:0.006874004294331696\n",
      "train loss:0.0206528065559856\n",
      "train loss:0.023559913794228192\n",
      "train loss:0.009918451301530492\n",
      "train loss:0.009315317865233439\n",
      "train loss:0.0028570457754630977\n",
      "train loss:0.005619615067174788\n",
      "train loss:0.06746645511611568\n",
      "train loss:0.0017393180047775402\n",
      "train loss:0.021515735120888356\n",
      "train loss:0.008495313553462242\n",
      "train loss:0.011571219664220155\n",
      "train loss:0.012261431070336266\n",
      "train loss:0.006209069596987496\n",
      "train loss:0.01682025804681432\n",
      "train loss:0.08398312153396775\n",
      "train loss:0.019191112862876003\n",
      "train loss:0.002853121584592038\n",
      "train loss:0.012569292289125374\n",
      "train loss:0.0034850401903306957\n",
      "train loss:0.013444647232664425\n",
      "train loss:0.04963256006727678\n",
      "train loss:0.06395052623084586\n",
      "train loss:0.008765193905606839\n",
      "train loss:0.01868960224032583\n",
      "train loss:0.03687014623543365\n",
      "train loss:0.04896157018911364\n",
      "train loss:0.05547910536993524\n",
      "train loss:0.015175142749765797\n",
      "train loss:0.007856943828184608\n",
      "train loss:0.07168519068939448\n",
      "train loss:0.005271020708716909\n",
      "train loss:0.008563866656081031\n",
      "train loss:0.006043599584435216\n",
      "train loss:0.0032493799809536965\n",
      "train loss:0.021726296786768896\n",
      "train loss:0.0019101481065912698\n",
      "train loss:0.0035691911010853504\n",
      "train loss:0.015042650344613434\n",
      "train loss:0.01008582338012047\n",
      "train loss:0.0036578777313578488\n",
      "train loss:0.06530246631406794\n",
      "train loss:0.010179064311438788\n",
      "train loss:0.02210705135280568\n",
      "train loss:0.008635236003870674\n",
      "train loss:0.009234851742138726\n",
      "train loss:0.018041855058578457\n",
      "train loss:0.012761942664528228\n",
      "train loss:0.0064290033620429225\n",
      "train loss:0.006169917774950684\n",
      "train loss:0.013299816190172458\n",
      "train loss:0.0017377338923638577\n",
      "train loss:0.0019810317928592083\n",
      "train loss:0.008575523377843383\n",
      "train loss:0.0037131013839325467\n",
      "train loss:0.009241557893418663\n",
      "train loss:0.008262083141375297\n",
      "train loss:0.01449086941851838\n",
      "train loss:0.0026734698545595992\n",
      "train loss:0.0066120553655854356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009771844765370076\n",
      "train loss:0.005526231435675064\n",
      "train loss:0.0137920473154635\n",
      "train loss:0.017439149081708807\n",
      "train loss:0.058710621661009856\n",
      "train loss:0.002355028883163988\n",
      "train loss:0.0059481922688278364\n",
      "train loss:0.030119007758901355\n",
      "train loss:0.0023274945876743253\n",
      "train loss:0.007430630997893102\n",
      "train loss:0.004125277600430741\n",
      "train loss:0.01128619489758739\n",
      "train loss:0.018631389478026138\n",
      "train loss:0.035061467713853996\n",
      "train loss:0.0058236224864747855\n",
      "train loss:0.037203339063756224\n",
      "train loss:0.013263879009946342\n",
      "train loss:0.0052552968485977125\n",
      "train loss:0.013938152812766167\n",
      "train loss:0.07465580522370399\n",
      "train loss:0.0047142167270937795\n",
      "train loss:0.014280857780440843\n",
      "train loss:0.008964766704523619\n",
      "train loss:0.01140812440215286\n",
      "train loss:0.020391351597371456\n",
      "train loss:0.0047711994466884435\n",
      "train loss:0.02082741243732932\n",
      "train loss:0.012488150853543134\n",
      "train loss:0.01923305152279774\n",
      "train loss:0.03155496048249785\n",
      "train loss:0.005729654067132276\n",
      "train loss:0.03664456548909225\n",
      "train loss:0.00881517851010549\n",
      "train loss:0.011226977940464124\n",
      "train loss:0.00416570235540654\n",
      "train loss:0.02875127016772312\n",
      "train loss:0.0026263446968846863\n",
      "train loss:0.041546779985910554\n",
      "train loss:0.010166297055535076\n",
      "train loss:0.0017635873133247074\n",
      "train loss:0.03215187653277917\n",
      "train loss:0.005217952869882695\n",
      "train loss:0.05741073832187897\n",
      "train loss:0.02138396360970929\n",
      "train loss:0.033955121415929546\n",
      "train loss:0.008717896291310524\n",
      "train loss:0.005090201102834135\n",
      "train loss:0.01559516205038061\n",
      "train loss:0.01522778045150193\n",
      "train loss:0.003637195955010311\n",
      "train loss:0.05195563690877461\n",
      "train loss:0.019216160049889\n",
      "train loss:0.004010402850489358\n",
      "train loss:0.023571808273897096\n",
      "train loss:0.009725147948678984\n",
      "train loss:0.035070853409312985\n",
      "train loss:0.007181975606615578\n",
      "train loss:0.0022418803030686417\n",
      "train loss:0.004822260860524674\n",
      "train loss:0.014343813747646237\n",
      "train loss:0.011268146640649871\n",
      "train loss:0.0208028080057824\n",
      "train loss:0.008552218429154022\n",
      "train loss:0.058417582412422266\n",
      "train loss:0.09634877224987065\n",
      "train loss:0.034509890773531976\n",
      "train loss:0.025933502892366157\n",
      "train loss:0.0036498401341723686\n",
      "train loss:0.02006777243233131\n",
      "train loss:0.018162260511711187\n",
      "train loss:0.01326145922678774\n",
      "train loss:0.00970342825542117\n",
      "train loss:0.005314124916454199\n",
      "train loss:0.021430155688331537\n",
      "train loss:0.029219062582779037\n",
      "train loss:0.0034026744387271857\n",
      "train loss:0.006766034121774799\n",
      "train loss:0.023296026324482407\n",
      "train loss:0.011399014256427331\n",
      "train loss:0.004115543318677735\n",
      "train loss:0.04600539750922244\n",
      "train loss:0.02874694012223075\n",
      "train loss:0.005255934140771561\n",
      "train loss:0.03609958293249102\n",
      "train loss:0.006363763602354302\n",
      "train loss:0.0028487392436815297\n",
      "train loss:0.011808364294930509\n",
      "train loss:0.011073739844721266\n",
      "train loss:0.005194097669503308\n",
      "train loss:0.011305926714706654\n",
      "train loss:0.009628038224499097\n",
      "train loss:0.034708096430361865\n",
      "train loss:0.0020210493182633033\n",
      "train loss:0.023653662268699062\n",
      "train loss:0.004862583940527557\n",
      "train loss:0.014681326236506795\n",
      "train loss:0.008861972886281677\n",
      "train loss:0.00930901956123737\n",
      "train loss:0.009942021663539241\n",
      "train loss:0.0038793424431977385\n",
      "train loss:0.00357367838925379\n",
      "train loss:0.01182209449127303\n",
      "train loss:0.0014517363133166794\n",
      "train loss:0.060296551917993796\n",
      "train loss:0.005615813946581817\n",
      "train loss:0.00839626927888403\n",
      "train loss:0.005325933967672813\n",
      "train loss:0.005880114301468615\n",
      "train loss:0.0038387109819140717\n",
      "train loss:0.012238350024127853\n",
      "train loss:0.006914679872685518\n",
      "train loss:0.0018891380732499589\n",
      "train loss:0.007083203559116853\n",
      "train loss:0.006448462821553846\n",
      "train loss:0.009442859309794696\n",
      "train loss:0.017964621044418188\n",
      "train loss:0.012063433538738457\n",
      "train loss:0.0021119529599964854\n",
      "train loss:0.020629701316637238\n",
      "train loss:0.0013871378147855627\n",
      "train loss:0.022765968653939685\n",
      "train loss:0.05262142356997397\n",
      "train loss:0.0023313694405195963\n",
      "train loss:0.007448957319407717\n",
      "train loss:0.002343710345630932\n",
      "train loss:0.007855148348170103\n",
      "train loss:0.009851639269308427\n",
      "train loss:0.009322320419127311\n",
      "train loss:0.010532475714329064\n",
      "train loss:0.023960741386340616\n",
      "train loss:0.02420084460450371\n",
      "train loss:0.003683111896484179\n",
      "train loss:0.02638596710271385\n",
      "train loss:0.004880789525295786\n",
      "train loss:0.01550236776669662\n",
      "train loss:0.009098390751891894\n",
      "train loss:0.008435716290822187\n",
      "train loss:0.016545860728161416\n",
      "train loss:0.009131716164427674\n",
      "train loss:0.0340591558321408\n",
      "train loss:0.005931678675783341\n",
      "train loss:0.0052539275974331804\n",
      "train loss:0.006613487276829557\n",
      "train loss:0.02236077171680508\n",
      "train loss:0.0032429205851148774\n",
      "train loss:0.0035262665600032756\n",
      "train loss:0.0039024251678633436\n",
      "train loss:0.023346935237734713\n",
      "train loss:0.0578737840369302\n",
      "train loss:0.009966477631581667\n",
      "train loss:0.017613963594666108\n",
      "train loss:0.021065953916568\n",
      "train loss:0.0038257726137065373\n",
      "train loss:0.01015969718034752\n",
      "train loss:0.011856855128185392\n",
      "train loss:0.0036665579858052213\n",
      "train loss:0.0071503684116888955\n",
      "train loss:0.0008194512522211408\n",
      "train loss:0.02956258617445801\n",
      "train loss:0.012993870372787137\n",
      "train loss:0.0072888908022161955\n",
      "train loss:0.0033072326448867866\n",
      "train loss:0.037755376737513426\n",
      "train loss:0.03657335889489235\n",
      "train loss:0.005397438637735432\n",
      "train loss:0.010282148432980467\n",
      "train loss:0.005005414598960792\n",
      "train loss:0.018545257083177783\n",
      "train loss:0.005471162468518342\n",
      "train loss:0.0682364721116471\n",
      "train loss:0.005660638918000469\n",
      "train loss:0.0036883756330374005\n",
      "train loss:0.024677149502871712\n",
      "train loss:0.056995344887972935\n",
      "train loss:0.003248788543928531\n",
      "train loss:0.006590401402847394\n",
      "train loss:0.07681791902789081\n",
      "train loss:0.01949852186795893\n",
      "train loss:0.007303072253546784\n",
      "train loss:0.017730425455236246\n",
      "train loss:0.02890519541998381\n",
      "train loss:0.004429762423671303\n",
      "train loss:0.020468970646920007\n",
      "train loss:0.012784571728986236\n",
      "train loss:0.031099488477545685\n",
      "train loss:0.006214669208927524\n",
      "train loss:0.014210348752624365\n",
      "train loss:0.005430322142896764\n",
      "train loss:0.01154948010625984\n",
      "train loss:0.01437392340669192\n",
      "train loss:0.011899793544407313\n",
      "train loss:0.007452056620395772\n",
      "train loss:0.0035837336637082494\n",
      "train loss:0.03608997839193701\n",
      "train loss:0.004053098010334761\n",
      "train loss:0.004913819374559001\n",
      "train loss:0.008830273847315183\n",
      "train loss:0.0040636433533289525\n",
      "train loss:0.0038181286104910657\n",
      "train loss:0.05420102827788452\n",
      "train loss:0.0024460702048299905\n",
      "train loss:0.022300483426555995\n",
      "train loss:0.009244715459479136\n",
      "train loss:0.013458371365246606\n",
      "train loss:0.002148165332721309\n",
      "train loss:0.003184188015518125\n",
      "train loss:0.03316395614735848\n",
      "train loss:0.0069688312436629145\n",
      "train loss:0.00753824210190615\n",
      "train loss:0.001785685047532569\n",
      "train loss:0.005044250838758031\n",
      "train loss:0.015067185068309077\n",
      "train loss:0.007272277752332508\n",
      "train loss:0.0051931053199082014\n",
      "train loss:0.020655469304672037\n",
      "train loss:0.010854719476664691\n",
      "train loss:0.004660951539497091\n",
      "train loss:0.00576631311891864\n",
      "train loss:0.0172937001344973\n",
      "train loss:0.02454173362871288\n",
      "train loss:0.0033601679712981797\n",
      "train loss:0.00851826137181652\n",
      "train loss:0.02844877044365646\n",
      "train loss:0.07679033156429926\n",
      "train loss:0.06221499284459339\n",
      "train loss:0.010430112611832092\n",
      "train loss:0.01757661356765123\n",
      "train loss:0.006316611456826862\n",
      "train loss:0.013245115017272593\n",
      "train loss:0.012825985527570354\n",
      "train loss:0.004928874625003313\n",
      "train loss:0.022718885208904225\n",
      "train loss:0.010730997624680667\n",
      "train loss:0.025633875081276677\n",
      "train loss:0.005092014970746106\n",
      "train loss:0.010234026426194842\n",
      "train loss:0.0022096820299233196\n",
      "train loss:0.008236428933788736\n",
      "train loss:0.07657093185547292\n",
      "train loss:0.006024496441017363\n",
      "train loss:0.013458154330787939\n",
      "train loss:0.013240593751152628\n",
      "train loss:0.009518274179253362\n",
      "train loss:0.005182270440255119\n",
      "train loss:0.007667708332872954\n",
      "train loss:0.04468899313803969\n",
      "train loss:0.0033737533816427362\n",
      "train loss:0.008565958114817938\n",
      "train loss:0.0238908223823112\n",
      "train loss:0.04752107643475763\n",
      "train loss:0.010049233031088236\n",
      "train loss:0.029989072956408572\n",
      "train loss:0.018744540307233673\n",
      "train loss:0.020944821819462726\n",
      "train loss:0.05945676867900973\n",
      "train loss:0.008246395082483217\n",
      "train loss:0.007010811182145698\n",
      "train loss:0.0075292029975866145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03266711637798594\n",
      "train loss:0.0018064230466949183\n",
      "train loss:0.001819798558035892\n",
      "train loss:0.02319767615732036\n",
      "train loss:0.01318948677105488\n",
      "train loss:0.008581606804413366\n",
      "train loss:0.01270229796742895\n",
      "train loss:0.012515122680062387\n",
      "train loss:0.00801143542930126\n",
      "train loss:0.02291741853773631\n",
      "train loss:0.01267411240715371\n",
      "train loss:0.0043754889998899\n",
      "train loss:0.011023567507757084\n",
      "train loss:0.007142688493179465\n",
      "train loss:0.06370682414505739\n",
      "train loss:0.01190503651492284\n",
      "train loss:0.003935120359017339\n",
      "train loss:0.005181308735169964\n",
      "train loss:0.010997638021298406\n",
      "train loss:0.022260097662907326\n",
      "train loss:0.04084517158662015\n",
      "train loss:0.007253578228152908\n",
      "train loss:0.012852952797766047\n",
      "train loss:0.006629041583285522\n",
      "train loss:0.0168393254898591\n",
      "train loss:0.013800600115534243\n",
      "train loss:0.0072263929201426035\n",
      "train loss:0.0005830789499760156\n",
      "train loss:0.014413386242703174\n",
      "train loss:0.017775101535575613\n",
      "train loss:0.0020516890315463087\n",
      "train loss:0.009587555777782577\n",
      "train loss:0.030098097579303474\n",
      "train loss:0.002637763870731076\n",
      "train loss:0.013242594654635929\n",
      "train loss:0.005130624658403975\n",
      "train loss:0.013309455155324952\n",
      "train loss:0.04109709966798844\n",
      "train loss:0.003643880203502497\n",
      "train loss:0.029174513630549598\n",
      "train loss:0.01915043757802851\n",
      "train loss:0.0033246593838763454\n",
      "train loss:0.006534210330456227\n",
      "train loss:0.01338391458331051\n",
      "train loss:0.005261867211815163\n",
      "train loss:0.010991590822326026\n",
      "train loss:0.007838056169259599\n",
      "train loss:0.008573030772521919\n",
      "train loss:0.007036775431588249\n",
      "train loss:0.008694052400006584\n",
      "train loss:0.05852203034087878\n",
      "train loss:0.006588614927778009\n",
      "train loss:0.011772190149159107\n",
      "train loss:0.0025975978205832993\n",
      "train loss:0.01647679639223781\n",
      "train loss:0.012138929890235716\n",
      "train loss:0.010641629912067525\n",
      "train loss:0.024208941368689448\n",
      "train loss:0.004766755765958881\n",
      "train loss:0.007496907933119269\n",
      "train loss:0.026909162870056368\n",
      "train loss:0.028718879187008804\n",
      "train loss:0.005892967528367603\n",
      "train loss:0.014865083524327449\n",
      "train loss:0.020734613236396388\n",
      "train loss:0.0068879032372281155\n",
      "train loss:0.012442684605129206\n",
      "train loss:0.012545290141204734\n",
      "train loss:0.09107947095665357\n",
      "train loss:0.008966535208747694\n",
      "train loss:0.00340945055641976\n",
      "train loss:0.004060351087533699\n",
      "train loss:0.01567283222318865\n",
      "train loss:0.02872575417620257\n",
      "train loss:0.056907154416238344\n",
      "train loss:0.04744604679880822\n",
      "train loss:0.00820755437747383\n",
      "train loss:0.0049295125759048096\n",
      "train loss:0.025699118115843002\n",
      "train loss:0.002862599720247099\n",
      "train loss:0.01120073519440057\n",
      "train loss:0.003908077233610362\n",
      "train loss:0.0007310690927573879\n",
      "train loss:0.014202421633940978\n",
      "train loss:0.007063930021054464\n",
      "train loss:0.027520553202347788\n",
      "train loss:0.0031736602397928137\n",
      "train loss:0.04512992872280944\n",
      "train loss:0.007080404833869968\n",
      "train loss:0.005279522192535959\n",
      "train loss:0.020051764315844035\n",
      "train loss:0.013335729002704138\n",
      "train loss:0.04653484303205238\n",
      "train loss:0.0118443277299779\n",
      "=== epoch:9, train acc:0.993, test acc:0.987 ===\n",
      "train loss:0.00486180173387431\n",
      "train loss:0.004434871050431292\n",
      "train loss:0.0011554552898245564\n",
      "train loss:0.010089825094969574\n",
      "train loss:0.04412832712839023\n",
      "train loss:0.004544746901831429\n",
      "train loss:0.00930924165528899\n",
      "train loss:0.003431950361684874\n",
      "train loss:0.0039919898227228365\n",
      "train loss:0.001976157297131243\n",
      "train loss:0.0024165239117467873\n",
      "train loss:0.03107581705486743\n",
      "train loss:0.012189385831690628\n",
      "train loss:0.0022784999294716887\n",
      "train loss:0.001189867771655529\n",
      "train loss:0.01569597538866072\n",
      "train loss:0.012548119254924061\n",
      "train loss:0.007145652018364054\n",
      "train loss:0.005058214253365856\n",
      "train loss:0.02156358524512417\n",
      "train loss:0.012929718005535091\n",
      "train loss:0.0016857851334788315\n",
      "train loss:0.00780242449469299\n",
      "train loss:0.006170925151672709\n",
      "train loss:0.014095261205334058\n",
      "train loss:0.018150322549634487\n",
      "train loss:0.025931238933986377\n",
      "train loss:0.026108384824327983\n",
      "train loss:0.011882640321024974\n",
      "train loss:0.005326162465060112\n",
      "train loss:0.009694054965375523\n",
      "train loss:0.003330846928231132\n",
      "train loss:0.0043290246585748725\n",
      "train loss:0.0235254219317104\n",
      "train loss:0.005800206834921109\n",
      "train loss:0.005979735883369033\n",
      "train loss:0.0038537021232146846\n",
      "train loss:0.01150331633260504\n",
      "train loss:0.0018194682957357261\n",
      "train loss:0.0037157595622289317\n",
      "train loss:0.009396406967158197\n",
      "train loss:0.0026932533988309492\n",
      "train loss:0.005474319895987691\n",
      "train loss:0.0035815215363991402\n",
      "train loss:0.014727377335444587\n",
      "train loss:0.006129890670777344\n",
      "train loss:0.004768580966268682\n",
      "train loss:0.0035079446050510633\n",
      "train loss:0.003118775901255308\n",
      "train loss:0.017446324663985924\n",
      "train loss:0.0033953095386731113\n",
      "train loss:0.006018787718945325\n",
      "train loss:0.1621679619794356\n",
      "train loss:0.033611524313961715\n",
      "train loss:0.009126172550985794\n",
      "train loss:0.005960860620552715\n",
      "train loss:0.005668681283929195\n",
      "train loss:0.004169814920684954\n",
      "train loss:0.0026248666912366387\n",
      "train loss:0.04545860506738233\n",
      "train loss:0.01816880884948327\n",
      "train loss:0.019132404315002852\n",
      "train loss:0.007927006945245446\n",
      "train loss:0.027873423418968243\n",
      "train loss:0.01190728872564645\n",
      "train loss:0.011728552737930982\n",
      "train loss:0.005569340793111214\n",
      "train loss:0.054093515797922945\n",
      "train loss:0.005936081348805487\n",
      "train loss:0.00940244659563553\n",
      "train loss:0.012689950386685998\n",
      "train loss:0.0070596822615604906\n",
      "train loss:0.0047646340534054235\n",
      "train loss:0.005673077075942274\n",
      "train loss:0.029288087713294435\n",
      "train loss:0.0046917927685153635\n",
      "train loss:0.0009508248030281335\n",
      "train loss:0.003239423374995661\n",
      "train loss:0.00550150974830945\n",
      "train loss:0.017024359984425717\n",
      "train loss:0.005847556159522172\n",
      "train loss:0.02200606127711722\n",
      "train loss:0.0027813080419153346\n",
      "train loss:0.005542700413069918\n",
      "train loss:0.005809296678192667\n",
      "train loss:0.04462842357401889\n",
      "train loss:0.05109408343225672\n",
      "train loss:0.017312896631046425\n",
      "train loss:0.007522297471100539\n",
      "train loss:0.01241541061451176\n",
      "train loss:0.006811755301322006\n",
      "train loss:0.005600364003920266\n",
      "train loss:0.004039067669815666\n",
      "train loss:0.0048791753029470645\n",
      "train loss:0.01789490043580001\n",
      "train loss:0.012261747326193\n",
      "train loss:0.03534856688089923\n",
      "train loss:0.031305026057143526\n",
      "train loss:0.009270818657683233\n",
      "train loss:0.009723611048645655\n",
      "train loss:0.011353983367961708\n",
      "train loss:0.005689767978726266\n",
      "train loss:0.002039760006570817\n",
      "train loss:0.003976512803842997\n",
      "train loss:0.011165612076852209\n",
      "train loss:0.0007548032789264186\n",
      "train loss:0.008418822669532547\n",
      "train loss:0.02228475793169362\n",
      "train loss:0.00198978702464375\n",
      "train loss:0.001547176707112056\n",
      "train loss:0.006299552807565864\n",
      "train loss:0.00563592607723809\n",
      "train loss:0.006108804707625514\n",
      "train loss:0.020357311107902305\n",
      "train loss:0.002533681892510211\n",
      "train loss:0.059002679484699574\n",
      "train loss:0.015899594327592564\n",
      "train loss:0.023041977954053893\n",
      "train loss:0.004979377905595278\n",
      "train loss:0.007172323455327014\n",
      "train loss:0.003412081445198164\n",
      "train loss:0.007673012443559126\n",
      "train loss:0.013103240297592945\n",
      "train loss:0.003821716312171201\n",
      "train loss:0.00732376161950274\n",
      "train loss:0.005165947680317533\n",
      "train loss:0.0023861719518123324\n",
      "train loss:0.017484343693456413\n",
      "train loss:0.010206729087037457\n",
      "train loss:0.006498380757422496\n",
      "train loss:0.007782811003365431\n",
      "train loss:0.005304358723011673\n",
      "train loss:0.009910458929777237\n",
      "train loss:0.0074322956054626325\n",
      "train loss:0.013110620567526569\n",
      "train loss:0.054353044123926206\n",
      "train loss:0.005163572022234082\n",
      "train loss:0.0037907932537237644\n",
      "train loss:0.007317423077173684\n",
      "train loss:0.009860824796591916\n",
      "train loss:0.00864096708509193\n",
      "train loss:0.0037621954691680324\n",
      "train loss:0.012104206412601792\n",
      "train loss:0.022119478074606756\n",
      "train loss:0.004531770431264036\n",
      "train loss:0.0032355969982847377\n",
      "train loss:0.003725209282525296\n",
      "train loss:0.0136348495909943\n",
      "train loss:0.005729839871772217\n",
      "train loss:0.006661693171347985\n",
      "train loss:0.02868684999531454\n",
      "train loss:0.0044302542167962075\n",
      "train loss:0.006520475868959041\n",
      "train loss:0.022146545837953932\n",
      "train loss:0.003775784739583561\n",
      "train loss:0.0013046917197513323\n",
      "train loss:0.007738661861193815\n",
      "train loss:0.006024928581860557\n",
      "train loss:0.013183618974460376\n",
      "train loss:0.009771105162970082\n",
      "train loss:0.0016523815858352068\n",
      "train loss:0.005413063506520935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0061147473529795235\n",
      "train loss:0.0015691613887332686\n",
      "train loss:0.007911893647475535\n",
      "train loss:0.003041422522791806\n",
      "train loss:0.008896302969862093\n",
      "train loss:0.0022374581925001832\n",
      "train loss:0.0267761151799587\n",
      "train loss:0.004597362638647866\n",
      "train loss:0.010222786662378245\n",
      "train loss:0.07970272198766082\n",
      "train loss:0.004844338700364444\n",
      "train loss:0.0008036018171502137\n",
      "train loss:0.009110556289934561\n",
      "train loss:0.007343930761294912\n",
      "train loss:0.004343773600234412\n",
      "train loss:0.001929531093250286\n",
      "train loss:0.00593878623504408\n",
      "train loss:0.0020352063917954935\n",
      "train loss:0.007409136198739088\n",
      "train loss:0.005803887454363514\n",
      "train loss:0.025462576123710806\n",
      "train loss:0.006411921699489141\n",
      "train loss:0.0005491538616203566\n",
      "train loss:0.021355282620854003\n",
      "train loss:0.0059408239704400005\n",
      "train loss:0.0026274498416249104\n",
      "train loss:0.0022928104147805065\n",
      "train loss:0.011175753092893466\n",
      "train loss:0.008310235809196187\n",
      "train loss:0.002127887836613747\n",
      "train loss:0.001896317475363146\n",
      "train loss:0.013568990489969335\n",
      "train loss:0.00330459685093962\n",
      "train loss:0.0036096018786450214\n",
      "train loss:0.01759435453943819\n",
      "train loss:0.01941042440714033\n",
      "train loss:0.007984601134364467\n",
      "train loss:0.0035541829799787634\n",
      "train loss:0.008492188567687305\n",
      "train loss:0.00832912442541428\n",
      "train loss:0.006676942839204363\n",
      "train loss:0.0032800052347850524\n",
      "train loss:0.015396357339517332\n",
      "train loss:0.006797359970952821\n",
      "train loss:0.0638221049700165\n",
      "train loss:0.003945539032459189\n",
      "train loss:0.03254620516471989\n",
      "train loss:0.04273082626742384\n",
      "train loss:0.003081853823467533\n",
      "train loss:0.0028379531110415907\n",
      "train loss:0.004538242276002108\n",
      "train loss:0.0068722183802643185\n",
      "train loss:0.00450714665924325\n",
      "train loss:0.014599549578986355\n",
      "train loss:0.004576170564726079\n",
      "train loss:0.002194492674669144\n",
      "train loss:0.02221843700690001\n",
      "train loss:0.029021918354766692\n",
      "train loss:0.008048765141814091\n",
      "train loss:0.004546350455180807\n",
      "train loss:0.011388084607301611\n",
      "train loss:0.010851980910321477\n",
      "train loss:0.004458302981670891\n",
      "train loss:0.0011478873263861885\n",
      "train loss:0.0037079139488267986\n",
      "train loss:0.007166695977410319\n",
      "train loss:0.01087961254483171\n",
      "train loss:0.007045018182469983\n",
      "train loss:0.004649314143149453\n",
      "train loss:0.004795484791661472\n",
      "train loss:0.006169660490467901\n",
      "train loss:0.004045377931595701\n",
      "train loss:0.010060412026721019\n",
      "train loss:0.006843482977006337\n",
      "train loss:0.0011993419027959337\n",
      "train loss:0.0037130474591247843\n",
      "train loss:0.013452137097760641\n",
      "train loss:0.019319442954966053\n",
      "train loss:0.0070804196245955265\n",
      "train loss:0.0031037308132701768\n",
      "train loss:0.006631217650102042\n",
      "train loss:0.008903196922796185\n",
      "train loss:0.015318181335015888\n",
      "train loss:0.0024320456157657885\n",
      "train loss:0.0021749315154872524\n",
      "train loss:0.049147665852290974\n",
      "train loss:0.021682796560643775\n",
      "train loss:0.0018728869640821765\n",
      "train loss:0.005251450501873581\n",
      "train loss:0.005408365485486169\n",
      "train loss:0.021678748883241342\n",
      "train loss:0.04810540048394188\n",
      "train loss:0.0064745506354167495\n",
      "train loss:0.015400314704420319\n",
      "train loss:0.062282214525312934\n",
      "train loss:0.005659631042180868\n",
      "train loss:0.008069817412430718\n",
      "train loss:0.019491372084899258\n",
      "train loss:0.0018299394638698367\n",
      "train loss:0.0057817515289922084\n",
      "train loss:0.010968290672964906\n",
      "train loss:0.01186517386552158\n",
      "train loss:0.0036120024029123103\n",
      "train loss:0.007153999923837617\n",
      "train loss:0.021234567490118282\n",
      "train loss:0.031007889695986855\n",
      "train loss:0.004026106470139204\n",
      "train loss:0.023991005490355054\n",
      "train loss:0.010285381348364854\n",
      "train loss:0.0026297969598718537\n",
      "train loss:0.005334989284505931\n",
      "train loss:0.008033614166417137\n",
      "train loss:0.027799605637195492\n",
      "train loss:0.006105121010285488\n",
      "train loss:0.008998605698516286\n",
      "train loss:0.046201176513176845\n",
      "train loss:0.005069923555489099\n",
      "train loss:0.008460189110714287\n",
      "train loss:0.03401416247343101\n",
      "train loss:0.01329993592544377\n",
      "train loss:0.005108843551565156\n",
      "train loss:0.013710191613406591\n",
      "train loss:0.0011687273325040645\n",
      "train loss:0.04918933956767772\n",
      "train loss:0.003252211288040688\n",
      "train loss:0.013135377583157718\n",
      "train loss:0.018408536568200556\n",
      "train loss:0.006309153571336307\n",
      "train loss:0.025265753478679466\n",
      "train loss:0.007481296346351592\n",
      "train loss:0.0007082547724727292\n",
      "train loss:0.03858324938293265\n",
      "train loss:0.006945782667285332\n",
      "train loss:0.01012996757460758\n",
      "train loss:0.12786634172663155\n",
      "train loss:0.0027568731838761885\n",
      "train loss:0.0052305760135745024\n",
      "train loss:0.008613113329012004\n",
      "train loss:0.003129434241285533\n",
      "train loss:0.003577650256891379\n",
      "train loss:0.03375030414958007\n",
      "train loss:0.004602360442684637\n",
      "train loss:0.011577392903243156\n",
      "train loss:0.0066989449874101\n",
      "train loss:0.020846891337130784\n",
      "train loss:0.008584685548373732\n",
      "train loss:0.013734720982519075\n",
      "train loss:0.006276756512830823\n",
      "train loss:0.0014631406858932737\n",
      "train loss:0.06001774077240819\n",
      "train loss:0.01737853017187984\n",
      "train loss:0.007341152404705078\n",
      "train loss:0.0027084910291563947\n",
      "train loss:0.0016424562704794908\n",
      "train loss:0.012714615913863294\n",
      "train loss:0.00507659550407688\n",
      "train loss:0.009218767799970787\n",
      "train loss:0.023056880797232643\n",
      "train loss:0.007439084754778478\n",
      "train loss:0.016137717255587353\n",
      "train loss:0.005804908405640079\n",
      "train loss:0.0025160178943741335\n",
      "train loss:0.021521262033279313\n",
      "train loss:0.0029247052906590148\n",
      "train loss:0.017598094291712937\n",
      "train loss:0.00411726045057166\n",
      "train loss:0.004011618913790584\n",
      "train loss:0.013169484792022193\n",
      "train loss:0.08702573721309753\n",
      "train loss:0.0038990154069943623\n",
      "train loss:0.002784696204055317\n",
      "train loss:0.002756254151672761\n",
      "train loss:0.014465712739084195\n",
      "train loss:0.005175301399826212\n",
      "train loss:0.0064256832502465715\n",
      "train loss:0.008922170172064425\n",
      "train loss:0.00435589063016945\n",
      "train loss:0.040090527151172894\n",
      "train loss:0.003026720598609131\n",
      "train loss:0.009698979976740112\n",
      "train loss:0.007034610478102133\n",
      "train loss:0.0019639162544833953\n",
      "train loss:0.031855760771262204\n",
      "train loss:0.004972348190682543\n",
      "train loss:0.0038384688275826754\n",
      "train loss:0.020955895317268002\n",
      "train loss:0.03555994845574417\n",
      "train loss:0.019849717804447657\n",
      "train loss:0.009633014618739603\n",
      "train loss:0.02096402505392783\n",
      "train loss:0.001580604856300598\n",
      "train loss:0.0015631082289747037\n",
      "train loss:0.02326588205488387\n",
      "train loss:0.006485846516586607\n",
      "train loss:0.003758973768049365\n",
      "train loss:0.007771193130889793\n",
      "train loss:0.008930349534551907\n",
      "train loss:0.01155359311678338\n",
      "train loss:0.028923848167157606\n",
      "train loss:0.0028089915038396734\n",
      "train loss:0.011913110111642582\n",
      "train loss:0.07172971409348061\n",
      "train loss:0.0084880211820832\n",
      "train loss:0.0027612628236487334\n",
      "train loss:0.003135192539725017\n",
      "train loss:0.0023346728777969682\n",
      "train loss:0.021591631774923355\n",
      "train loss:0.006625308342031474\n",
      "train loss:0.011116327719779955\n",
      "train loss:0.01846107169554189\n",
      "train loss:0.004254616095779324\n",
      "train loss:0.018865730890113005\n",
      "train loss:0.0125601974537851\n",
      "train loss:0.01599119808609171\n",
      "train loss:0.007604601623465177\n",
      "train loss:0.013691937279808638\n",
      "train loss:0.034357590836977064\n",
      "train loss:0.0016221913983410924\n",
      "train loss:0.005041887021846172\n",
      "train loss:0.0015449015612039258\n",
      "train loss:0.007371914990724091\n",
      "train loss:0.014833938438347842\n",
      "train loss:0.00214155926042415\n",
      "train loss:0.021148747289260274\n",
      "train loss:0.0025993074966087198\n",
      "train loss:0.009701464964441105\n",
      "train loss:0.003247049148623146\n",
      "train loss:0.0010199620654818872\n",
      "train loss:0.014941402959864892\n",
      "train loss:0.032847334242921675\n",
      "train loss:0.0031274114733505286\n",
      "train loss:0.0038510041795304234\n",
      "train loss:0.0022391071760192805\n",
      "train loss:0.0050099207612757145\n",
      "train loss:0.0069757040016127925\n",
      "train loss:0.01319501512498745\n",
      "train loss:0.005515935714824382\n",
      "train loss:0.006505177587159227\n",
      "train loss:0.05257865471842127\n",
      "train loss:0.012019429910973925\n",
      "train loss:0.00458914474388247\n",
      "train loss:0.005474903305669163\n",
      "train loss:0.04724707183007449\n",
      "train loss:0.006125083653771606\n",
      "train loss:0.008515150240803356\n",
      "train loss:0.092441370299171\n",
      "train loss:0.016307345833302345\n",
      "train loss:0.023469051280321587\n",
      "train loss:0.03985224561200135\n",
      "train loss:0.00289245498844945\n",
      "train loss:0.008429941398337665\n",
      "train loss:0.051417644728098975\n",
      "train loss:0.013520185684916072\n",
      "train loss:0.0061793637197025885\n",
      "train loss:0.05649491949197566\n",
      "train loss:0.026702700646139606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002833275635742474\n",
      "train loss:0.005699274825470063\n",
      "train loss:0.006848485363711303\n",
      "train loss:0.009918103708223254\n",
      "train loss:0.017348541075889835\n",
      "train loss:0.014483125993861996\n",
      "train loss:0.01419158287623222\n",
      "train loss:0.006106496481538552\n",
      "train loss:0.014602241607129467\n",
      "train loss:0.014456320023929025\n",
      "train loss:0.00625897445715263\n",
      "train loss:0.005832768814244314\n",
      "train loss:0.0018567999241954265\n",
      "train loss:0.012087566774224021\n",
      "train loss:0.0692159876541099\n",
      "train loss:0.004046355413200684\n",
      "train loss:0.02004187839447122\n",
      "train loss:0.010133060237455652\n",
      "train loss:0.002903447652046036\n",
      "train loss:0.003535059776039304\n",
      "train loss:0.008126998140759229\n",
      "train loss:0.009893437667430343\n",
      "train loss:0.0027041513665193306\n",
      "train loss:0.0244423994590509\n",
      "train loss:0.013479345385775053\n",
      "train loss:0.007100067959311467\n",
      "train loss:0.004023962925722695\n",
      "train loss:0.020229915479677233\n",
      "train loss:0.009418842125612116\n",
      "train loss:0.012121341260070483\n",
      "train loss:0.013936935064488216\n",
      "train loss:0.012341415050704354\n",
      "train loss:0.008211831877105395\n",
      "train loss:0.0008334361324839965\n",
      "train loss:0.012669403907641166\n",
      "train loss:0.010004952687364682\n",
      "train loss:0.008248671835555952\n",
      "train loss:0.008204429364971158\n",
      "train loss:0.004754236845242179\n",
      "train loss:0.008885853072236083\n",
      "train loss:0.002870544726452997\n",
      "train loss:0.010436452518151364\n",
      "train loss:0.003742175518605643\n",
      "train loss:0.00873606270620111\n",
      "train loss:0.0012815491588123015\n",
      "train loss:0.044053614516927075\n",
      "train loss:0.009924116058825636\n",
      "train loss:0.0025671985785257444\n",
      "train loss:0.007241488623122279\n",
      "train loss:0.0017302521612077904\n",
      "train loss:0.011021454940037631\n",
      "train loss:0.005179589059050884\n",
      "train loss:0.004307455334453952\n",
      "train loss:0.006098409302761029\n",
      "train loss:0.002272306430752313\n",
      "train loss:0.011445700086160209\n",
      "train loss:0.01831225807450731\n",
      "train loss:0.0037456251068735975\n",
      "train loss:0.019122853551633054\n",
      "train loss:0.008523941616233993\n",
      "train loss:0.01291043004176776\n",
      "train loss:0.0067266112369573465\n",
      "train loss:0.0027453486854771693\n",
      "train loss:0.021655283437604624\n",
      "train loss:0.0015295350654816414\n",
      "train loss:0.002522325941742482\n",
      "train loss:0.01024528012049807\n",
      "train loss:0.004050098470136898\n",
      "train loss:0.003183452933256256\n",
      "train loss:0.002455063806970698\n",
      "train loss:0.008477062384200833\n",
      "train loss:0.0046999738887265295\n",
      "train loss:0.10901850116364796\n",
      "train loss:0.014864740789458888\n",
      "train loss:0.007534577721289372\n",
      "train loss:0.006612543640516453\n",
      "train loss:0.011069673255807407\n",
      "train loss:0.01936869657975262\n",
      "train loss:0.01454335932306693\n",
      "train loss:0.0042717405895585795\n",
      "train loss:0.006449464649240765\n",
      "train loss:0.005460873104235066\n",
      "train loss:0.009386747955338788\n",
      "train loss:0.004138414208515876\n",
      "train loss:0.004224341598601586\n",
      "train loss:0.013126449455636024\n",
      "train loss:0.036041453919393784\n",
      "train loss:0.007346601476505077\n",
      "train loss:0.0006579394760379834\n",
      "train loss:0.032599405233215\n",
      "train loss:0.0064703984338931545\n",
      "train loss:0.006982631064627198\n",
      "train loss:0.006089768777202873\n",
      "train loss:0.006840417695355026\n",
      "train loss:0.0027195030467437693\n",
      "train loss:0.010199797588146637\n",
      "train loss:0.023933582149767138\n",
      "train loss:0.015683033033059565\n",
      "train loss:0.007517757810823932\n",
      "train loss:0.007578298789006874\n",
      "train loss:0.004216493211835799\n",
      "train loss:0.01411240159650961\n",
      "train loss:0.008939167894695964\n",
      "train loss:0.013085099179118013\n",
      "train loss:0.006962653052762974\n",
      "train loss:0.012041153567277505\n",
      "train loss:0.0031244192489902666\n",
      "train loss:0.00534541880586265\n",
      "train loss:0.06713209991614157\n",
      "train loss:0.0553842503659474\n",
      "train loss:0.01884810644596182\n",
      "train loss:0.004743237223211511\n",
      "train loss:0.010780222942902413\n",
      "train loss:0.0025863448577379483\n",
      "train loss:0.0067623348991546215\n",
      "train loss:0.004676998524544502\n",
      "train loss:0.0046784241730733036\n",
      "train loss:0.005539602744241776\n",
      "train loss:0.0007843014296713309\n",
      "train loss:0.008088921323486742\n",
      "train loss:0.01383510587231536\n",
      "train loss:0.0021413250848144683\n",
      "train loss:0.02734303684257703\n",
      "train loss:0.0022488571028171844\n",
      "train loss:0.006711438194199292\n",
      "train loss:0.03096255591563547\n",
      "train loss:0.005443072810360022\n",
      "train loss:0.009510213368561728\n",
      "train loss:0.002228129355943768\n",
      "train loss:0.012837923023211541\n",
      "train loss:0.0074052364579118134\n",
      "train loss:0.007382982889307785\n",
      "train loss:0.019394928776843283\n",
      "train loss:0.007844564495939715\n",
      "train loss:0.02052088727998366\n",
      "train loss:0.002645409574612836\n",
      "train loss:0.004453639727741665\n",
      "train loss:0.034557755952989065\n",
      "train loss:0.05067053416396372\n",
      "train loss:0.023435420622053872\n",
      "train loss:0.002363529559085879\n",
      "train loss:0.021489991158511787\n",
      "train loss:0.0022792380900519458\n",
      "train loss:0.01427885228510545\n",
      "train loss:0.009384593404600518\n",
      "train loss:0.004057770536456993\n",
      "train loss:0.018711797698714262\n",
      "train loss:0.013381228632063057\n",
      "train loss:0.004107684078658331\n",
      "train loss:0.007400166036378247\n",
      "train loss:0.009607406434557346\n",
      "train loss:0.03497157034098229\n",
      "train loss:0.0006339094980333922\n",
      "train loss:0.006531785539377531\n",
      "train loss:0.01976927949183624\n",
      "train loss:0.029628279040176043\n",
      "train loss:0.0033915916909032407\n",
      "train loss:0.006232440169879028\n",
      "train loss:0.006444214643175311\n",
      "train loss:0.017779836663604196\n",
      "train loss:0.003509117648607406\n",
      "train loss:0.006823556631004954\n",
      "train loss:0.002502940704575032\n",
      "train loss:0.01488651006767579\n",
      "train loss:0.0014136445440234612\n",
      "train loss:0.07724208347087114\n",
      "train loss:0.0199117572124829\n",
      "train loss:0.002886883543956139\n",
      "train loss:0.0029488426051243895\n",
      "train loss:0.0010005291972081428\n",
      "train loss:0.0033957150671444776\n",
      "train loss:0.005392529061327923\n",
      "train loss:0.0019249909532916443\n",
      "train loss:0.0019253403917030112\n",
      "train loss:0.00969306693366111\n",
      "train loss:0.009560028810827398\n",
      "train loss:0.0020372750729356006\n",
      "train loss:0.003180886441333085\n",
      "train loss:0.0025959818707280867\n",
      "train loss:0.0004905377367574192\n",
      "train loss:0.014000317078306273\n",
      "train loss:0.004661715377638934\n",
      "=== epoch:10, train acc:0.992, test acc:0.988 ===\n",
      "train loss:0.17969561361317235\n",
      "train loss:0.0010810093635866117\n",
      "train loss:0.00857562875266827\n",
      "train loss:0.00088968286930717\n",
      "train loss:0.004006458712665438\n",
      "train loss:0.028639107893142158\n",
      "train loss:0.005619901164939672\n",
      "train loss:0.01274962340914645\n",
      "train loss:0.025550572108819294\n",
      "train loss:0.002603060141391086\n",
      "train loss:0.008248268065461686\n",
      "train loss:0.005491079147799897\n",
      "train loss:0.005514269934381633\n",
      "train loss:0.0027368223421044228\n",
      "train loss:0.004531775030845588\n",
      "train loss:0.009196732887584757\n",
      "train loss:0.003226396156944446\n",
      "train loss:0.005337907206482564\n",
      "train loss:0.0011589655771048163\n",
      "train loss:0.0022517903605627334\n",
      "train loss:0.003001856448191116\n",
      "train loss:0.052863630507035214\n",
      "train loss:0.006268793948608643\n",
      "train loss:0.006597767405984742\n",
      "train loss:0.027071652322562888\n",
      "train loss:0.029064461712325743\n",
      "train loss:0.0014501006368398375\n",
      "train loss:0.009455083724548813\n",
      "train loss:0.013187803069816215\n",
      "train loss:0.011612873164513529\n",
      "train loss:0.01316124720272262\n",
      "train loss:0.0021215773006536564\n",
      "train loss:0.041193929316470264\n",
      "train loss:0.013671770752407015\n",
      "train loss:0.010712306662506176\n",
      "train loss:0.004328754266818344\n",
      "train loss:0.01224005733774708\n",
      "train loss:0.04521562943604462\n",
      "train loss:0.008027149954549626\n",
      "train loss:0.008182200874563766\n",
      "train loss:0.002554466040635509\n",
      "train loss:0.005400872226273393\n",
      "train loss:0.0031524011587145445\n",
      "train loss:0.0036801472417590042\n",
      "train loss:0.0021896396028761346\n",
      "train loss:0.004689524170651055\n",
      "train loss:0.03479037996025599\n",
      "train loss:0.0036115976763286665\n",
      "train loss:0.005420983440704911\n",
      "train loss:0.0009320243609279116\n",
      "train loss:0.003941289645592414\n",
      "train loss:0.000819658891967365\n",
      "train loss:0.008085065175590114\n",
      "train loss:0.026221726999570635\n",
      "train loss:0.03719620143939589\n",
      "train loss:0.011964496544606455\n",
      "train loss:0.004067858114370465\n",
      "train loss:0.0022606495402680217\n",
      "train loss:0.025666757709388633\n",
      "train loss:0.031147985784400763\n",
      "train loss:0.001848935791073421\n",
      "train loss:0.005701204334981055\n",
      "train loss:0.00915091437488028\n",
      "train loss:0.0056074934674725015\n",
      "train loss:0.0022079317851783735\n",
      "train loss:0.010385661785772443\n",
      "train loss:0.019738157839736165\n",
      "train loss:0.018316183207021386\n",
      "train loss:0.003317147357101874\n",
      "train loss:0.02194324178248834\n",
      "train loss:0.01845069120467122\n",
      "train loss:0.004307122831891545\n",
      "train loss:0.005654577204013657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.02819631571173791\n",
      "train loss:0.021069589596879986\n",
      "train loss:0.010503899906925991\n",
      "train loss:0.0034664500568010142\n",
      "train loss:0.002609557610992577\n",
      "train loss:0.003371634976515546\n",
      "train loss:0.0062559709550414335\n",
      "train loss:0.011633002042587316\n",
      "train loss:0.016817620053726275\n",
      "train loss:0.0005167566167826522\n",
      "train loss:0.009712357577887808\n",
      "train loss:0.041018889934650964\n",
      "train loss:0.018287413715901563\n",
      "train loss:0.004680746056061679\n",
      "train loss:0.008211492116176429\n",
      "train loss:0.04295456913896379\n",
      "train loss:0.0008248805839169221\n",
      "train loss:0.001533028197267622\n",
      "train loss:0.007266818319652954\n",
      "train loss:0.0351524197350345\n",
      "train loss:0.015715134287034565\n",
      "train loss:0.008312558843124514\n",
      "train loss:0.00436569564825808\n",
      "train loss:0.011176134744000423\n",
      "train loss:0.018376365648764714\n",
      "train loss:0.045571317986467665\n",
      "train loss:0.024335958889608236\n",
      "train loss:0.007910813485000067\n",
      "train loss:0.017044237872762553\n",
      "train loss:0.0015222983580779905\n",
      "train loss:0.0026970661554264488\n",
      "train loss:0.005473907258563233\n",
      "train loss:0.006324938012831782\n",
      "train loss:0.020335219908067848\n",
      "train loss:0.0013814804258063767\n",
      "train loss:0.005743123689009726\n",
      "train loss:0.010952550850355703\n",
      "train loss:0.0054023987105038425\n",
      "train loss:0.019382477742100616\n",
      "train loss:0.0058282976962118135\n",
      "train loss:0.01326854745722556\n",
      "train loss:0.00540632464735667\n",
      "train loss:0.01707959235051147\n",
      "train loss:0.05772275874850653\n",
      "train loss:0.008047668682437201\n",
      "train loss:0.001355419146973808\n",
      "train loss:0.0031322914422373983\n",
      "train loss:0.04489540347294683\n",
      "train loss:0.01583305872199134\n",
      "train loss:0.00223884875770844\n",
      "train loss:0.018938793260214536\n",
      "train loss:0.001480511293783695\n",
      "train loss:0.002760640090085008\n",
      "train loss:0.017623113297484925\n",
      "train loss:0.018090918934810934\n",
      "train loss:0.013413998469782886\n",
      "train loss:0.006720688476375526\n",
      "train loss:0.007439587430252463\n",
      "train loss:0.0012023160934686605\n",
      "train loss:0.0011322988133479549\n",
      "train loss:0.009217948190923335\n",
      "train loss:0.00873665264400622\n",
      "train loss:0.006761084691922822\n",
      "train loss:0.02031166127068773\n",
      "train loss:0.007197600127420846\n",
      "train loss:0.012403478276810582\n",
      "train loss:0.007804887821887005\n",
      "train loss:0.011095046325952868\n",
      "train loss:0.006826455687380879\n",
      "train loss:0.002863796975534738\n",
      "train loss:0.002254533763628313\n",
      "train loss:0.0055741731307786015\n",
      "train loss:0.013668724786384822\n",
      "train loss:0.013825861376707344\n",
      "train loss:0.019413960717554805\n",
      "train loss:0.0036213608743499597\n",
      "train loss:0.012846820335126342\n",
      "train loss:0.07395960453794409\n",
      "train loss:0.014607604375804535\n",
      "train loss:0.00330945541377421\n",
      "train loss:0.009402135513934063\n",
      "train loss:0.003141151862866272\n",
      "train loss:0.014870798817002893\n",
      "train loss:0.012816026928061315\n",
      "train loss:0.029220762044884777\n",
      "train loss:0.0023136353587940185\n",
      "train loss:0.002631396164966002\n",
      "train loss:0.03468827385531176\n",
      "train loss:0.00505687443682462\n",
      "train loss:0.020324693900736504\n",
      "train loss:0.0045241226102626046\n",
      "train loss:0.04529161143384262\n",
      "train loss:0.021255066473986596\n",
      "train loss:0.0026554633589198403\n",
      "train loss:0.002982075459186447\n",
      "train loss:0.010904499658447624\n",
      "train loss:0.005379581686995902\n",
      "train loss:0.001087030895905044\n",
      "train loss:0.006048424335194063\n",
      "train loss:0.010999213453419771\n",
      "train loss:0.02065784320616326\n",
      "train loss:0.0027531710535891123\n",
      "train loss:0.009535259503336469\n",
      "train loss:0.00848766175434088\n",
      "train loss:0.0007920757489229502\n",
      "train loss:0.004209173292936919\n",
      "train loss:0.00899462895254146\n",
      "train loss:0.04697133268198796\n",
      "train loss:0.0026111597430367485\n",
      "train loss:0.0034382864839772927\n",
      "train loss:0.006073624887761864\n",
      "train loss:0.006646579291955851\n",
      "train loss:0.006038945522315511\n",
      "train loss:0.0009036141669214202\n",
      "train loss:0.002086509507105428\n",
      "train loss:0.012027922785205624\n",
      "train loss:0.025369611881241497\n",
      "train loss:0.008909930717171508\n",
      "train loss:0.008401460088841219\n",
      "train loss:0.010737695917941926\n",
      "train loss:0.007427320924998109\n",
      "train loss:0.010057209719641422\n",
      "train loss:0.0063433673415902204\n",
      "train loss:0.026109571122521196\n",
      "train loss:0.016634544285269896\n",
      "train loss:0.01058788193837763\n",
      "train loss:0.022418723955978923\n",
      "train loss:0.0057349248636632336\n",
      "train loss:0.03626878578692444\n",
      "train loss:0.04551605536816374\n",
      "train loss:0.007114763597789512\n",
      "train loss:0.004996685956066448\n",
      "train loss:0.01356003026896134\n",
      "train loss:0.008533275998275969\n",
      "train loss:0.009587182840693053\n",
      "train loss:0.010095313928218726\n",
      "train loss:0.010202327957510852\n",
      "train loss:0.027446979572550025\n",
      "train loss:0.007335430270769991\n",
      "train loss:0.018574635571953834\n",
      "train loss:0.002655414287465863\n",
      "train loss:0.005636235497041171\n",
      "train loss:0.011780670873034275\n",
      "train loss:0.0029607509745138527\n",
      "train loss:0.009246036664723527\n",
      "train loss:0.016076037372149788\n",
      "train loss:0.011751883023535995\n",
      "train loss:0.01803623591225366\n",
      "train loss:0.005312170919704704\n",
      "train loss:0.005258543179207115\n",
      "train loss:0.015088037522055352\n",
      "train loss:0.004899776557569329\n",
      "train loss:0.029896029317416768\n",
      "train loss:0.0024376919270261087\n",
      "train loss:0.0018824689295692263\n",
      "train loss:0.008096644921080436\n",
      "train loss:0.009597653477170412\n",
      "train loss:0.008402830713465382\n",
      "train loss:0.014634307589284492\n",
      "train loss:0.03737587686959003\n",
      "train loss:0.016779982495605136\n",
      "train loss:0.007401692013311053\n",
      "train loss:0.011869084923008182\n",
      "train loss:0.004966778875311828\n",
      "train loss:0.008752505392939747\n",
      "train loss:0.005145687000030458\n",
      "train loss:0.006517221922244881\n",
      "train loss:0.01887304540182309\n",
      "train loss:0.006490611385864973\n",
      "train loss:0.036562683152677564\n",
      "train loss:0.018078209256982017\n",
      "train loss:0.0017057649679128712\n",
      "train loss:0.009117486995527878\n",
      "train loss:0.008095554863196635\n",
      "train loss:0.03122985354875479\n",
      "train loss:0.008735034478721407\n",
      "train loss:0.013551415570991179\n",
      "train loss:0.0026844074700577997\n",
      "train loss:0.0021467161269912017\n",
      "train loss:0.001496430784346802\n",
      "train loss:0.01625708150294786\n",
      "train loss:0.009603295643635674\n",
      "train loss:0.004712175435790242\n",
      "train loss:0.014287703610865909\n",
      "train loss:0.0035723289250539484\n",
      "train loss:0.005149956779098356\n",
      "train loss:0.012235994520150754\n",
      "train loss:0.0041379752923775825\n",
      "train loss:0.004670304073438961\n",
      "train loss:0.01697060069511943\n",
      "train loss:0.00028521212105071694\n",
      "train loss:0.0043392306067618356\n",
      "train loss:0.014519563035856189\n",
      "train loss:0.009613145712171822\n",
      "train loss:0.007467973175825664\n",
      "train loss:0.0057129641479494305\n",
      "train loss:0.0019821223756549982\n",
      "train loss:0.003821933588747077\n",
      "train loss:0.0026348816489334768\n",
      "train loss:0.0026200071809749283\n",
      "train loss:0.00290294549059762\n",
      "train loss:0.003318046673341451\n",
      "train loss:0.006682413718083959\n",
      "train loss:0.020567749924441023\n",
      "train loss:0.00988281412907967\n",
      "train loss:0.0010997854213480227\n",
      "train loss:0.02404325053076065\n",
      "train loss:0.0009304338343173486\n",
      "train loss:0.0009594399752435659\n",
      "train loss:0.0035124711905393053\n",
      "train loss:0.005340725471312607\n",
      "train loss:0.036241785189559485\n",
      "train loss:0.08648884127449627\n",
      "train loss:0.004343322145799242\n",
      "train loss:0.024652369518590057\n",
      "train loss:0.006727922022172107\n",
      "train loss:0.0068101099109187865\n",
      "train loss:0.004189056434958904\n",
      "train loss:0.011343025688374713\n",
      "train loss:0.001844088506230583\n",
      "train loss:0.011516603404487681\n",
      "train loss:0.001268399111382479\n",
      "train loss:0.00837264338034574\n",
      "train loss:0.0076144658746456935\n",
      "train loss:0.006904125829319109\n",
      "train loss:0.00664718141999186\n",
      "train loss:0.004693948082260012\n",
      "train loss:0.005384537464542502\n",
      "train loss:0.0027410622468039387\n",
      "train loss:0.019531299760912158\n",
      "train loss:0.0021182986738219815\n",
      "train loss:0.021928128895955128\n",
      "train loss:0.010768429538334876\n",
      "train loss:0.0016255483407627421\n",
      "train loss:0.008536594787180303\n",
      "train loss:0.003184691101064646\n",
      "train loss:0.005298583258706975\n",
      "train loss:0.007745342724276785\n",
      "train loss:0.002410690679800081\n",
      "train loss:0.002224372771616178\n",
      "train loss:0.01294523562433453\n",
      "train loss:0.007976044587523401\n",
      "train loss:0.018690270711493\n",
      "train loss:0.006019248410580444\n",
      "train loss:0.0031850134411348686\n",
      "train loss:0.020076829346951902\n",
      "train loss:0.014530181000312205\n",
      "train loss:0.06094285543526072\n",
      "train loss:0.0042215332059822065\n",
      "train loss:0.0023370602095504427\n",
      "train loss:0.005021262929604456\n",
      "train loss:0.006732682915637759\n",
      "train loss:0.004552570128000134\n",
      "train loss:0.004588967301269761\n",
      "train loss:0.002363580005950823\n",
      "train loss:0.009246328632275798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.022509958579755022\n",
      "train loss:0.03553534129051652\n",
      "train loss:0.0021443630409636043\n",
      "train loss:0.01512175657255832\n",
      "train loss:0.011860625727805956\n",
      "train loss:0.0010164121915274397\n",
      "train loss:0.034892669247320346\n",
      "train loss:0.009282392069100177\n",
      "train loss:0.035390495713575866\n",
      "train loss:0.03511110919371145\n",
      "train loss:0.0027051556421953974\n",
      "train loss:0.03867729803583458\n",
      "train loss:0.0010542978501771798\n",
      "train loss:0.04874380087000042\n",
      "train loss:0.023807992461291637\n",
      "train loss:0.008876723100813303\n",
      "train loss:0.0051993090861206645\n",
      "train loss:0.004735628923077769\n",
      "train loss:0.004341573024961549\n",
      "train loss:0.011891625261443535\n",
      "train loss:0.0035149015344588365\n",
      "train loss:0.005385100364845344\n",
      "train loss:0.007168514354867401\n",
      "train loss:0.0011421078557635276\n",
      "train loss:0.018136107932858282\n",
      "train loss:0.010986214078364793\n",
      "train loss:0.002658566684427998\n",
      "train loss:0.00828589551066525\n",
      "train loss:0.030607403084763948\n",
      "train loss:0.00953168143523326\n",
      "train loss:0.02125707325347157\n",
      "train loss:0.0006712601118123757\n",
      "train loss:0.0033116387451478163\n",
      "train loss:0.0016844088297909262\n",
      "train loss:0.009364508904300226\n",
      "train loss:0.005863640352563949\n",
      "train loss:0.007115831925646776\n",
      "train loss:0.037931410372624645\n",
      "train loss:0.010139258302337886\n",
      "train loss:0.0033361240545928036\n",
      "train loss:0.004300184542669741\n",
      "train loss:0.033138683819134374\n",
      "train loss:0.0006254165970614408\n",
      "train loss:0.015074130326821969\n",
      "train loss:0.0023308700556676876\n",
      "train loss:0.0009152188006623292\n",
      "train loss:0.001669179690958588\n",
      "train loss:0.0007725665302977749\n",
      "train loss:0.00608032897513724\n",
      "train loss:0.014052441396112987\n",
      "train loss:0.009835667404602013\n",
      "train loss:0.006436150907977524\n",
      "train loss:0.009305999007518587\n",
      "train loss:0.006512015813935829\n",
      "train loss:0.040233140821058146\n",
      "train loss:0.0017807408176024368\n",
      "train loss:0.00735806754060362\n",
      "train loss:0.007903107621039395\n",
      "train loss:0.004619570625542972\n",
      "train loss:0.004874147988944415\n",
      "train loss:0.002927729034769483\n",
      "train loss:0.004004065276340874\n",
      "train loss:0.0068372909675863255\n",
      "train loss:0.005983692140497273\n",
      "train loss:0.0013056437898785684\n",
      "train loss:0.03229534514597891\n",
      "train loss:0.01042631070815341\n",
      "train loss:0.07643874973686722\n",
      "train loss:0.02675415538557745\n",
      "train loss:0.0036118849994496148\n",
      "train loss:0.03654891192645826\n",
      "train loss:0.025050226560865304\n",
      "train loss:0.009810466510700966\n",
      "train loss:0.004511199683014847\n",
      "train loss:0.01666572073208602\n",
      "train loss:0.03887051039815947\n",
      "train loss:0.01937390375511326\n",
      "train loss:0.01745475048651213\n",
      "train loss:0.0038068832185687105\n",
      "train loss:0.0011112847007295362\n",
      "train loss:0.004414371272045466\n",
      "train loss:0.001641049752790995\n",
      "train loss:0.008021127600402496\n",
      "train loss:0.008686595990917067\n",
      "train loss:0.006610850975261476\n",
      "train loss:0.014441359117911678\n",
      "train loss:0.002698639134035265\n",
      "train loss:0.013859431940387041\n",
      "train loss:0.01266102975521814\n",
      "train loss:0.010332248372838198\n",
      "train loss:0.0017515610409715094\n",
      "train loss:0.0028361109551894633\n",
      "train loss:0.022137489779168042\n",
      "train loss:0.016235896443664806\n",
      "train loss:0.0073920498278568746\n",
      "train loss:0.006822734191646932\n",
      "train loss:0.0008509271953857065\n",
      "train loss:0.0070536355184844055\n",
      "train loss:0.005986202138380621\n",
      "train loss:0.029940725743216642\n",
      "train loss:0.018957510586553733\n",
      "train loss:0.0026198581495048847\n",
      "train loss:0.011823325006124388\n",
      "train loss:0.005091762330906781\n",
      "train loss:0.0009915232920126012\n",
      "train loss:0.04807586657215599\n",
      "train loss:0.008995504618822453\n",
      "train loss:0.006183681721457216\n",
      "train loss:0.012161043674076989\n",
      "train loss:0.0011226011765872335\n",
      "train loss:0.004540066913101581\n",
      "train loss:0.022911142666793265\n",
      "train loss:0.002601886779670828\n",
      "train loss:0.006623303583358275\n",
      "train loss:0.006349603052417264\n",
      "train loss:0.007938929599514184\n",
      "train loss:0.0047007679878769216\n",
      "train loss:0.005045503402387428\n",
      "train loss:0.002281901243147552\n",
      "train loss:0.02097534016295344\n",
      "train loss:0.010941586763231887\n",
      "train loss:0.0007929427424747515\n",
      "train loss:0.014701478914129311\n",
      "train loss:0.005511911627302529\n",
      "train loss:0.0035093711615364533\n",
      "train loss:0.01049431817203342\n",
      "train loss:0.004573245216500886\n",
      "train loss:0.004708693697702378\n",
      "train loss:0.004850897664314136\n",
      "train loss:0.005752107215590548\n",
      "train loss:0.01339685791568663\n",
      "train loss:0.0013618045913047067\n",
      "train loss:0.02725226742844701\n",
      "train loss:0.006520335173864212\n",
      "train loss:0.005285150509733249\n",
      "train loss:0.007278333968763767\n",
      "train loss:0.004332551381845897\n",
      "train loss:0.005811685246558412\n",
      "train loss:0.053496700622131216\n",
      "train loss:0.019912879141846584\n",
      "train loss:0.03680595911433607\n",
      "train loss:0.0011871349292694301\n",
      "train loss:0.00560761217066693\n",
      "train loss:0.0022226326874412996\n",
      "train loss:0.003537858047140015\n",
      "train loss:0.001881523040068046\n",
      "train loss:0.018149394312421706\n",
      "train loss:0.0029340943215748717\n",
      "train loss:0.02494116052182909\n",
      "train loss:0.03012521559939908\n",
      "train loss:0.003500158242548264\n",
      "train loss:0.004207340174968592\n",
      "train loss:0.0015399786809711423\n",
      "train loss:0.0026113291882586777\n",
      "train loss:0.006144001347325778\n",
      "train loss:0.0025351131255739734\n",
      "train loss:0.004846009322213265\n",
      "train loss:0.003651297322746756\n",
      "train loss:0.013769887468298748\n",
      "train loss:0.022104131660932724\n",
      "train loss:0.0060555574052593856\n",
      "train loss:0.0241440983378794\n",
      "train loss:0.007911510154686042\n",
      "train loss:0.0533467365488552\n",
      "train loss:0.0027242500269030277\n",
      "train loss:0.012570033758357732\n",
      "train loss:0.006229873153988442\n",
      "train loss:0.009430228454449577\n",
      "train loss:0.004860292305557848\n",
      "train loss:0.031925671132191906\n",
      "train loss:0.0043398384414784635\n",
      "train loss:0.002180949887822474\n",
      "train loss:0.002177455313337997\n",
      "train loss:0.00014970718429681184\n",
      "train loss:0.03775308003135886\n",
      "train loss:0.07609417518474973\n",
      "train loss:0.013758708814908642\n",
      "train loss:0.0021201002452349606\n",
      "train loss:0.028878535359691534\n",
      "train loss:0.02413512244148951\n",
      "train loss:0.0032473718716298917\n",
      "train loss:0.006723015686486506\n",
      "train loss:0.019106388255263913\n",
      "train loss:0.025142432280212856\n",
      "train loss:0.0030959347672641934\n",
      "train loss:0.018630942803012484\n",
      "train loss:0.006438613825970989\n",
      "train loss:0.005819548278867079\n",
      "train loss:0.009245601434747576\n",
      "train loss:0.008569858949618928\n",
      "train loss:0.005417375355677225\n",
      "train loss:0.002613085108929899\n",
      "train loss:0.010078126831262597\n",
      "train loss:0.03598304370035525\n",
      "train loss:0.034730327336650844\n",
      "train loss:0.003361634334284016\n",
      "train loss:0.00603031916047339\n",
      "train loss:0.006434748734271623\n",
      "train loss:0.01598356316602157\n",
      "train loss:0.002998110062503726\n",
      "train loss:0.007901976882972022\n",
      "train loss:0.005139811235287716\n",
      "train loss:0.010041160519388437\n",
      "train loss:0.0034288869066455225\n",
      "train loss:0.0034956945677194536\n",
      "train loss:0.013150478596531028\n",
      "train loss:0.006729283192380159\n",
      "train loss:0.005313520047903615\n",
      "train loss:0.010693573863766338\n",
      "train loss:0.0063086389679659245\n",
      "train loss:0.013685887440154622\n",
      "train loss:0.016722060135952992\n",
      "train loss:0.020137665913560587\n",
      "train loss:0.0020715677905154004\n",
      "train loss:0.005153418366930956\n",
      "train loss:0.003581726054526981\n",
      "train loss:0.007825673964180858\n",
      "train loss:0.011322179090262714\n",
      "train loss:0.0011329801208714231\n",
      "train loss:0.0021397356815262437\n",
      "train loss:0.01071945880966797\n",
      "train loss:0.006732832823420271\n",
      "train loss:0.0007840700243415326\n",
      "train loss:0.0035159052717930067\n",
      "train loss:0.0024817068033692333\n",
      "train loss:0.019232042285875176\n",
      "train loss:0.006004911414048514\n",
      "train loss:0.009409206328657329\n",
      "train loss:0.004293380564006065\n",
      "train loss:0.05571881874877798\n",
      "train loss:0.007086784968982965\n",
      "train loss:0.006186848211388926\n",
      "train loss:0.005743271636212786\n",
      "train loss:0.005121829576996938\n",
      "train loss:0.0019479946301204168\n",
      "train loss:0.00945440293463616\n",
      "train loss:0.0019692015450722116\n",
      "train loss:0.007616781247006084\n",
      "train loss:0.04746179004078138\n",
      "train loss:0.009366922969229032\n",
      "train loss:0.005207591081896386\n",
      "train loss:0.003291599481810909\n",
      "train loss:0.0008771130716946443\n",
      "train loss:0.005914503480234994\n",
      "train loss:0.0010476765202200472\n",
      "train loss:0.0254941772184041\n",
      "train loss:0.010171635571187604\n",
      "train loss:0.003178393904133989\n",
      "train loss:0.0017524312379899767\n",
      "train loss:0.007587913655743599\n",
      "train loss:0.008315273358542506\n",
      "train loss:0.003663733814469944\n",
      "train loss:0.011782041088144006\n",
      "train loss:0.00488283464916622\n",
      "train loss:0.004386955934693001\n",
      "train loss:0.004676068707141249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004478246206931278\n",
      "train loss:0.006823653549174001\n",
      "train loss:0.003676642118099712\n",
      "train loss:0.00285291348225475\n",
      "train loss:0.007363038365879224\n",
      "train loss:0.04851103546065258\n",
      "train loss:0.005637592446319886\n",
      "train loss:0.018192773572718896\n",
      "train loss:0.036902010496168154\n",
      "train loss:0.021296094648950725\n",
      "train loss:0.013338760803024277\n",
      "train loss:0.017963872962669117\n",
      "train loss:0.0038279234811501705\n",
      "train loss:0.005989726248989938\n",
      "train loss:0.002914057741144535\n",
      "=== epoch:11, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.003788036476606702\n",
      "train loss:0.042519201775564446\n",
      "train loss:0.007677325032518009\n",
      "train loss:0.013608242670319216\n",
      "train loss:0.0036997727455448603\n",
      "train loss:0.006095661888588243\n",
      "train loss:0.0025788868937363174\n",
      "train loss:0.0004915873571096178\n",
      "train loss:0.0018542544386080534\n",
      "train loss:0.001787009325181558\n",
      "train loss:0.011949249351994404\n",
      "train loss:0.00885700267025664\n",
      "train loss:0.0038612518279183532\n",
      "train loss:0.01739065953374186\n",
      "train loss:0.004296234730261766\n",
      "train loss:0.005991407287035186\n",
      "train loss:0.010653001896753387\n",
      "train loss:0.003200934430583638\n",
      "train loss:0.0006373749120696394\n",
      "train loss:0.004114409927722146\n",
      "train loss:0.002625203295438528\n",
      "train loss:0.00803731522511992\n",
      "train loss:0.007437856560087989\n",
      "train loss:0.0014924509848699844\n",
      "train loss:0.005451181193736003\n",
      "train loss:0.016044510999672468\n",
      "train loss:0.013641571998360257\n",
      "train loss:0.0025397986429491924\n",
      "train loss:0.004636721494492899\n",
      "train loss:0.006336100779838778\n",
      "train loss:0.004102046810053717\n",
      "train loss:0.00889459347382875\n",
      "train loss:0.003593340440309369\n",
      "train loss:0.0004912418343609527\n",
      "train loss:0.011292414665631412\n",
      "train loss:0.011613499291793856\n",
      "train loss:0.002081597030636719\n",
      "train loss:0.006689766755603967\n",
      "train loss:0.03397454442511004\n",
      "train loss:0.0011192673061210957\n",
      "train loss:0.004051476287917372\n",
      "train loss:0.0018026384153252558\n",
      "train loss:0.010850126949690578\n",
      "train loss:0.023765902318679203\n",
      "train loss:0.0008830730118435258\n",
      "train loss:0.007822464498745409\n",
      "train loss:0.004703355280357351\n",
      "train loss:0.005712849904309326\n",
      "train loss:0.00580670171766219\n",
      "train loss:0.01547506287202124\n",
      "train loss:0.005625500348078541\n",
      "train loss:0.0012968485865698168\n",
      "train loss:0.0010654318866942147\n",
      "train loss:0.0027243572668926084\n",
      "train loss:0.011290849475639774\n",
      "train loss:0.03139717865466793\n",
      "train loss:0.0016084067222698526\n",
      "train loss:0.02228581253515432\n",
      "train loss:0.005708928353990723\n",
      "train loss:0.0038053118534451995\n",
      "train loss:0.002947215580339782\n",
      "train loss:0.0018233842763581707\n",
      "train loss:0.004096773672560128\n",
      "train loss:0.00705101161352441\n",
      "train loss:0.008185297531264794\n",
      "train loss:0.0045355974422355725\n",
      "train loss:0.0041652237726523674\n",
      "train loss:0.0013225551193178089\n",
      "train loss:0.004302056227088352\n",
      "train loss:0.01055857010380155\n",
      "train loss:0.012739397820511322\n",
      "train loss:0.012994818150358488\n",
      "train loss:0.004940313773071061\n",
      "train loss:0.008908821234857832\n",
      "train loss:0.0025179375893791063\n",
      "train loss:0.00441704959412555\n",
      "train loss:0.003014070650599357\n",
      "train loss:0.0038564492904543547\n",
      "train loss:0.012301074455478414\n",
      "train loss:0.003076420826808612\n",
      "train loss:0.006719356891344282\n",
      "train loss:0.014340313821177906\n",
      "train loss:0.002890115612037451\n",
      "train loss:0.0062065184025417094\n",
      "train loss:0.0006002285251622599\n",
      "train loss:0.010825679437666469\n",
      "train loss:0.0008219017472205825\n",
      "train loss:0.008455339106297055\n",
      "train loss:0.0030439750626088157\n",
      "train loss:0.015496611984847404\n",
      "train loss:0.0036164619999258397\n",
      "train loss:0.007890131699364943\n",
      "train loss:0.0004680542385619603\n",
      "train loss:0.00695314983613832\n",
      "train loss:0.008876741989251544\n",
      "train loss:0.003585761405509656\n",
      "train loss:0.00234575806202258\n",
      "train loss:0.008457513913785807\n",
      "train loss:0.019844105196114303\n",
      "train loss:0.010280053316629505\n",
      "train loss:0.008587695025581148\n",
      "train loss:0.017097082074683707\n",
      "train loss:0.006638850057652476\n",
      "train loss:0.002757259372529855\n",
      "train loss:0.0062124190292584085\n",
      "train loss:0.0036344444418907407\n",
      "train loss:0.009190750109329127\n",
      "train loss:0.018303582303923805\n",
      "train loss:0.003955843906191713\n",
      "train loss:0.0009953429391767847\n",
      "train loss:0.003340647889851409\n",
      "train loss:0.0070958476574737115\n",
      "train loss:0.0015623052449242343\n",
      "train loss:0.008417430940713259\n",
      "train loss:0.02452859248712731\n",
      "train loss:0.005421723050182816\n",
      "train loss:0.01719444262592975\n",
      "train loss:0.011380265495372919\n",
      "train loss:0.0026564799131216683\n",
      "train loss:0.007542009141800864\n",
      "train loss:0.0013249539970763102\n",
      "train loss:0.02928811992586061\n",
      "train loss:0.009409287318331086\n",
      "train loss:0.002663455569106696\n",
      "train loss:0.003788152928713547\n",
      "train loss:0.009047795318144801\n",
      "train loss:0.005357022945925086\n",
      "train loss:0.02347813850094942\n",
      "train loss:0.0029662068249089834\n",
      "train loss:0.002758031481897377\n",
      "train loss:0.007107506394909982\n",
      "train loss:0.0015888538913905869\n",
      "train loss:0.025641201549639184\n",
      "train loss:0.006816966913457372\n",
      "train loss:0.0032911048082934825\n",
      "train loss:0.07889129177951566\n",
      "train loss:0.005333547480651421\n",
      "train loss:0.003315043412153711\n",
      "train loss:0.0063847165277919685\n",
      "train loss:0.02469377732129177\n",
      "train loss:0.004393628940897024\n",
      "train loss:0.005007767370880942\n",
      "train loss:0.008523289159087033\n",
      "train loss:0.019298674615774374\n",
      "train loss:0.011166430069265798\n",
      "train loss:0.015943872983813515\n",
      "train loss:0.001392674809140507\n",
      "train loss:0.008558407203498777\n",
      "train loss:0.0012436492531133518\n",
      "train loss:0.003633655810904143\n",
      "train loss:0.004254722261415418\n",
      "train loss:0.002864375197556607\n",
      "train loss:0.005406877937994965\n",
      "train loss:0.012204118477772544\n",
      "train loss:0.001936053642183186\n",
      "train loss:0.002405106928485607\n",
      "train loss:0.009725642456123111\n",
      "train loss:0.0071157352310816015\n",
      "train loss:0.005753335531717484\n",
      "train loss:0.014281789081277156\n",
      "train loss:0.003493866086300374\n",
      "train loss:0.006462789116511298\n",
      "train loss:0.004034811010251255\n",
      "train loss:0.0048392465070934195\n",
      "train loss:0.0014933668104557846\n",
      "train loss:0.0009436524272045749\n",
      "train loss:0.006069160440486271\n",
      "train loss:0.014606634288272627\n",
      "train loss:0.0013420214675757256\n",
      "train loss:0.007976121989425454\n",
      "train loss:0.015796101610441773\n",
      "train loss:0.006360744755760662\n",
      "train loss:0.03320488884208314\n",
      "train loss:0.002960585033120662\n",
      "train loss:0.00487360603055464\n",
      "train loss:0.0174671903725061\n",
      "train loss:0.0007981734134653398\n",
      "train loss:0.002285026386730703\n",
      "train loss:0.0061023375287533\n",
      "train loss:0.007280346375937469\n",
      "train loss:0.0044488351396662325\n",
      "train loss:0.011634767539673695\n",
      "train loss:0.03904484978511404\n",
      "train loss:0.0067265697028516605\n",
      "train loss:0.0016249621165860461\n",
      "train loss:0.011530333131548349\n",
      "train loss:0.005407229057442525\n",
      "train loss:0.0011984014828493041\n",
      "train loss:0.0035910316681919724\n",
      "train loss:0.005702732547421319\n",
      "train loss:0.017415907833302532\n",
      "train loss:0.007765932418666391\n",
      "train loss:0.04527203228072462\n",
      "train loss:0.0034047717820005798\n",
      "train loss:0.00740204121237244\n",
      "train loss:0.012115424571912664\n",
      "train loss:0.008034051825461474\n",
      "train loss:0.00019761901200168088\n",
      "train loss:0.01828145759606157\n",
      "train loss:0.0036797232852473546\n",
      "train loss:0.008356228315490329\n",
      "train loss:0.007348688345905072\n",
      "train loss:0.0025027344171882817\n",
      "train loss:0.0065093370014205724\n",
      "train loss:0.0008050264795015832\n",
      "train loss:0.006528129117617893\n",
      "train loss:0.003985681010323244\n",
      "train loss:0.001622586533663241\n",
      "train loss:0.0018693802896492086\n",
      "train loss:0.0026297314361989257\n",
      "train loss:0.0016031965155091277\n",
      "train loss:0.016286263921443268\n",
      "train loss:0.009180632667315844\n",
      "train loss:0.01670924678951902\n",
      "train loss:0.003601324061608505\n",
      "train loss:0.02874086249957029\n",
      "train loss:0.003924056424935239\n",
      "train loss:0.014948069680511173\n",
      "train loss:0.03753750737433562\n",
      "train loss:0.008569323141848453\n",
      "train loss:0.003681235745925571\n",
      "train loss:0.002052786925880472\n",
      "train loss:0.016221832484194402\n",
      "train loss:0.006852522848358349\n",
      "train loss:0.0050851042754053374\n",
      "train loss:0.003397948280588308\n",
      "train loss:0.0014097763772306473\n",
      "train loss:0.0053333351337634515\n",
      "train loss:0.008896451500915448\n",
      "train loss:0.005819551801957951\n",
      "train loss:0.002227122005659996\n",
      "train loss:0.011612689592054465\n",
      "train loss:0.0005116873961249764\n",
      "train loss:0.02523353693367014\n",
      "train loss:0.00465542266718199\n",
      "train loss:0.010823473022251088\n",
      "train loss:0.007095212389165761\n",
      "train loss:0.005288192833472665\n",
      "train loss:0.007190230655095965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005079401639223492\n",
      "train loss:0.03606721729178812\n",
      "train loss:0.0041481290495636635\n",
      "train loss:0.03806788354029371\n",
      "train loss:0.0017455950456262963\n",
      "train loss:0.002578504389848036\n",
      "train loss:0.003122382679715612\n",
      "train loss:0.0013801352219618601\n",
      "train loss:0.0019868456195990198\n",
      "train loss:0.007680323002667716\n",
      "train loss:0.011262604366991624\n",
      "train loss:0.007578777753810414\n",
      "train loss:0.01321586899043286\n",
      "train loss:0.003348636069749754\n",
      "train loss:0.04037387791296423\n",
      "train loss:0.0015336567764963425\n",
      "train loss:0.05145346915467842\n",
      "train loss:0.007610987036057542\n",
      "train loss:0.008540940636648519\n",
      "train loss:0.011434991363039427\n",
      "train loss:0.002830530143754042\n",
      "train loss:0.003952593358490086\n",
      "train loss:0.026890455096128044\n",
      "train loss:0.03898211779210294\n",
      "train loss:0.00771746593338946\n",
      "train loss:0.003746655590118252\n",
      "train loss:0.0063114158728268775\n",
      "train loss:0.007483551644924789\n",
      "train loss:0.02066345297106066\n",
      "train loss:0.005708066391386257\n",
      "train loss:0.0033359546962827176\n",
      "train loss:0.001056697322963282\n",
      "train loss:0.004965976910682307\n",
      "train loss:0.01486589295364148\n",
      "train loss:0.0037998505761375465\n",
      "train loss:0.0014541977262174201\n",
      "train loss:0.02267322360426689\n",
      "train loss:0.0010454751917007195\n",
      "train loss:0.024222931458210244\n",
      "train loss:0.005225356576905202\n",
      "train loss:0.0006158273582637361\n",
      "train loss:0.02120113499967474\n",
      "train loss:0.012048593783630721\n",
      "train loss:0.025191040472552127\n",
      "train loss:0.002638958351953174\n",
      "train loss:0.03336199459717037\n",
      "train loss:0.0016034704280355608\n",
      "train loss:0.0045644467528844004\n",
      "train loss:0.052301094374328845\n",
      "train loss:0.018748996739297592\n",
      "train loss:0.007362133854485556\n",
      "train loss:0.03203674715560622\n",
      "train loss:0.0024068718545587854\n",
      "train loss:0.018990519076189216\n",
      "train loss:0.0003018942997785447\n",
      "train loss:0.0009075406927477474\n",
      "train loss:0.0018893535884364182\n",
      "train loss:0.003093754067140908\n",
      "train loss:0.005908567789746489\n",
      "train loss:0.002899265952629163\n",
      "train loss:0.006431395742441604\n",
      "train loss:0.007366349652954237\n",
      "train loss:0.003174310891742313\n",
      "train loss:0.00535334562042277\n",
      "train loss:0.003037509847172126\n",
      "train loss:0.002730686225481473\n",
      "train loss:0.001037536677654933\n",
      "train loss:0.004353584428825514\n",
      "train loss:0.0026118050160876165\n",
      "train loss:0.01311221068005784\n",
      "train loss:0.023433508208872092\n",
      "train loss:0.0057266069890545565\n",
      "train loss:0.000341315815633814\n",
      "train loss:0.0032258133052129496\n",
      "train loss:0.004842975584931682\n",
      "train loss:0.001748232334690898\n",
      "train loss:0.009467258498834152\n",
      "train loss:0.0237455668420846\n",
      "train loss:0.0010985622958310135\n",
      "train loss:0.039652524863008944\n",
      "train loss:0.001974743792767868\n",
      "train loss:0.004878804722387465\n",
      "train loss:0.004864061948628987\n",
      "train loss:0.006277169293122335\n",
      "train loss:0.0035395939544192834\n",
      "train loss:0.011973798253376846\n",
      "train loss:0.012393498071003775\n",
      "train loss:0.003086318682936171\n",
      "train loss:0.0013887398031831872\n",
      "train loss:0.003181939453261766\n",
      "train loss:0.010871831717835527\n",
      "train loss:0.014782070053575262\n",
      "train loss:0.006259425056902511\n",
      "train loss:0.0025984203312045683\n",
      "train loss:0.07017733455573928\n",
      "train loss:0.014372225813494045\n",
      "train loss:0.018015048305589188\n",
      "train loss:0.0012907973971571457\n",
      "train loss:0.023087348160036526\n",
      "train loss:0.0015013294003504102\n",
      "train loss:0.0037359414905287127\n",
      "train loss:0.001613404993552021\n",
      "train loss:0.0023498214343757855\n",
      "train loss:0.002391224761901513\n",
      "train loss:0.0040334270198541175\n",
      "train loss:0.0015415157658905262\n",
      "train loss:0.0034445556826568097\n",
      "train loss:0.0175932287418324\n",
      "train loss:0.006857076555742632\n",
      "train loss:0.04653548100223788\n",
      "train loss:0.002873778628902965\n",
      "train loss:0.004226758460889992\n",
      "train loss:0.0037324700753252234\n",
      "train loss:0.010859020874765061\n",
      "train loss:0.00549354738899221\n",
      "train loss:0.006862644866241378\n",
      "train loss:0.011935703484870986\n",
      "train loss:0.0034634954615514846\n",
      "train loss:0.013059911621251884\n",
      "train loss:0.008341008732571696\n",
      "train loss:0.015875094351271865\n",
      "train loss:0.004834827684853558\n",
      "train loss:0.002683696833755243\n",
      "train loss:0.0025449865766207468\n",
      "train loss:0.00026806875002331054\n",
      "train loss:0.005315984375128473\n",
      "train loss:0.0013460303444168076\n",
      "train loss:0.02306956516843447\n",
      "train loss:0.006150985411389625\n",
      "train loss:0.017671603031117436\n",
      "train loss:0.008224084853034786\n",
      "train loss:0.015541342116151576\n",
      "train loss:0.0043927836114010235\n",
      "train loss:0.002599225888647799\n",
      "train loss:0.0014840022345030074\n",
      "train loss:0.00439581081253017\n",
      "train loss:0.004890633222901347\n",
      "train loss:0.0029454973463365203\n",
      "train loss:0.0025361074201788038\n",
      "train loss:0.01161886700372127\n",
      "train loss:0.008639946017931895\n",
      "train loss:0.0011763868199906019\n",
      "train loss:0.012995200690649047\n",
      "train loss:0.0035428423950005974\n",
      "train loss:0.0015479019293762558\n",
      "train loss:0.007006459323874246\n",
      "train loss:0.011721864234624709\n",
      "train loss:0.0069591105615990235\n",
      "train loss:0.009292105260490199\n",
      "train loss:0.0016193068607041965\n",
      "train loss:0.0011988481063339377\n",
      "train loss:0.0016691795583147525\n",
      "train loss:0.003562818434816627\n",
      "train loss:0.006212069289233065\n",
      "train loss:0.0009928009326835405\n",
      "train loss:0.005531793026381162\n",
      "train loss:0.0033161221474522257\n",
      "train loss:0.0012501012708195174\n",
      "train loss:0.01872275875393993\n",
      "train loss:0.0013222306144829317\n",
      "train loss:0.01115574078644556\n",
      "train loss:0.0006884991443117927\n",
      "train loss:0.007893671297970752\n",
      "train loss:0.004606978220526935\n",
      "train loss:0.00530515963872143\n",
      "train loss:0.014243989660386808\n",
      "train loss:0.0018148411970904743\n",
      "train loss:0.0021016109848429445\n",
      "train loss:0.0006466630995630203\n",
      "train loss:0.0015221588326665841\n",
      "train loss:0.0012332549084329834\n",
      "train loss:0.0028353687814894925\n",
      "train loss:0.005430102173963356\n",
      "train loss:0.00241287085615741\n",
      "train loss:0.004092491508349315\n",
      "train loss:0.010498670362552037\n",
      "train loss:0.003441801005289904\n",
      "train loss:0.004241269454834786\n",
      "train loss:0.003564007383951668\n",
      "train loss:0.06824040914726749\n",
      "train loss:0.0013629253043897869\n",
      "train loss:0.0001772918256644887\n",
      "train loss:0.006121135435154277\n",
      "train loss:0.0036405939974552483\n",
      "train loss:0.002180682770933846\n",
      "train loss:0.004457370913597007\n",
      "train loss:0.0012031181358176496\n",
      "train loss:0.0006196763510856426\n",
      "train loss:0.0032178835320855813\n",
      "train loss:0.008588330767182031\n",
      "train loss:0.0023268471638972746\n",
      "train loss:0.00492132587054297\n",
      "train loss:0.0009374828219353157\n",
      "train loss:0.0007937519654677359\n",
      "train loss:0.004380820799582474\n",
      "train loss:0.007781697448818149\n",
      "train loss:0.007973672256518233\n",
      "train loss:0.07687941443514668\n",
      "train loss:0.0036095716325583466\n",
      "train loss:0.004830994436795993\n",
      "train loss:0.005305194902648518\n",
      "train loss:0.0013236278172928295\n",
      "train loss:0.0010842151772860367\n",
      "train loss:0.0018786230261906985\n",
      "train loss:0.0058315620352612585\n",
      "train loss:0.005326558850890153\n",
      "train loss:0.001977767012875244\n",
      "train loss:0.0020077445788242677\n",
      "train loss:0.012135553061962859\n",
      "train loss:0.014254004588570164\n",
      "train loss:0.03765742548402679\n",
      "train loss:0.00043866103716886436\n",
      "train loss:0.006894143916953305\n",
      "train loss:0.006980384680522869\n",
      "train loss:0.0019419425331406262\n",
      "train loss:0.0031383674490472768\n",
      "train loss:0.002814499739803683\n",
      "train loss:0.006919290509818451\n",
      "train loss:0.008945466313230194\n",
      "train loss:0.001848548665888124\n",
      "train loss:0.003464208773778106\n",
      "train loss:0.01647963077034917\n",
      "train loss:0.0013995657073996126\n",
      "train loss:0.00325011252629261\n",
      "train loss:0.009124549394265215\n",
      "train loss:0.004062218620321038\n",
      "train loss:0.006241040188203182\n",
      "train loss:0.006021757472516587\n",
      "train loss:0.012092301211165042\n",
      "train loss:0.0010727981443574616\n",
      "train loss:0.0016443857543573385\n",
      "train loss:0.0058031078966864725\n",
      "train loss:0.004395995579658189\n",
      "train loss:0.012294764437993712\n",
      "train loss:0.006561850522839037\n",
      "train loss:0.0041123818746362836\n",
      "train loss:0.0008791826359374372\n",
      "train loss:0.006328268133750329\n",
      "train loss:0.014670805723586706\n",
      "train loss:0.0009359243198733777\n",
      "train loss:0.0019004333485050956\n",
      "train loss:0.0001981816628607222\n",
      "train loss:0.005611707445437709\n",
      "train loss:0.003268850745499672\n",
      "train loss:0.004410328988704382\n",
      "train loss:0.0027581541632081437\n",
      "train loss:0.0007343486741346844\n",
      "train loss:0.008337570481546909\n",
      "train loss:0.046701411473815145\n",
      "train loss:0.0073413321576378055\n",
      "train loss:0.0022330867979461206\n",
      "train loss:0.03250904995407925\n",
      "train loss:0.0018833544185297383\n",
      "train loss:0.008749988673663164\n",
      "train loss:0.001234092622604243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.018729171704625795\n",
      "train loss:0.0010956286697933063\n",
      "train loss:0.002233669985407953\n",
      "train loss:0.0012309425596409116\n",
      "train loss:0.010800512917108134\n",
      "train loss:0.01798279767193963\n",
      "train loss:0.0008966804987659174\n",
      "train loss:0.005751790276316941\n",
      "train loss:0.0060428231224648075\n",
      "train loss:0.005938642107499927\n",
      "train loss:0.0033855756730588452\n",
      "train loss:0.0005559308651807014\n",
      "train loss:0.009142709759434623\n",
      "train loss:0.011247967801856128\n",
      "train loss:0.005586189227338597\n",
      "train loss:0.0004701698613048056\n",
      "train loss:0.00044297045703377806\n",
      "train loss:0.004054407955933029\n",
      "train loss:0.0017450777414976695\n",
      "train loss:0.0018283485745751072\n",
      "train loss:0.0008940461124194295\n",
      "train loss:0.0008885882149449346\n",
      "train loss:0.0008015271140333833\n",
      "train loss:0.004426026354172272\n",
      "train loss:0.012184105529699889\n",
      "train loss:0.0009750734436427416\n",
      "train loss:0.001889725187420771\n",
      "train loss:0.001069232184114834\n",
      "train loss:0.003340840411070883\n",
      "train loss:0.008266972973050905\n",
      "train loss:0.00973187716298575\n",
      "train loss:0.005701685600245492\n",
      "train loss:0.004513169400817364\n",
      "train loss:0.0006594380511784671\n",
      "train loss:0.0011478512053691718\n",
      "train loss:0.012840017073837098\n",
      "train loss:0.004122505351276623\n",
      "train loss:0.00025500885511657015\n",
      "train loss:0.0032858571774178036\n",
      "train loss:0.0009276865053302688\n",
      "train loss:0.004883973587154244\n",
      "train loss:0.0037226114191607662\n",
      "train loss:0.0047555423580297445\n",
      "train loss:0.0015234763659419904\n",
      "train loss:0.004875685783959724\n",
      "train loss:0.003118396866460603\n",
      "train loss:0.00022645837439732235\n",
      "train loss:0.003538315060713451\n",
      "train loss:0.004562931439111181\n",
      "train loss:0.01811478029178841\n",
      "train loss:0.004428516008691977\n",
      "train loss:0.0026202092605716186\n",
      "train loss:0.0015348737282890237\n",
      "train loss:0.0004859432303732892\n",
      "train loss:0.0034011228961786\n",
      "train loss:0.002582150271701744\n",
      "train loss:0.002990011800431129\n",
      "train loss:0.003547476067033803\n",
      "train loss:0.0008333928437393476\n",
      "train loss:0.08780710788044929\n",
      "train loss:0.0008560542761652054\n",
      "train loss:0.011348070778290833\n",
      "train loss:0.007586438413615603\n",
      "train loss:0.003933831210999922\n",
      "train loss:0.005886440453130035\n",
      "train loss:0.03545807237319092\n",
      "train loss:0.0012012818724570031\n",
      "train loss:0.002399785686999446\n",
      "train loss:0.000655431012963877\n",
      "train loss:0.0069675952901140014\n",
      "train loss:0.007170905974490627\n",
      "train loss:0.0008000652966559347\n",
      "train loss:0.0025561301287560564\n",
      "train loss:0.009106433917380584\n",
      "train loss:0.04767096447587086\n",
      "train loss:0.002217598764353728\n",
      "train loss:0.004897945478746503\n",
      "train loss:0.007203688505648985\n",
      "train loss:0.0034834136186211334\n",
      "train loss:0.0008508614510074366\n",
      "train loss:0.004115598820108247\n",
      "train loss:0.00044112868954674977\n",
      "train loss:0.0034267147537081944\n",
      "train loss:0.004967878200599245\n",
      "train loss:0.0036828826105821614\n",
      "train loss:0.004847735206937127\n",
      "train loss:0.00040644434281764184\n",
      "train loss:0.020583741737986574\n",
      "train loss:0.0011028188248535472\n",
      "train loss:0.0013938453415836354\n",
      "train loss:0.005711740309297898\n",
      "train loss:0.009736558171513091\n",
      "train loss:0.04789126561028115\n",
      "train loss:0.005207569520853938\n",
      "train loss:0.00486626791984817\n",
      "train loss:0.006342960182988804\n",
      "train loss:0.014653286516619617\n",
      "train loss:0.005466231504095554\n",
      "train loss:0.003915051980345411\n",
      "train loss:0.0022208381736683806\n",
      "train loss:0.013632854361083387\n",
      "train loss:0.025178388840543565\n",
      "train loss:0.00033983272620282697\n",
      "train loss:0.003568388227788339\n",
      "train loss:0.006575875570832058\n",
      "train loss:0.0021835861000035995\n",
      "=== epoch:12, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.005741896982202075\n",
      "train loss:0.002226540979710402\n",
      "train loss:0.006597831176028054\n",
      "train loss:0.0013877938630716142\n",
      "train loss:0.002507311009308991\n",
      "train loss:0.005479925367201662\n",
      "train loss:0.014252154213404963\n",
      "train loss:0.005108968365663877\n",
      "train loss:0.04013535159458326\n",
      "train loss:0.005092245772152537\n",
      "train loss:0.0029800981809123606\n",
      "train loss:0.007948211203449131\n",
      "train loss:0.003467126856420057\n",
      "train loss:0.04620839392047957\n",
      "train loss:0.004332372890937191\n",
      "train loss:0.0031451914553331534\n",
      "train loss:0.0013554224126633488\n",
      "train loss:0.004142723918352591\n",
      "train loss:0.010579216445820444\n",
      "train loss:0.007462802288276484\n",
      "train loss:0.0002989356998062544\n",
      "train loss:0.005648889902389026\n",
      "train loss:0.0017099919777559744\n",
      "train loss:0.007177395516768891\n",
      "train loss:0.0004985851952876268\n",
      "train loss:0.02017471442252079\n",
      "train loss:0.001625383269222534\n",
      "train loss:0.008159982704433426\n",
      "train loss:0.0022810637594769616\n",
      "train loss:0.007605516906217027\n",
      "train loss:0.005244319853093996\n",
      "train loss:0.0012786233705428052\n",
      "train loss:0.01857195292737488\n",
      "train loss:0.04030190406107198\n",
      "train loss:0.011236696466069609\n",
      "train loss:0.00249987888230152\n",
      "train loss:0.003886954550925529\n",
      "train loss:0.00429567328451789\n",
      "train loss:0.004601803850942097\n",
      "train loss:0.01504053484211098\n",
      "train loss:0.0057029100453831\n",
      "train loss:0.004594717777822072\n",
      "train loss:0.014785730889445363\n",
      "train loss:0.010140199251553999\n",
      "train loss:0.0011742827211016756\n",
      "train loss:0.007481143514491985\n",
      "train loss:0.004433834742917953\n",
      "train loss:0.009929244229853747\n",
      "train loss:0.009123565344748997\n",
      "train loss:0.007450667952213186\n",
      "train loss:0.0023503261532406257\n",
      "train loss:0.017970063593950744\n",
      "train loss:0.02189669099984597\n",
      "train loss:0.015586523743954903\n",
      "train loss:0.028214962968607243\n",
      "train loss:0.004940060481281845\n",
      "train loss:0.006268699700139403\n",
      "train loss:0.06714216687515787\n",
      "train loss:0.0035808006797233474\n",
      "train loss:0.013582846584626794\n",
      "train loss:0.0006716657278001349\n",
      "train loss:0.0016895260074375213\n",
      "train loss:0.01132195450795644\n",
      "train loss:0.012715165336329572\n",
      "train loss:0.0008732567069577795\n",
      "train loss:0.04301167128658809\n",
      "train loss:0.0027468801008485072\n",
      "train loss:0.0057509603223946555\n",
      "train loss:0.0031469449052743074\n",
      "train loss:0.0012022172300818535\n",
      "train loss:0.0032780591780882185\n",
      "train loss:0.004771367361067757\n",
      "train loss:0.007769388542936719\n",
      "train loss:0.004460539714431825\n",
      "train loss:0.009012984951744693\n",
      "train loss:0.0033324360542657766\n",
      "train loss:0.0017133243359401843\n",
      "train loss:0.0011561076161545215\n",
      "train loss:0.006257235967026617\n",
      "train loss:0.0038426994240999108\n",
      "train loss:0.00480990775824595\n",
      "train loss:0.0023541166826692075\n",
      "train loss:0.000987277919925934\n",
      "train loss:0.0011604628284115235\n",
      "train loss:0.0072775714138177535\n",
      "train loss:0.00823697725971672\n",
      "train loss:0.00437350367716619\n",
      "train loss:0.0047490706798337425\n",
      "train loss:0.008295771010929343\n",
      "train loss:0.0036829676841611653\n",
      "train loss:0.00597602008293787\n",
      "train loss:0.002315113494910033\n",
      "train loss:0.0020436517145368755\n",
      "train loss:0.0015750107612711934\n",
      "train loss:0.0022999553024607585\n",
      "train loss:0.00490451832641775\n",
      "train loss:0.0009898486157435087\n",
      "train loss:0.0009876939454204067\n",
      "train loss:0.0021951216010526364\n",
      "train loss:0.02290503123184321\n",
      "train loss:0.002544056577826088\n",
      "train loss:0.0064568140103081475\n",
      "train loss:0.0034914717995832016\n",
      "train loss:0.020387051367651753\n",
      "train loss:0.0033049013729118306\n",
      "train loss:0.001704661301446726\n",
      "train loss:0.0014256982133435856\n",
      "train loss:0.008483010007619852\n",
      "train loss:0.006284722333342509\n",
      "train loss:0.0022554484493289744\n",
      "train loss:0.004398123078325084\n",
      "train loss:0.0011605484050157715\n",
      "train loss:0.0029914477113337818\n",
      "train loss:0.002888216029478821\n",
      "train loss:0.0002525990736757635\n",
      "train loss:0.00752686948405285\n",
      "train loss:0.05676502726110365\n",
      "train loss:0.004312527283944965\n",
      "train loss:0.0025732696469828327\n",
      "train loss:0.007614552176762344\n",
      "train loss:0.04400024411173779\n",
      "train loss:0.0042083024550641605\n",
      "train loss:0.005012682904801953\n",
      "train loss:0.005106014878888077\n",
      "train loss:0.003737994385731852\n",
      "train loss:0.004009289529384381\n",
      "train loss:0.023790092787329468\n",
      "train loss:0.002802621694478866\n",
      "train loss:0.0014288773267817963\n",
      "train loss:0.0037565078441852457\n",
      "train loss:0.0014246173474189488\n",
      "train loss:0.013340498922066336\n",
      "train loss:0.0023788390361351034\n",
      "train loss:0.00478949970734784\n",
      "train loss:0.0033542384465888916\n",
      "train loss:0.0002769608546532281\n",
      "train loss:0.011367741594741814\n",
      "train loss:0.007190125978844583\n",
      "train loss:0.014459260159785303\n",
      "train loss:0.0009596749447750684\n",
      "train loss:0.009295105124941905\n",
      "train loss:0.0028749817216770735\n",
      "train loss:0.004089202934476158\n",
      "train loss:0.006160684802104795\n",
      "train loss:0.0016661352691735257\n",
      "train loss:0.0023781638283080888\n",
      "train loss:0.09741703790872125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003153347377494442\n",
      "train loss:0.0047239975017869555\n",
      "train loss:0.011620079664934004\n",
      "train loss:0.005079821854981042\n",
      "train loss:0.006210630889047223\n",
      "train loss:0.0022143737720657186\n",
      "train loss:0.016000753085605956\n",
      "train loss:0.012435776498560576\n",
      "train loss:0.0038548074338445744\n",
      "train loss:0.0007568381407991077\n",
      "train loss:0.005477416981623601\n",
      "train loss:0.0008875345479179446\n",
      "train loss:0.006547731561053813\n",
      "train loss:0.005043952337069644\n",
      "train loss:0.000940510177533072\n",
      "train loss:0.006599698269610662\n",
      "train loss:0.001239770728203032\n",
      "train loss:0.007393300241391421\n",
      "train loss:0.0021898734205623056\n",
      "train loss:0.004216608978677233\n",
      "train loss:0.013541577122021293\n",
      "train loss:0.01577568760822679\n",
      "train loss:0.0038602920317069977\n",
      "train loss:0.0021667380732652963\n",
      "train loss:0.005623511534752682\n",
      "train loss:0.011283951692750474\n",
      "train loss:0.012984081793027114\n",
      "train loss:0.003099038374414153\n",
      "train loss:0.003791439254160546\n",
      "train loss:0.0016226766652427923\n",
      "train loss:0.0065713210632717565\n",
      "train loss:0.001786392061800824\n",
      "train loss:0.0012041203542752779\n",
      "train loss:0.004092886580266491\n",
      "train loss:0.011323488428156806\n",
      "train loss:0.018501068278034685\n",
      "train loss:0.0018330179883699295\n",
      "train loss:0.03603198934970903\n",
      "train loss:0.009974665709939316\n",
      "train loss:0.0006477909187746642\n",
      "train loss:0.026890707705281104\n",
      "train loss:0.003726375807161392\n",
      "train loss:0.0025026867063486914\n",
      "train loss:0.005308980378932742\n",
      "train loss:0.013841744032992796\n",
      "train loss:0.00016735314915842473\n",
      "train loss:0.004955269734031527\n",
      "train loss:0.006071730824751686\n",
      "train loss:0.002575534789707544\n",
      "train loss:0.0012514299456894862\n",
      "train loss:0.007447715308291502\n",
      "train loss:0.024416664853578227\n",
      "train loss:0.003433494154644253\n",
      "train loss:0.012134754291117726\n",
      "train loss:0.000739473259224252\n",
      "train loss:0.006544556207318587\n",
      "train loss:0.008371013830442755\n",
      "train loss:0.0048718505107333806\n",
      "train loss:0.0034540820387762763\n",
      "train loss:0.0232399034908424\n",
      "train loss:0.012034907135359341\n",
      "train loss:0.0007436177625957722\n",
      "train loss:0.004698190211547407\n",
      "train loss:0.008115034467376537\n",
      "train loss:0.0038832009305350326\n",
      "train loss:0.004874499179188229\n",
      "train loss:0.0008967740480777704\n",
      "train loss:0.003862585483410749\n",
      "train loss:0.04068855934985135\n",
      "train loss:0.035238899679975344\n",
      "train loss:0.007695400732091318\n",
      "train loss:0.009649298245648634\n",
      "train loss:0.00647579954295576\n",
      "train loss:0.014378166074223318\n",
      "train loss:0.003415702477095405\n",
      "train loss:0.00323357221655164\n",
      "train loss:0.006126571521775676\n",
      "train loss:0.0015846573544600901\n",
      "train loss:0.0031271939425662537\n",
      "train loss:0.004128840059959122\n",
      "train loss:0.008338024463549101\n",
      "train loss:0.002700432877475002\n",
      "train loss:0.0018389102421607552\n",
      "train loss:0.007377774810120622\n",
      "train loss:0.007568353357577892\n",
      "train loss:0.00796244434793884\n",
      "train loss:0.008930494458869951\n",
      "train loss:0.005009615299582664\n",
      "train loss:0.013911085006332648\n",
      "train loss:0.01259493187806557\n",
      "train loss:0.005898720556174058\n",
      "train loss:0.003267375681368665\n",
      "train loss:0.002664979661403919\n",
      "train loss:0.015938417522609515\n",
      "train loss:0.07259460367167705\n",
      "train loss:0.003983295630269413\n",
      "train loss:0.0016778303282474999\n",
      "train loss:0.005793943633670058\n",
      "train loss:0.0065318408934539295\n",
      "train loss:0.006935538171534738\n",
      "train loss:0.010935581911613663\n",
      "train loss:0.00587284252382657\n",
      "train loss:0.0024502274466897405\n",
      "train loss:0.01168669074743194\n",
      "train loss:0.0015636733223045535\n",
      "train loss:0.051570115117841826\n",
      "train loss:0.006164372666058071\n",
      "train loss:0.006356239957430172\n",
      "train loss:0.009091587529490252\n",
      "train loss:0.0006455885248947236\n",
      "train loss:0.0008698830418952276\n",
      "train loss:0.002167141997613577\n",
      "train loss:0.004731779301211782\n",
      "train loss:0.001165733357926642\n",
      "train loss:0.004869248219494129\n",
      "train loss:0.006864465567367054\n",
      "train loss:0.012728547293216617\n",
      "train loss:0.016172020284345768\n",
      "train loss:0.163175395401074\n",
      "train loss:0.009916744178495314\n",
      "train loss:0.0008656191272594499\n",
      "train loss:0.001949986987506914\n",
      "train loss:0.007159779704187534\n",
      "train loss:0.002432160371282833\n",
      "train loss:0.007986961372165445\n",
      "train loss:0.0037218023812847522\n",
      "train loss:0.00978249860749221\n",
      "train loss:0.0010553737819424139\n",
      "train loss:0.0010891586176075298\n",
      "train loss:0.009535944794901205\n",
      "train loss:0.0027153585343604376\n",
      "train loss:0.0015249987912720276\n",
      "train loss:0.00741970158845259\n",
      "train loss:0.0051795729615988625\n",
      "train loss:0.0020844783067784714\n",
      "train loss:0.003507605049892678\n",
      "train loss:0.007447586119028088\n",
      "train loss:0.0008653143633362527\n",
      "train loss:0.008110264472549195\n",
      "train loss:0.0009681117582422555\n",
      "train loss:0.016632711697505572\n",
      "train loss:0.0014409484343565482\n",
      "train loss:0.14127941232080782\n",
      "train loss:0.001498014333602504\n",
      "train loss:0.0065683908427348605\n",
      "train loss:0.0013043962994479575\n",
      "train loss:0.005451617687385363\n",
      "train loss:0.0024267920092475377\n",
      "train loss:0.0056957606382159985\n",
      "train loss:0.007215991606015322\n",
      "train loss:0.002386871068011329\n",
      "train loss:0.023448843218731055\n",
      "train loss:0.007170775879295281\n",
      "train loss:0.06586269552533579\n",
      "train loss:0.0032278210443091155\n",
      "train loss:0.0016169445631641778\n",
      "train loss:0.0011727441721815903\n",
      "train loss:0.008515583199666834\n",
      "train loss:0.010349631541263163\n",
      "train loss:0.000837128607732145\n",
      "train loss:0.0020161246226622774\n",
      "train loss:0.028729945320143425\n",
      "train loss:0.0021418335306529843\n",
      "train loss:0.005712676307236234\n",
      "train loss:0.029287151845800587\n",
      "train loss:0.009273884990919613\n",
      "train loss:0.004084887087251366\n",
      "train loss:0.0027513829841866494\n",
      "train loss:0.002248941566344258\n",
      "train loss:0.002956451052692534\n",
      "train loss:0.0006972639175348925\n",
      "train loss:0.0015730072797270366\n",
      "train loss:0.005257822927448669\n",
      "train loss:0.013234534677666143\n",
      "train loss:0.004241578013364447\n",
      "train loss:0.006197944685152135\n",
      "train loss:0.0410556873024302\n",
      "train loss:0.009740308312123264\n",
      "train loss:0.006125630500133427\n",
      "train loss:0.0016015629204544077\n",
      "train loss:0.0022854727220717845\n",
      "train loss:0.0011048975066056397\n",
      "train loss:0.0031100547518495814\n",
      "train loss:0.0026224267052213433\n",
      "train loss:0.0016097808273378069\n",
      "train loss:0.0020476785536519544\n",
      "train loss:0.009363560825518064\n",
      "train loss:0.010273973869080967\n",
      "train loss:0.0013516144077837704\n",
      "train loss:0.00531700803738741\n",
      "train loss:0.003937223430371894\n",
      "train loss:0.0011656413605204922\n",
      "train loss:0.025609281106386127\n",
      "train loss:0.006661717875866318\n",
      "train loss:0.04213692618985337\n",
      "train loss:0.0008442325247076997\n",
      "train loss:0.00961014303703869\n",
      "train loss:0.002945805716871548\n",
      "train loss:0.0020997230360082497\n",
      "train loss:0.003532524660444053\n",
      "train loss:0.0008530128721267818\n",
      "train loss:0.0009110646743979985\n",
      "train loss:0.0064233031793883046\n",
      "train loss:0.003508749690457048\n",
      "train loss:0.019839152243283455\n",
      "train loss:0.0004550673420385358\n",
      "train loss:0.0027344940270193846\n",
      "train loss:0.004421592607397804\n",
      "train loss:0.007962792680463737\n",
      "train loss:0.001829365549085735\n",
      "train loss:0.0018554167805614795\n",
      "train loss:0.0312669611446637\n",
      "train loss:0.005875148556667149\n",
      "train loss:0.005724910600546228\n",
      "train loss:0.0012699448925510503\n",
      "train loss:0.004848125712385232\n",
      "train loss:0.008970607506788983\n",
      "train loss:0.0011104469324506434\n",
      "train loss:0.0018481876838157153\n",
      "train loss:0.011977943473102513\n",
      "train loss:0.0029598668059714326\n",
      "train loss:0.0013188998567169763\n",
      "train loss:0.007530547940567281\n",
      "train loss:0.003802137129573298\n",
      "train loss:0.0011049867132451434\n",
      "train loss:0.0021826459295349425\n",
      "train loss:0.019389671906210156\n",
      "train loss:0.0005879109571208798\n",
      "train loss:0.005379532099124327\n",
      "train loss:0.007408692053639827\n",
      "train loss:0.0020659062262331327\n",
      "train loss:0.0022733271570014456\n",
      "train loss:0.012908877243995904\n",
      "train loss:0.006848260972888697\n",
      "train loss:0.01006257876224041\n",
      "train loss:0.007279437279289219\n",
      "train loss:0.009132839646982256\n",
      "train loss:0.009739015358879707\n",
      "train loss:0.0008599533416545781\n",
      "train loss:0.0009994864335399992\n",
      "train loss:0.0016524479059289888\n",
      "train loss:0.0031116051093923146\n",
      "train loss:0.005431472138493824\n",
      "train loss:0.011224785184910387\n",
      "train loss:0.004174599774667584\n",
      "train loss:0.008012510253732345\n",
      "train loss:0.0015033657125796745\n",
      "train loss:0.002699625828132847\n",
      "train loss:0.0003891991335995647\n",
      "train loss:0.0027565373233030066\n",
      "train loss:0.0015306444690552077\n",
      "train loss:0.0034664708209000894\n",
      "train loss:0.003572936772534602\n",
      "train loss:0.007104928672201306\n",
      "train loss:0.0022008796427387574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009324628998356156\n",
      "train loss:0.010916929176975758\n",
      "train loss:0.0012963063836545546\n",
      "train loss:0.017323033737838688\n",
      "train loss:0.033822099446993444\n",
      "train loss:0.006389878596338905\n",
      "train loss:0.0027610500414642146\n",
      "train loss:0.008731025334199697\n",
      "train loss:0.0016288029819452846\n",
      "train loss:0.007349417083801029\n",
      "train loss:0.006674433028269217\n",
      "train loss:0.0007936979814268634\n",
      "train loss:0.013464242582094686\n",
      "train loss:0.005505519785264267\n",
      "train loss:0.0030373424014211504\n",
      "train loss:0.006896525709197069\n",
      "train loss:0.0056667959265037015\n",
      "train loss:0.029855673834679904\n",
      "train loss:0.0026874227219688346\n",
      "train loss:0.010949658935462812\n",
      "train loss:0.0010123495078850858\n",
      "train loss:0.007810293692913845\n",
      "train loss:0.0030850335980668574\n",
      "train loss:0.003108337174354519\n",
      "train loss:0.0036436561300484316\n",
      "train loss:0.018981612578635624\n",
      "train loss:0.00593860658413348\n",
      "train loss:0.0021817113255462577\n",
      "train loss:0.0007226120402948374\n",
      "train loss:0.006869032816014354\n",
      "train loss:0.0003947639260437634\n",
      "train loss:0.002858058588621027\n",
      "train loss:0.004515074316265977\n",
      "train loss:0.000613839527120692\n",
      "train loss:0.001547291412745131\n",
      "train loss:0.00044238898787487874\n",
      "train loss:0.003959425787450674\n",
      "train loss:0.0020975524674246796\n",
      "train loss:0.03195187178606089\n",
      "train loss:0.0002130690209121531\n",
      "train loss:0.004745896968570619\n",
      "train loss:0.006040501245565729\n",
      "train loss:0.001922482623407284\n",
      "train loss:0.0004820989408580799\n",
      "train loss:0.003935241032214709\n",
      "train loss:0.003376313331300629\n",
      "train loss:0.0016556559975455646\n",
      "train loss:0.0033142278986778104\n",
      "train loss:0.0112456796747953\n",
      "train loss:0.023271695812910168\n",
      "train loss:0.013728326488203366\n",
      "train loss:0.012678248598520814\n",
      "train loss:0.006606630390995097\n",
      "train loss:0.006717583925448503\n",
      "train loss:0.012211733457807301\n",
      "train loss:0.004231311096204087\n",
      "train loss:0.011226762960845921\n",
      "train loss:0.0017590876109295141\n",
      "train loss:0.008182986804812317\n",
      "train loss:0.036846715986967794\n",
      "train loss:0.010526237322716205\n",
      "train loss:0.024220539986794506\n",
      "train loss:0.005017130423052848\n",
      "train loss:0.002514238699525244\n",
      "train loss:0.009229575924589672\n",
      "train loss:0.000803206294448007\n",
      "train loss:0.001984242735516442\n",
      "train loss:0.009624305498830133\n",
      "train loss:0.0020240574379590415\n",
      "train loss:0.022513230613273663\n",
      "train loss:0.005487573048185169\n",
      "train loss:0.000795277746199564\n",
      "train loss:0.007984858818786722\n",
      "train loss:0.0037070047449028936\n",
      "train loss:0.002882990796357327\n",
      "train loss:0.0013868560417237949\n",
      "train loss:0.0012909017866892427\n",
      "train loss:0.0030114305067348458\n",
      "train loss:0.00652663435313217\n",
      "train loss:0.0045767151490305165\n",
      "train loss:0.018425813167772764\n",
      "train loss:0.0012345359193168442\n",
      "train loss:0.008011640615852036\n",
      "train loss:0.005707193438425253\n",
      "train loss:0.005711544417012987\n",
      "train loss:0.0007249356408831467\n",
      "train loss:0.0024267982712345136\n",
      "train loss:0.006322478852758479\n",
      "train loss:0.0003463793864702257\n",
      "train loss:0.0005970967326084115\n",
      "train loss:0.009328605382080968\n",
      "train loss:0.0007663049639333092\n",
      "train loss:0.005114518857492144\n",
      "train loss:0.004073200653220504\n",
      "train loss:0.0005300946334796267\n",
      "train loss:0.00026961653262463746\n",
      "train loss:0.015319919324198048\n",
      "train loss:0.0033443295787857403\n",
      "train loss:0.002444713074816437\n",
      "train loss:0.0056425353464471355\n",
      "train loss:0.0007839198908677656\n",
      "train loss:0.0025109010961308644\n",
      "train loss:0.01349352159315045\n",
      "train loss:0.00941502136805717\n",
      "train loss:0.002499086604240483\n",
      "train loss:0.0005890134228017101\n",
      "train loss:0.013170323861484154\n",
      "train loss:0.008005875388433323\n",
      "train loss:0.02449187391646964\n",
      "train loss:0.0016844981315724992\n",
      "train loss:0.0007348194184121624\n",
      "train loss:0.0003804044488639317\n",
      "train loss:0.003615298034934537\n",
      "train loss:0.0039172413771837505\n",
      "train loss:0.005594687324807491\n",
      "train loss:0.02779592052683134\n",
      "train loss:0.0015605285877862563\n",
      "train loss:0.021540357347657902\n",
      "train loss:0.0019647348126143787\n",
      "train loss:0.004466905590086437\n",
      "train loss:0.002946505055498877\n",
      "train loss:0.005028263109782502\n",
      "train loss:0.002538974867090017\n",
      "train loss:0.0071877664676569565\n",
      "train loss:0.0018068640550753068\n",
      "train loss:0.002810342709573817\n",
      "train loss:0.030027681422235376\n",
      "train loss:0.0019701540630925377\n",
      "train loss:0.00314231606525449\n",
      "train loss:0.004940997092724965\n",
      "train loss:0.0008446119415247604\n",
      "train loss:0.005257878434828717\n",
      "train loss:0.00914538692305474\n",
      "train loss:0.0047161182588959915\n",
      "train loss:0.002523936566780813\n",
      "train loss:0.007362829449397312\n",
      "train loss:0.003402035085206398\n",
      "train loss:0.012866894397003528\n",
      "train loss:0.0066785092141927495\n",
      "train loss:0.0010741058115321805\n",
      "train loss:0.003723165794654351\n",
      "train loss:0.002670114873129522\n",
      "train loss:0.008598228282914101\n",
      "train loss:0.0026069757564174383\n",
      "train loss:0.007490470367423087\n",
      "train loss:0.0014736188322463683\n",
      "train loss:0.005686760907708633\n",
      "train loss:0.001958852082925474\n",
      "train loss:0.029429110485856773\n",
      "train loss:0.0019442827251455195\n",
      "train loss:0.0063648050711590685\n",
      "train loss:0.026396517169085233\n",
      "train loss:0.013418224548428925\n",
      "train loss:0.00028779562946059734\n",
      "train loss:0.004961911177226203\n",
      "train loss:0.0012499488744203628\n",
      "train loss:0.0044620995526424775\n",
      "train loss:0.011743833967114967\n",
      "train loss:0.0033170493379597473\n",
      "train loss:0.00221634122504054\n",
      "train loss:0.01572349447990709\n",
      "train loss:0.008669151814301779\n",
      "train loss:0.007704938159972723\n",
      "train loss:0.0012734275519442318\n",
      "train loss:0.0010954337676618276\n",
      "train loss:0.003462110594373667\n",
      "train loss:0.008615912335342592\n",
      "train loss:0.004050003905801948\n",
      "train loss:0.029533936973256406\n",
      "train loss:0.0031097144296430668\n",
      "train loss:0.002244367553573023\n",
      "train loss:0.009938878109147052\n",
      "train loss:0.0109931260337101\n",
      "train loss:0.04294091476042332\n",
      "train loss:0.0025711438960638504\n",
      "train loss:0.007425104934202957\n",
      "train loss:0.001766436968565014\n",
      "train loss:0.004061434803369962\n",
      "train loss:0.0074807971605896995\n",
      "train loss:0.01986663737519018\n",
      "train loss:0.001540034257352845\n",
      "train loss:0.0034189526301165746\n",
      "train loss:0.012573579552822041\n",
      "train loss:0.04537735336894087\n",
      "train loss:0.0030964218288762734\n",
      "train loss:0.006560105070272187\n",
      "train loss:0.0029687575078274487\n",
      "train loss:0.13929160720245318\n",
      "train loss:0.0038865981844262727\n",
      "train loss:0.010441684686625177\n",
      "train loss:0.027830953486790398\n",
      "train loss:0.0025251980729455127\n",
      "train loss:0.0031798446283320342\n",
      "train loss:0.00563557874389058\n",
      "train loss:0.021579237495703767\n",
      "train loss:0.006577885604064392\n",
      "train loss:0.0009145962118743636\n",
      "train loss:0.002262718254457049\n",
      "=== epoch:13, train acc:0.996, test acc:0.988 ===\n",
      "train loss:0.017748760620364477\n",
      "train loss:0.017216994898795426\n",
      "train loss:0.0038049832749782147\n",
      "train loss:0.002382285140322833\n",
      "train loss:0.013410128742402888\n",
      "train loss:0.09000893916425272\n",
      "train loss:0.004393835797663735\n",
      "train loss:0.003978789476536402\n",
      "train loss:0.003052505212810205\n",
      "train loss:0.010533707888389714\n",
      "train loss:0.004069224365330005\n",
      "train loss:0.0031900569362577364\n",
      "train loss:0.007033163159878317\n",
      "train loss:0.0031036202820147623\n",
      "train loss:0.0019394274801202852\n",
      "train loss:0.013720501212498924\n",
      "train loss:0.007990139103144877\n",
      "train loss:0.00643878627828927\n",
      "train loss:0.00593896028041038\n",
      "train loss:0.0027856625095733223\n",
      "train loss:0.03229274769666861\n",
      "train loss:0.0057181160749605435\n",
      "train loss:0.0035327898756723325\n",
      "train loss:0.002397649780308266\n",
      "train loss:0.00893100654062393\n",
      "train loss:0.001732519672022595\n",
      "train loss:0.0027037298933977193\n",
      "train loss:0.0011391737197524907\n",
      "train loss:0.0011906507095986159\n",
      "train loss:0.014465287879783784\n",
      "train loss:0.01183314431163296\n",
      "train loss:0.000462605531088322\n",
      "train loss:0.0033282896963529717\n",
      "train loss:0.005703504291089289\n",
      "train loss:0.00394743238650612\n",
      "train loss:0.0013484039688333818\n",
      "train loss:0.0024545633794701713\n",
      "train loss:0.0008055449957369031\n",
      "train loss:0.006020732974254281\n",
      "train loss:0.0017205763963373077\n",
      "train loss:0.005760001452228728\n",
      "train loss:0.005078912023980198\n",
      "train loss:0.012859998200737584\n",
      "train loss:0.006616401065736019\n",
      "train loss:0.0037392469681949867\n",
      "train loss:0.0024069034491725834\n",
      "train loss:0.0038812655179826534\n",
      "train loss:0.01793564396874582\n",
      "train loss:0.00228371611737409\n",
      "train loss:0.003483049507487905\n",
      "train loss:0.0009865501152111291\n",
      "train loss:0.0064129125806750694\n",
      "train loss:0.0017318224703468212\n",
      "train loss:0.0023117913897490795\n",
      "train loss:0.002445419202150752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014838172072551507\n",
      "train loss:0.0038376230457166805\n",
      "train loss:0.0019476801879969579\n",
      "train loss:0.0032343339004723883\n",
      "train loss:0.0007231867182858193\n",
      "train loss:0.003871836152023026\n",
      "train loss:0.002901163281157921\n",
      "train loss:0.008341150465038359\n",
      "train loss:0.009534998678842617\n",
      "train loss:0.004091806736727245\n",
      "train loss:0.00589041962745427\n",
      "train loss:0.0012116736023203437\n",
      "train loss:0.013160586713558626\n",
      "train loss:0.017274519892192763\n",
      "train loss:0.0016648049194139842\n",
      "train loss:0.0018117853994100124\n",
      "train loss:0.00036492590035228887\n",
      "train loss:0.024567401200890196\n",
      "train loss:0.008159023075789897\n",
      "train loss:0.004658199513500862\n",
      "train loss:0.002610158542217389\n",
      "train loss:0.0019476280504064272\n",
      "train loss:0.0019054711263494473\n",
      "train loss:0.028129285383565298\n",
      "train loss:0.003115423211006196\n",
      "train loss:0.0019993888171621396\n",
      "train loss:0.0012602240893008461\n",
      "train loss:0.00493390499771278\n",
      "train loss:0.002705544283091186\n",
      "train loss:0.004980127345367054\n",
      "train loss:0.0012728504055163634\n",
      "train loss:0.0006544809699946013\n",
      "train loss:0.0005783585883580902\n",
      "train loss:0.005108431046597802\n",
      "train loss:0.0014110491843636055\n",
      "train loss:0.00474437723618443\n",
      "train loss:0.007601768556616555\n",
      "train loss:0.0038736190027242384\n",
      "train loss:0.005937571628904764\n",
      "train loss:0.015533995951258164\n",
      "train loss:0.02412588230228978\n",
      "train loss:0.0010003689955289932\n",
      "train loss:0.00011859947374264858\n",
      "train loss:0.004658892488262486\n",
      "train loss:0.00039113211726495847\n",
      "train loss:0.004441391504446859\n",
      "train loss:0.005172339201630265\n",
      "train loss:0.0010371119059761499\n",
      "train loss:0.0005026409677791009\n",
      "train loss:0.003166751368647312\n",
      "train loss:0.0036108381446787524\n",
      "train loss:0.005723147646804468\n",
      "train loss:0.008141998208012749\n",
      "train loss:0.0007763600214974664\n",
      "train loss:0.0016642084310810321\n",
      "train loss:0.007853336802822101\n",
      "train loss:0.00020618294742755962\n",
      "train loss:0.00031492305916149807\n",
      "train loss:0.0021067273681375357\n",
      "train loss:0.010309474023243812\n",
      "train loss:0.0016709121571566725\n",
      "train loss:0.003670266210558938\n",
      "train loss:0.0020492281943461986\n",
      "train loss:0.0029426600120230533\n",
      "train loss:0.0009397134797901794\n",
      "train loss:0.00038306805495600565\n",
      "train loss:0.009189168005842357\n",
      "train loss:0.0038721067451518193\n",
      "train loss:0.003010735631419652\n",
      "train loss:0.012342840637458044\n",
      "train loss:0.004675661403740458\n",
      "train loss:0.01325386297215536\n",
      "train loss:0.0011372045889539465\n",
      "train loss:0.0035012324108112673\n",
      "train loss:0.0024299955503623554\n",
      "train loss:0.0007979892030834139\n",
      "train loss:0.0003135409536452937\n",
      "train loss:0.007803156125733829\n",
      "train loss:0.0015591802449125413\n",
      "train loss:0.004057783148121436\n",
      "train loss:0.0004080437709013969\n",
      "train loss:0.024774214281989372\n",
      "train loss:0.045031641200775914\n",
      "train loss:0.005771030485837921\n",
      "train loss:0.00028975014294360646\n",
      "train loss:0.0054808282285273725\n",
      "train loss:0.007234918417039778\n",
      "train loss:0.005289933829515811\n",
      "train loss:0.0026643851578898375\n",
      "train loss:0.002748530549779884\n",
      "train loss:0.01534178532135531\n",
      "train loss:0.001842684366585982\n",
      "train loss:0.0005354717344045161\n",
      "train loss:0.005383099765004226\n",
      "train loss:0.01303055250462989\n",
      "train loss:0.0008415206132053914\n",
      "train loss:0.006677622352070205\n",
      "train loss:0.004337961845282431\n",
      "train loss:0.0030604143042649344\n",
      "train loss:0.001544132840000856\n",
      "train loss:0.0030456237772785964\n",
      "train loss:0.0004804832296952949\n",
      "train loss:0.0020139298535321983\n",
      "train loss:0.003932456266495733\n",
      "train loss:0.002540083071790402\n",
      "train loss:0.00036600495631200546\n",
      "train loss:0.0026946603787901696\n",
      "train loss:0.0011330849291085255\n",
      "train loss:0.01385740243987359\n",
      "train loss:0.0008200299477955556\n",
      "train loss:0.0007961342181923861\n",
      "train loss:0.0021961291644566317\n",
      "train loss:0.0006115257861635791\n",
      "train loss:0.0010076473666805088\n",
      "train loss:0.00155366099339192\n",
      "train loss:0.0016455551758687958\n",
      "train loss:0.0002568819124375581\n",
      "train loss:0.006438251985236032\n",
      "train loss:0.00034934828543122307\n",
      "train loss:0.004357044832931171\n",
      "train loss:0.013298759181316525\n",
      "train loss:0.002414745661578361\n",
      "train loss:0.004129379176478377\n",
      "train loss:0.0024187346788307022\n",
      "train loss:0.004649580350247835\n",
      "train loss:0.0001812078656118751\n",
      "train loss:0.003007319307931243\n",
      "train loss:0.007318425300254834\n",
      "train loss:0.0030318191550698387\n",
      "train loss:0.0038470915382987038\n",
      "train loss:0.002829264870297475\n",
      "train loss:0.007011182338580459\n",
      "train loss:0.029149174297002426\n",
      "train loss:0.001778540992460212\n",
      "train loss:0.0004471415259336051\n",
      "train loss:0.014132249648469073\n",
      "train loss:0.0028016851952240274\n",
      "train loss:0.0013005796157309843\n",
      "train loss:0.0024524840247544576\n",
      "train loss:0.005839514463062109\n",
      "train loss:0.046188278888592275\n",
      "train loss:0.0007090529445003039\n",
      "train loss:0.0007280486859363476\n",
      "train loss:0.0005133988535490553\n",
      "train loss:0.0024603021475202986\n",
      "train loss:0.0004420810362114469\n",
      "train loss:0.01814466347209311\n",
      "train loss:0.0008348660497298992\n",
      "train loss:0.01820176306356607\n",
      "train loss:0.0019006124019474685\n",
      "train loss:0.0042460258218674765\n",
      "train loss:0.013996509448408544\n",
      "train loss:0.0005576340853750185\n",
      "train loss:0.005774577455284675\n",
      "train loss:0.0005672018658234207\n",
      "train loss:0.0029627917540277354\n",
      "train loss:0.00044400454790811033\n",
      "train loss:0.001705469725208933\n",
      "train loss:0.001197101270094017\n",
      "train loss:0.0015794244576532186\n",
      "train loss:0.014356769442950456\n",
      "train loss:0.003760922411354924\n",
      "train loss:0.009503255034685623\n",
      "train loss:0.023038016965398544\n",
      "train loss:0.005044575182274128\n",
      "train loss:0.011240340087958923\n",
      "train loss:0.00500057820208456\n",
      "train loss:0.006450910863407456\n",
      "train loss:0.015780997548350918\n",
      "train loss:0.013526851399300398\n",
      "train loss:0.00020702924652998302\n",
      "train loss:0.0004858565860404508\n",
      "train loss:0.0010883196690539363\n",
      "train loss:0.0013698417501981773\n",
      "train loss:0.0016203233742895038\n",
      "train loss:0.018106588047325848\n",
      "train loss:0.006728751439630132\n",
      "train loss:0.005362645476387765\n",
      "train loss:0.0066119453494544725\n",
      "train loss:0.02493366048867117\n",
      "train loss:0.0034677294275105006\n",
      "train loss:0.003573551913681133\n",
      "train loss:0.004862292578351482\n",
      "train loss:0.0006985278793559045\n",
      "train loss:0.0022950177528362425\n",
      "train loss:0.002545090482783403\n",
      "train loss:0.002165629104616524\n",
      "train loss:0.00463889814583865\n",
      "train loss:0.004500809785741295\n",
      "train loss:0.0031700051620003715\n",
      "train loss:0.011839343200028463\n",
      "train loss:0.000423570294662685\n",
      "train loss:0.0015406374101600573\n",
      "train loss:0.00301644051931514\n",
      "train loss:0.009529441109726939\n",
      "train loss:0.01738958993831875\n",
      "train loss:0.0010699545627709903\n",
      "train loss:0.0018224490764484713\n",
      "train loss:0.015163592523134557\n",
      "train loss:0.009913811662375462\n",
      "train loss:0.0026984597123889385\n",
      "train loss:0.001981649110788826\n",
      "train loss:0.022471147900325738\n",
      "train loss:0.0009199948652814826\n",
      "train loss:0.002040275219589649\n",
      "train loss:0.0024405721046087594\n",
      "train loss:0.0043189341165899495\n",
      "train loss:0.001338202698382327\n",
      "train loss:0.0007019039135031986\n",
      "train loss:0.002964973855586023\n",
      "train loss:0.005713312946211312\n",
      "train loss:0.0023843918087036032\n",
      "train loss:0.005744548579350286\n",
      "train loss:0.005035515415778747\n",
      "train loss:0.008366525349171707\n",
      "train loss:0.05990495953808203\n",
      "train loss:0.0024916563406904443\n",
      "train loss:0.003818874578219293\n",
      "train loss:0.04874702246013947\n",
      "train loss:0.00548072210379977\n",
      "train loss:0.008100219375498218\n",
      "train loss:0.0010331580190098791\n",
      "train loss:0.008381595769247394\n",
      "train loss:0.02128113578091268\n",
      "train loss:0.007013009393094836\n",
      "train loss:0.006638901353481734\n",
      "train loss:0.003626295814326491\n",
      "train loss:0.0011027420948598275\n",
      "train loss:0.0025790462845991487\n",
      "train loss:0.002468226552362432\n",
      "train loss:0.01583067841210191\n",
      "train loss:0.003874891333875001\n",
      "train loss:0.015783671378886307\n",
      "train loss:0.0044958303966864555\n",
      "train loss:0.003735071405502751\n",
      "train loss:0.001096579635449378\n",
      "train loss:0.003031428704976082\n",
      "train loss:0.0038112292363909344\n",
      "train loss:0.0034370010553007035\n",
      "train loss:0.0026435036021306697\n",
      "train loss:0.0019964433657353297\n",
      "train loss:0.003074228046842207\n",
      "train loss:0.000793572554704222\n",
      "train loss:0.003968790602071679\n",
      "train loss:0.001481904495146197\n",
      "train loss:0.004779624634059723\n",
      "train loss:0.009111721452821585\n",
      "train loss:0.004774230292275475\n",
      "train loss:0.007411238096935925\n",
      "train loss:0.0019129271766253058\n",
      "train loss:0.0005307138267202909\n",
      "train loss:0.005574144290477794\n",
      "train loss:0.009666829141471834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005598205765081078\n",
      "train loss:0.002096034174702119\n",
      "train loss:0.002350154434490811\n",
      "train loss:0.0013241607447555576\n",
      "train loss:0.01742720670837295\n",
      "train loss:0.008300722691952797\n",
      "train loss:0.00425425846162805\n",
      "train loss:0.009574396303289842\n",
      "train loss:0.0007429279121186601\n",
      "train loss:0.0011072647743559517\n",
      "train loss:0.00237709326558919\n",
      "train loss:0.0036446182948418667\n",
      "train loss:0.012227065295792181\n",
      "train loss:0.005234865049761952\n",
      "train loss:0.006828971043711227\n",
      "train loss:0.006618820380183665\n",
      "train loss:0.0006219526722601854\n",
      "train loss:0.01180152902797952\n",
      "train loss:0.004649040673041594\n",
      "train loss:0.003750343613886917\n",
      "train loss:0.008991783863034324\n",
      "train loss:0.00975003831823207\n",
      "train loss:0.0003552866554128751\n",
      "train loss:0.001838573698471948\n",
      "train loss:0.00043826803106634965\n",
      "train loss:0.008238852029860275\n",
      "train loss:0.004669490436417755\n",
      "train loss:0.0464702653151334\n",
      "train loss:0.004797945624191861\n",
      "train loss:0.0010007515531322466\n",
      "train loss:0.003319046704885404\n",
      "train loss:0.005074433138804307\n",
      "train loss:0.0005540961081537128\n",
      "train loss:0.0020989927131580283\n",
      "train loss:0.005523407201054853\n",
      "train loss:0.019383231562047118\n",
      "train loss:0.0033533764348299775\n",
      "train loss:0.002863626007551986\n",
      "train loss:0.003356785501889695\n",
      "train loss:0.010309353545504244\n",
      "train loss:0.0030794336523183065\n",
      "train loss:0.0026718583908161664\n",
      "train loss:0.0005799229149569423\n",
      "train loss:0.0022585919223978546\n",
      "train loss:0.008379397069565647\n",
      "train loss:0.008468712578161838\n",
      "train loss:0.002667177784854316\n",
      "train loss:0.002332177754545964\n",
      "train loss:0.011630949615194057\n",
      "train loss:0.0008168073622219181\n",
      "train loss:0.03199836309241002\n",
      "train loss:0.006734949225357093\n",
      "train loss:0.002193623584196403\n",
      "train loss:0.002041593614769672\n",
      "train loss:0.013911892542823014\n",
      "train loss:0.0024283569764900485\n",
      "train loss:0.0031688425327141222\n",
      "train loss:0.006692004792240337\n",
      "train loss:0.003160308972321968\n",
      "train loss:0.005341710429278895\n",
      "train loss:0.01880154163590252\n",
      "train loss:0.0008529261015994987\n",
      "train loss:0.0007674340401778227\n",
      "train loss:0.010902284559887057\n",
      "train loss:0.0019260871058237612\n",
      "train loss:0.0028406084353584053\n",
      "train loss:0.00246138848478199\n",
      "train loss:0.0017095859776078857\n",
      "train loss:0.0010880048818371815\n",
      "train loss:0.0009471859687229556\n",
      "train loss:0.000992381048290443\n",
      "train loss:0.0037433099955613523\n",
      "train loss:0.0019107961688329695\n",
      "train loss:0.00029593059770612165\n",
      "train loss:0.007729734734438212\n",
      "train loss:0.004755243529180373\n",
      "train loss:0.001241989276924436\n",
      "train loss:0.016349276985073397\n",
      "train loss:0.0023734971220748125\n",
      "train loss:0.0004340816366435348\n",
      "train loss:0.0073689690119824345\n",
      "train loss:0.012275647413033773\n",
      "train loss:0.009931090474974777\n",
      "train loss:0.0008851229566070824\n",
      "train loss:0.0005013965264710925\n",
      "train loss:0.002775992559280272\n",
      "train loss:0.005557822119415841\n",
      "train loss:0.0012319493575426355\n",
      "train loss:0.003477552868917374\n",
      "train loss:0.005561209470815084\n",
      "train loss:0.0025333575399671617\n",
      "train loss:0.0006939313994838839\n",
      "train loss:0.0015424050602518755\n",
      "train loss:0.002145106474370446\n",
      "train loss:0.004464062960264802\n",
      "train loss:0.0016325979708341992\n",
      "train loss:0.018181851495551668\n",
      "train loss:0.0028761742076170538\n",
      "train loss:0.0005557842242106133\n",
      "train loss:0.003787379299421649\n",
      "train loss:0.0033504139425811004\n",
      "train loss:0.0004806584532140138\n",
      "train loss:0.010472357036513771\n",
      "train loss:0.00171628823367283\n",
      "train loss:0.0013871224018144888\n",
      "train loss:0.0013945458424795194\n",
      "train loss:0.0005559855503396273\n",
      "train loss:0.0018955283540771678\n",
      "train loss:0.00045647914082753234\n",
      "train loss:0.0019909795693932937\n",
      "train loss:0.0002547375524278618\n",
      "train loss:0.0019123178282240152\n",
      "train loss:0.000567874401548475\n",
      "train loss:0.0007862877275910341\n",
      "train loss:0.008221715663506012\n",
      "train loss:0.0025430529482097135\n",
      "train loss:0.0023924643255908355\n",
      "train loss:0.013478802798933251\n",
      "train loss:0.011680530830494742\n",
      "train loss:0.0011548675778244298\n",
      "train loss:0.0015217195361460975\n",
      "train loss:0.005138032756635574\n",
      "train loss:0.0008032923015680846\n",
      "train loss:0.0052101039398799835\n",
      "train loss:0.002936657116059286\n",
      "train loss:0.00306197995577463\n",
      "train loss:0.0011611479062409607\n",
      "train loss:0.009081221172269354\n",
      "train loss:0.0001480118426673723\n",
      "train loss:0.00046384139505038557\n",
      "train loss:0.001358454291090651\n",
      "train loss:0.033414473387984034\n",
      "train loss:0.0014614001469289487\n",
      "train loss:0.001983694318748713\n",
      "train loss:0.003381075383116341\n",
      "train loss:0.0015910623526166428\n",
      "train loss:0.011793903117874632\n",
      "train loss:9.481201850825934e-05\n",
      "train loss:0.0017216788880696516\n",
      "train loss:0.002691776702969747\n",
      "train loss:0.0021025585973785043\n",
      "train loss:0.006164320273947017\n",
      "train loss:0.012909702894531474\n",
      "train loss:0.004156485228445315\n",
      "train loss:0.0005845645959824809\n",
      "train loss:0.0038310772387201\n",
      "train loss:0.012666024399900382\n",
      "train loss:0.0034606829335207005\n",
      "train loss:0.016541536706425074\n",
      "train loss:0.0997676758777592\n",
      "train loss:0.00215985009255168\n",
      "train loss:0.0001896016563872198\n",
      "train loss:0.006947101926988025\n",
      "train loss:0.0006130307194315864\n",
      "train loss:0.0023826337536742843\n",
      "train loss:0.002102463138550516\n",
      "train loss:0.0009743230672979185\n",
      "train loss:0.0016744865168925429\n",
      "train loss:0.0009152654548208402\n",
      "train loss:0.00720466073289723\n",
      "train loss:0.005687603045848475\n",
      "train loss:0.00028902788824754303\n",
      "train loss:0.00843365807670559\n",
      "train loss:0.0028738067342633155\n",
      "train loss:0.0007730928370721231\n",
      "train loss:0.0009182753268661252\n",
      "train loss:0.010299223534275825\n",
      "train loss:0.003544794597190048\n",
      "train loss:0.00018069881073247838\n",
      "train loss:0.0009301146173831214\n",
      "train loss:0.0024051943723673677\n",
      "train loss:0.003286702494632456\n",
      "train loss:0.02379810260403717\n",
      "train loss:0.0006872792033817448\n",
      "train loss:0.010944652596633568\n",
      "train loss:0.0024939814850274437\n",
      "train loss:0.004309367385565601\n",
      "train loss:0.0023263826767531883\n",
      "train loss:0.011399238527528534\n",
      "train loss:0.003719753280036387\n",
      "train loss:0.0059938573261310545\n",
      "train loss:0.00042774022877989696\n",
      "train loss:0.014608966201051574\n",
      "train loss:0.001502764815748557\n",
      "train loss:0.004789685192834173\n",
      "train loss:0.00055306918381201\n",
      "train loss:0.0023921835558767105\n",
      "train loss:0.006950752736629766\n",
      "train loss:0.008588621051499426\n",
      "train loss:0.01822906145449217\n",
      "train loss:0.011398457079374848\n",
      "train loss:0.024290153793597516\n",
      "train loss:0.005612245291937542\n",
      "train loss:0.004413090554348977\n",
      "train loss:0.00316886173780255\n",
      "train loss:0.007588392855413231\n",
      "train loss:0.002786227195823482\n",
      "train loss:0.008108905014174248\n",
      "train loss:0.005647399903797775\n",
      "train loss:0.0019154539442330775\n",
      "train loss:0.0009091872689565271\n",
      "train loss:0.0011903649050461968\n",
      "train loss:0.002188342858307678\n",
      "train loss:0.004244367937423321\n",
      "train loss:0.005080150181401344\n",
      "train loss:0.0004030171390937412\n",
      "train loss:0.003025478405926539\n",
      "train loss:0.0033934659449207285\n",
      "train loss:0.0015803781687203458\n",
      "train loss:0.000774507368532669\n",
      "train loss:0.012443049499475172\n",
      "train loss:0.01610539553146531\n",
      "train loss:0.0008315187197374243\n",
      "train loss:0.0042673245732664875\n",
      "train loss:0.0021117055851073993\n",
      "train loss:0.006383148113443606\n",
      "train loss:0.006340017024016004\n",
      "train loss:0.002179815154856798\n",
      "train loss:0.001174488313968294\n",
      "train loss:0.0309374035355512\n",
      "train loss:0.0005328985182014869\n",
      "train loss:0.0015589370626407934\n",
      "train loss:0.010859800374767253\n",
      "train loss:0.0019110581018329637\n",
      "train loss:0.0020910914579182647\n",
      "train loss:0.0019223091953084698\n",
      "train loss:0.005531310615360705\n",
      "train loss:0.001566701215741589\n",
      "train loss:0.04372034300784291\n",
      "train loss:0.005978048018996508\n",
      "train loss:0.0008148237015686621\n",
      "train loss:0.0055868215657246464\n",
      "train loss:0.008513878281935583\n",
      "train loss:0.009308067517212226\n",
      "train loss:0.0007922434263564242\n",
      "train loss:0.004213793244437856\n",
      "train loss:0.003093625790372012\n",
      "train loss:0.0013428128809916467\n",
      "train loss:0.0025013881851703667\n",
      "train loss:0.0003680810391677619\n",
      "train loss:0.0012341683252758832\n",
      "train loss:0.004237669179514217\n",
      "train loss:0.005316402676911795\n",
      "train loss:0.0012016612568426482\n",
      "train loss:0.005447774416716897\n",
      "train loss:0.00533058502272995\n",
      "train loss:0.008029128941026831\n",
      "train loss:0.0039006932109274224\n",
      "train loss:0.006402294078660923\n",
      "train loss:0.0008582667278073118\n",
      "train loss:0.0012291799999483365\n",
      "train loss:0.007064549709104924\n",
      "train loss:0.0011193822880708796\n",
      "train loss:0.0010120055152122505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006382245473136865\n",
      "train loss:0.0010502253910233106\n",
      "train loss:0.006228035462245722\n",
      "train loss:0.004108877547855023\n",
      "train loss:0.00327298346438141\n",
      "train loss:0.0086371706793401\n",
      "train loss:0.00027047111629298364\n",
      "train loss:0.00037895172621756784\n",
      "train loss:0.004703336158593283\n",
      "train loss:0.002569772868344634\n",
      "train loss:0.00028323384341536416\n",
      "train loss:0.001020044587348829\n",
      "train loss:0.0017903356634976148\n",
      "train loss:0.0026743662410193035\n",
      "train loss:0.0022346472430519585\n",
      "train loss:0.005895964320320992\n",
      "train loss:0.0023250223354127934\n",
      "train loss:0.007588043536160058\n",
      "train loss:0.001813803384939674\n",
      "train loss:0.004970720006298703\n",
      "train loss:0.01563212629205727\n",
      "train loss:0.01719226995803732\n",
      "train loss:0.00433483221169211\n",
      "train loss:0.002552777621891778\n",
      "train loss:0.0048323669510340304\n",
      "train loss:0.00413150571229368\n",
      "train loss:0.013394263684226032\n",
      "train loss:0.006717820173224087\n",
      "train loss:0.008472548142834373\n",
      "train loss:0.0029034487439531043\n",
      "train loss:0.0013453607051223304\n",
      "train loss:0.002465652761456512\n",
      "train loss:0.0038594440011780664\n",
      "train loss:0.009068586959998964\n",
      "train loss:0.0007992707144048623\n",
      "train loss:0.001327786670117457\n",
      "train loss:0.05019520847605059\n",
      "train loss:0.0031971861586693852\n",
      "=== epoch:14, train acc:0.996, test acc:0.989 ===\n",
      "train loss:0.00042728459876520836\n",
      "train loss:0.0058681309175860575\n",
      "train loss:0.00035677587085134973\n",
      "train loss:0.009595092791083275\n",
      "train loss:0.0011594485319936022\n",
      "train loss:0.004468192665108562\n",
      "train loss:0.007483847729978822\n",
      "train loss:0.004775692796748429\n",
      "train loss:0.0015944112797063525\n",
      "train loss:0.017402136167445615\n",
      "train loss:0.0014256236437852619\n",
      "train loss:0.0005672489689120781\n",
      "train loss:0.004891853277203124\n",
      "train loss:0.0005195505075806421\n",
      "train loss:0.005706391391837582\n",
      "train loss:0.0070777780080922715\n",
      "train loss:0.01270922438600584\n",
      "train loss:0.0031814893836053224\n",
      "train loss:0.00020979936696318907\n",
      "train loss:0.002035441384922584\n",
      "train loss:0.0024627744282509426\n",
      "train loss:0.010541829015179669\n",
      "train loss:0.005985114126868213\n",
      "train loss:0.0010676702337658218\n",
      "train loss:0.018193173929315177\n",
      "train loss:0.0020260166615541347\n",
      "train loss:0.0020613856832609827\n",
      "train loss:0.012481979822925473\n",
      "train loss:0.005846180715695567\n",
      "train loss:0.0012176939842628133\n",
      "train loss:0.0033441319122924445\n",
      "train loss:0.0019098909205634033\n",
      "train loss:0.005072417179264072\n",
      "train loss:0.0022311379175695796\n",
      "train loss:0.00778862559733918\n",
      "train loss:0.00338958722347308\n",
      "train loss:0.0032359829215859305\n",
      "train loss:0.0006864798203257595\n",
      "train loss:0.0009064761528240109\n",
      "train loss:0.014726683602166318\n",
      "train loss:0.0038982103927623917\n",
      "train loss:0.003809543749890684\n",
      "train loss:0.0037060770898465468\n",
      "train loss:0.002054486447445147\n",
      "train loss:0.0012732618946000656\n",
      "train loss:0.0029376660883770208\n",
      "train loss:0.0002311800583266091\n",
      "train loss:0.045638412114559615\n",
      "train loss:0.00271131795361851\n",
      "train loss:0.002310561418654082\n",
      "train loss:0.006087381027710974\n",
      "train loss:0.0020374858567885016\n",
      "train loss:0.02753784971716633\n",
      "train loss:0.024704630745886615\n",
      "train loss:0.0008916957385505822\n",
      "train loss:0.011184892047002386\n",
      "train loss:0.007426242455820187\n",
      "train loss:0.0006823621953364451\n",
      "train loss:0.007035327007087137\n",
      "train loss:0.003586687943898491\n",
      "train loss:0.013068667178120483\n",
      "train loss:0.002863336135951217\n",
      "train loss:0.03205432093263758\n",
      "train loss:0.0044094561704036885\n",
      "train loss:0.002339959626662825\n",
      "train loss:0.005638970098385917\n",
      "train loss:0.0023493074870922625\n",
      "train loss:0.004710456377173309\n",
      "train loss:0.0009821524516504454\n",
      "train loss:0.0011969424637917126\n",
      "train loss:0.0042672318806956586\n",
      "train loss:0.008287519617385924\n",
      "train loss:0.012920421816846989\n",
      "train loss:0.0037371639675288465\n",
      "train loss:0.008714305062475912\n",
      "train loss:0.0022199303109099373\n",
      "train loss:0.005961495446932265\n",
      "train loss:0.002664103380865166\n",
      "train loss:0.005581653452225217\n",
      "train loss:0.0011608105876403708\n",
      "train loss:0.0022166033104954884\n",
      "train loss:0.013675020952485946\n",
      "train loss:0.003273876060969057\n",
      "train loss:0.0030091510145054097\n",
      "train loss:0.00504601433535118\n",
      "train loss:0.0014950013161348957\n",
      "train loss:0.00045698312390956994\n",
      "train loss:0.007534068863460842\n",
      "train loss:0.0016563638962776902\n",
      "train loss:0.0016336347121355217\n",
      "train loss:0.00016673758767153969\n",
      "train loss:0.005985716653209338\n",
      "train loss:0.004704760171504553\n",
      "train loss:0.0009639087383272116\n",
      "train loss:0.0034245151629985304\n",
      "train loss:0.006236714523993524\n",
      "train loss:0.004815929336664674\n",
      "train loss:0.0033011444260673106\n",
      "train loss:0.0037491980220826834\n",
      "train loss:0.005348462287679438\n",
      "train loss:0.006216794167218517\n",
      "train loss:0.0007743349956913205\n",
      "train loss:0.0005803342611105989\n",
      "train loss:0.0027845901088688883\n",
      "train loss:0.015498385485713483\n",
      "train loss:0.0004801171442224317\n",
      "train loss:0.0038580277729102414\n",
      "train loss:0.0008103577823807847\n",
      "train loss:0.020466288699456093\n",
      "train loss:0.002105733254801624\n",
      "train loss:0.0013733285610228036\n",
      "train loss:0.0016543405578814138\n",
      "train loss:0.00881168083693211\n",
      "train loss:0.007710436624716267\n",
      "train loss:0.00705714707742225\n",
      "train loss:0.0009973060866838848\n",
      "train loss:0.011194170359908504\n",
      "train loss:0.00010803270810428343\n",
      "train loss:0.0023678595710944577\n",
      "train loss:0.0004392574822833147\n",
      "train loss:0.005727816404499379\n",
      "train loss:0.007551349012074242\n",
      "train loss:0.000868509098945899\n",
      "train loss:0.0011085373653923554\n",
      "train loss:0.008588055598541429\n",
      "train loss:0.03187364744584676\n",
      "train loss:0.004386315932332011\n",
      "train loss:0.008758497147212154\n",
      "train loss:0.000984253307132426\n",
      "train loss:0.0031069029493871196\n",
      "train loss:0.00037929020519391607\n",
      "train loss:0.0011540042139953188\n",
      "train loss:0.0038569196329264034\n",
      "train loss:0.0019435850700343566\n",
      "train loss:0.006644270209273793\n",
      "train loss:0.00037944636384685897\n",
      "train loss:0.017190594194308812\n",
      "train loss:0.004086262322451627\n",
      "train loss:0.000546017658754303\n",
      "train loss:0.007044146781538379\n",
      "train loss:0.01634575680603163\n",
      "train loss:0.0040624106941435836\n",
      "train loss:0.002676533338197388\n",
      "train loss:0.0028348331621693627\n",
      "train loss:0.0015920261376039305\n",
      "train loss:0.0006723028551408674\n",
      "train loss:0.002107115929291127\n",
      "train loss:0.0055454934567094735\n",
      "train loss:0.003614038338845247\n",
      "train loss:0.003962291251384804\n",
      "train loss:0.01710950230430142\n",
      "train loss:0.002147121944759661\n",
      "train loss:0.007157841479456428\n",
      "train loss:0.0008910932321191071\n",
      "train loss:0.003085857570190075\n",
      "train loss:0.007534343440886191\n",
      "train loss:0.005605204348900997\n",
      "train loss:0.005918748372485969\n",
      "train loss:0.0007612494734985847\n",
      "train loss:0.004900295513322839\n",
      "train loss:0.004187615355778387\n",
      "train loss:0.004511114590495986\n",
      "train loss:0.003742177227038727\n",
      "train loss:0.008210330889063434\n",
      "train loss:0.004374669673653764\n",
      "train loss:0.0015389495154870148\n",
      "train loss:0.0028965898664374224\n",
      "train loss:0.0016536801768070638\n",
      "train loss:0.017637874066657944\n",
      "train loss:0.00013705024917432838\n",
      "train loss:0.0018173418342990464\n",
      "train loss:0.0014120923173954968\n",
      "train loss:0.005254470599431469\n",
      "train loss:0.005313275479531091\n",
      "train loss:0.016173570615349884\n",
      "train loss:0.001051420133244775\n",
      "train loss:0.003625969199431395\n",
      "train loss:0.004445574134336711\n",
      "train loss:0.006254771304910564\n",
      "train loss:0.007207031830526027\n",
      "train loss:0.0023385986912879612\n",
      "train loss:0.005448085630614408\n",
      "train loss:0.0013335420991980968\n",
      "train loss:0.0013632701170623617\n",
      "train loss:0.03675054338603671\n",
      "train loss:0.0028882917887413486\n",
      "train loss:0.001638542940948113\n",
      "train loss:0.00857916691717423\n",
      "train loss:0.002981022293351418\n",
      "train loss:0.00048690038368644423\n",
      "train loss:0.005809924870945204\n",
      "train loss:0.010176723568748427\n",
      "train loss:0.001590848379258449\n",
      "train loss:0.006474250203068248\n",
      "train loss:0.004580017688042065\n",
      "train loss:0.0013016035063411224\n",
      "train loss:0.0014951693829514928\n",
      "train loss:0.0023863292375944766\n",
      "train loss:0.003896138527786235\n",
      "train loss:0.0055902743135723\n",
      "train loss:0.0017424995210505328\n",
      "train loss:0.0012666161859132515\n",
      "train loss:0.0009595919877949013\n",
      "train loss:0.005722861819092956\n",
      "train loss:0.0027393289788557947\n",
      "train loss:0.01720633434516305\n",
      "train loss:0.0018042962840238855\n",
      "train loss:0.048748570077749055\n",
      "train loss:0.0027243706324837184\n",
      "train loss:0.002931653304013207\n",
      "train loss:0.010841438250849182\n",
      "train loss:0.002390756712677978\n",
      "train loss:0.0003399184034422465\n",
      "train loss:0.0014038667942057848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007659247427367412\n",
      "train loss:0.0009179005642632118\n",
      "train loss:0.0039019951630735543\n",
      "train loss:0.0015091299760054877\n",
      "train loss:0.004320235700581162\n",
      "train loss:0.0029774739999986572\n",
      "train loss:0.00510762120887616\n",
      "train loss:0.0032030124869461907\n",
      "train loss:0.0014149108370680862\n",
      "train loss:0.002889540800970688\n",
      "train loss:0.0013112161128612805\n",
      "train loss:0.0005813123474053661\n",
      "train loss:0.0036238060939446474\n",
      "train loss:0.0012433522703139805\n",
      "train loss:0.0002153792751802687\n",
      "train loss:0.005119532636345232\n",
      "train loss:0.0023213175488065647\n",
      "train loss:0.0018509864172029052\n",
      "train loss:0.004832631517807171\n",
      "train loss:0.006799861704685455\n",
      "train loss:0.0007204649470142935\n",
      "train loss:0.0010082361387744661\n",
      "train loss:0.000299585284789989\n",
      "train loss:0.0009429429767365812\n",
      "train loss:0.007774141108059118\n",
      "train loss:0.0008058740995950145\n",
      "train loss:0.0026360396639796323\n",
      "train loss:0.0008796423376746921\n",
      "train loss:0.0011058921357279359\n",
      "train loss:0.0017440421915742486\n",
      "train loss:0.0272114669955063\n",
      "train loss:0.0004636120118683123\n",
      "train loss:0.0015474117372380855\n",
      "train loss:0.005123407334939669\n",
      "train loss:0.005315659978829854\n",
      "train loss:0.01157443377036949\n",
      "train loss:0.00019885344264174105\n",
      "train loss:0.0024602981823815704\n",
      "train loss:0.011637716887303752\n",
      "train loss:0.004669534340365764\n",
      "train loss:0.002673956480835951\n",
      "train loss:0.0022836952788510747\n",
      "train loss:0.0012187706102399956\n",
      "train loss:0.0014023765288851114\n",
      "train loss:0.0013486661573216955\n",
      "train loss:0.0007324599721731186\n",
      "train loss:0.001083678496555176\n",
      "train loss:0.0019728321220698116\n",
      "train loss:0.011516164064003067\n",
      "train loss:0.010296803931216155\n",
      "train loss:0.0015513886265704786\n",
      "train loss:0.010465037974074186\n",
      "train loss:0.006228536368148729\n",
      "train loss:0.0006943063205291994\n",
      "train loss:0.0023609095641484745\n",
      "train loss:0.002152354761838123\n",
      "train loss:0.005202451211748774\n",
      "train loss:0.0022443967214890075\n",
      "train loss:0.0031742302540565034\n",
      "train loss:0.014412383460841257\n",
      "train loss:0.0037338447675457354\n",
      "train loss:0.00030659967165031616\n",
      "train loss:0.0025255379029179093\n",
      "train loss:0.0002021714073621723\n",
      "train loss:0.007224929390572904\n",
      "train loss:0.001320207585681167\n",
      "train loss:0.006523894793232572\n",
      "train loss:0.008477540153407402\n",
      "train loss:0.005417316150534545\n",
      "train loss:0.007472963852942023\n",
      "train loss:0.0039923940684371065\n",
      "train loss:0.0032302690519064674\n",
      "train loss:0.010419870043863789\n",
      "train loss:0.0029574932860967134\n",
      "train loss:0.0017908996130331103\n",
      "train loss:0.013104804769086743\n",
      "train loss:0.0015733400899379556\n",
      "train loss:0.0010082691846762131\n",
      "train loss:0.00677577769816362\n",
      "train loss:0.0008494189971451136\n",
      "train loss:0.0011111007802841215\n",
      "train loss:0.002670060785061127\n",
      "train loss:0.0008711324211276065\n",
      "train loss:0.0019979086035014134\n",
      "train loss:0.0005400029662380144\n",
      "train loss:0.0008988395282651359\n",
      "train loss:0.00023441147505039108\n",
      "train loss:0.008575703357099984\n",
      "train loss:0.002796269943881453\n",
      "train loss:0.0030658252943093055\n",
      "train loss:0.008837421428852146\n",
      "train loss:0.013791979029008783\n",
      "train loss:0.0009556262265787642\n",
      "train loss:0.0007916465878432293\n",
      "train loss:0.001257730151121682\n",
      "train loss:0.001798281644827455\n",
      "train loss:0.012471981535291807\n",
      "train loss:0.000686654023906899\n",
      "train loss:0.0013118059022943925\n",
      "train loss:0.007555924990211237\n",
      "train loss:0.002680312427021375\n",
      "train loss:0.027428430033355225\n",
      "train loss:0.007658199522242146\n",
      "train loss:0.001160994505432974\n",
      "train loss:0.005705664868486885\n",
      "train loss:0.0031260041138611167\n",
      "train loss:0.0024828134916929064\n",
      "train loss:0.0043232425168430845\n",
      "train loss:0.0036540156347694697\n",
      "train loss:0.0009559303472733066\n",
      "train loss:0.008517396503719918\n",
      "train loss:0.00533607509391624\n",
      "train loss:0.0022606218202316313\n",
      "train loss:0.00865589432421281\n",
      "train loss:0.0036330367798186876\n",
      "train loss:0.003244886572230397\n",
      "train loss:0.002970989432668628\n",
      "train loss:0.0075264408671743286\n",
      "train loss:0.001323688394737973\n",
      "train loss:0.0024401870839949784\n",
      "train loss:0.00043913280147954355\n",
      "train loss:0.0028491402600832154\n",
      "train loss:0.006300724542381734\n",
      "train loss:0.0016612807553163362\n",
      "train loss:0.00520062206264221\n",
      "train loss:0.012464978923131356\n",
      "train loss:0.0014955495513707298\n",
      "train loss:0.005393764268729162\n",
      "train loss:0.025689433137907364\n",
      "train loss:0.00011378500925277923\n",
      "train loss:0.01249249726609751\n",
      "train loss:0.0008491631711391013\n",
      "train loss:0.0007260184787801711\n",
      "train loss:0.0013804725209881144\n",
      "train loss:0.0024793249418791157\n",
      "train loss:0.00397402339031028\n",
      "train loss:0.004292860377128845\n",
      "train loss:0.001292513414755255\n",
      "train loss:0.001087714146706253\n",
      "train loss:0.0035329799665950595\n",
      "train loss:0.00045004079218979474\n",
      "train loss:0.005651254905825654\n",
      "train loss:0.004239390846542\n",
      "train loss:0.005321112951956113\n",
      "train loss:0.011962668624676263\n",
      "train loss:0.0005411410108891555\n",
      "train loss:0.0008099341827533215\n",
      "train loss:0.0017152547141879243\n",
      "train loss:0.00443568351425432\n",
      "train loss:0.001231918047309364\n",
      "train loss:0.0007226514210898322\n",
      "train loss:0.0021089804485045853\n",
      "train loss:0.0032068995103611197\n",
      "train loss:0.00039781663049333636\n",
      "train loss:0.00033397676923980845\n",
      "train loss:0.012040590267294184\n",
      "train loss:0.007885401251768781\n",
      "train loss:0.00318916278569618\n",
      "train loss:0.0009865032381165182\n",
      "train loss:0.0034420892705970597\n",
      "train loss:0.006408283854548053\n",
      "train loss:0.0037334657420293725\n",
      "train loss:0.0014416538511741782\n",
      "train loss:0.006959729845798084\n",
      "train loss:0.0012141594128421123\n",
      "train loss:0.002301368805152763\n",
      "train loss:0.0007923711170654096\n",
      "train loss:0.006010237182408401\n",
      "train loss:0.0027715823520196047\n",
      "train loss:0.0009603418649180444\n",
      "train loss:0.0003635206283932017\n",
      "train loss:0.002165487490171575\n",
      "train loss:0.003960913685181766\n",
      "train loss:0.0036724916806782346\n",
      "train loss:0.00046387883641267\n",
      "train loss:0.0012082966706095139\n",
      "train loss:0.0019207244237451437\n",
      "train loss:0.003255641793537045\n",
      "train loss:0.004689120096219673\n",
      "train loss:0.0005361952679777059\n",
      "train loss:9.008655719517005e-05\n",
      "train loss:0.004187640252148286\n",
      "train loss:3.328902557734152e-05\n",
      "train loss:0.001876404454446251\n",
      "train loss:0.0017882820182269605\n",
      "train loss:0.0008477232569195977\n",
      "train loss:0.00016633874761898032\n",
      "train loss:0.00021905859474009485\n",
      "train loss:0.003427816373518991\n",
      "train loss:0.001027313088521345\n",
      "train loss:0.0023621003577114813\n",
      "train loss:0.0016631443513622426\n",
      "train loss:0.000987194245077727\n",
      "train loss:0.003287537438398592\n",
      "train loss:0.0026975689677482583\n",
      "train loss:0.0006956979357989761\n",
      "train loss:0.00011599049907073287\n",
      "train loss:0.0004314791190868325\n",
      "train loss:0.002589858026465832\n",
      "train loss:0.00827830458797524\n",
      "train loss:0.0005396274483907539\n",
      "train loss:0.0010019426685121992\n",
      "train loss:0.00013462376337223817\n",
      "train loss:0.00015981105940027207\n",
      "train loss:0.0015491998150044778\n",
      "train loss:0.00016653058119713972\n",
      "train loss:0.0034037293093721545\n",
      "train loss:0.002550915937979873\n",
      "train loss:0.001253502683148036\n",
      "train loss:0.010191057771722072\n",
      "train loss:0.0025138072613499324\n",
      "train loss:0.0003473987575259056\n",
      "train loss:0.0010394983480732532\n",
      "train loss:0.007298985278307892\n",
      "train loss:0.001408148899848093\n",
      "train loss:0.0017739153099176786\n",
      "train loss:0.0007215730881591952\n",
      "train loss:0.006932375757434085\n",
      "train loss:0.0010008482727830005\n",
      "train loss:0.0030627865375632396\n",
      "train loss:0.0009524514731475002\n",
      "train loss:0.0019097181134663532\n",
      "train loss:0.012717226063180298\n",
      "train loss:0.0003760568291056243\n",
      "train loss:0.0006627597159477314\n",
      "train loss:0.0005066539902007466\n",
      "train loss:0.0021546971427570207\n",
      "train loss:0.006484378413943203\n",
      "train loss:0.0032196351847068798\n",
      "train loss:0.003996815142629058\n",
      "train loss:0.006822977026181917\n",
      "train loss:0.0006490703762599304\n",
      "train loss:0.003781352488922289\n",
      "train loss:0.008804056515717692\n",
      "train loss:0.003144053102548582\n",
      "train loss:0.005589504628405109\n",
      "train loss:0.00017318670115640765\n",
      "train loss:9.403727160377145e-05\n",
      "train loss:0.0003225087204619117\n",
      "train loss:0.009600823249780238\n",
      "train loss:0.014211368244163447\n",
      "train loss:0.001552326693263504\n",
      "train loss:0.0012088146442159942\n",
      "train loss:0.0032418808520496773\n",
      "train loss:0.0039046297265748157\n",
      "train loss:0.0007691770063885239\n",
      "train loss:0.0024292701319659693\n",
      "train loss:8.48691181207035e-05\n",
      "train loss:0.002073299143632776\n",
      "train loss:0.005925026678708902\n",
      "train loss:0.001561693476943464\n",
      "train loss:0.02486701764318714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023753254104871583\n",
      "train loss:0.00033705733212288744\n",
      "train loss:0.000310338167524693\n",
      "train loss:0.00023059297555287443\n",
      "train loss:0.003974102504005702\n",
      "train loss:0.010771331786929593\n",
      "train loss:0.0017102867092968269\n",
      "train loss:0.0004214718069301654\n",
      "train loss:0.029085968118644834\n",
      "train loss:0.0036765954106183856\n",
      "train loss:0.00343285154978277\n",
      "train loss:0.002990338890104073\n",
      "train loss:0.0006419252093398608\n",
      "train loss:0.0002424176891222694\n",
      "train loss:0.0009019824144247139\n",
      "train loss:0.00039163462969758707\n",
      "train loss:0.0032928287516861077\n",
      "train loss:0.004524717834317889\n",
      "train loss:0.001119232978047914\n",
      "train loss:0.013836187802317825\n",
      "train loss:0.006774033179805666\n",
      "train loss:0.0007980623145627628\n",
      "train loss:0.006813539608370031\n",
      "train loss:0.002288228580984115\n",
      "train loss:0.008487141120330109\n",
      "train loss:0.0007005391701738112\n",
      "train loss:0.008923229431598092\n",
      "train loss:0.003998970605172107\n",
      "train loss:0.019027805475802743\n",
      "train loss:0.0038592720535793918\n",
      "train loss:0.00106407378129642\n",
      "train loss:0.00011542991930032336\n",
      "train loss:0.00041100146096002967\n",
      "train loss:0.00039855702812511363\n",
      "train loss:0.009786125417036213\n",
      "train loss:0.000428349212058023\n",
      "train loss:0.001959795036934416\n",
      "train loss:0.002184222264939657\n",
      "train loss:0.0014876255965627775\n",
      "train loss:0.0029799150684428656\n",
      "train loss:0.0030077204576153594\n",
      "train loss:0.00010342613542701821\n",
      "train loss:0.003248574997212067\n",
      "train loss:0.0016658358013893072\n",
      "train loss:0.004399236792944512\n",
      "train loss:0.00012663662107830813\n",
      "train loss:0.003256090768242055\n",
      "train loss:0.0009126178373345198\n",
      "train loss:0.0013390643445391473\n",
      "train loss:0.0038936043077839933\n",
      "train loss:0.0003546987150495141\n",
      "train loss:0.0008785942620312921\n",
      "train loss:0.009815458363561054\n",
      "train loss:0.0005234586638691936\n",
      "train loss:0.002576501907573366\n",
      "train loss:0.004411781510829656\n",
      "train loss:0.004766257969527398\n",
      "train loss:0.0012173453539889804\n",
      "train loss:0.0016237351191866333\n",
      "train loss:0.005384635638060356\n",
      "train loss:0.00023965755068604275\n",
      "train loss:0.0014841432797515239\n",
      "train loss:0.005981303029858059\n",
      "train loss:0.005873952752485968\n",
      "train loss:0.004987227382747106\n",
      "train loss:0.0007170041297510417\n",
      "train loss:0.001157004350247253\n",
      "train loss:0.007200456020824408\n",
      "train loss:0.004382246519137875\n",
      "train loss:0.002618578651193994\n",
      "train loss:0.0001922452464650268\n",
      "train loss:0.0023504527136967946\n",
      "train loss:0.0004295029939185277\n",
      "train loss:0.0005880131526522849\n",
      "train loss:0.006918589551861738\n",
      "train loss:0.0007556900521974564\n",
      "train loss:0.0005224647299984323\n",
      "train loss:0.0009702031197824637\n",
      "train loss:0.0005839699444354656\n",
      "train loss:0.004207763445317791\n",
      "train loss:0.0009356360779072795\n",
      "train loss:0.0036246732114222696\n",
      "train loss:0.0023191814311145404\n",
      "train loss:0.000990903372737132\n",
      "train loss:0.0009386488675024483\n",
      "train loss:0.005996691565796013\n",
      "train loss:0.0036484027694617467\n",
      "train loss:0.002910201588008463\n",
      "train loss:0.0007908508613284546\n",
      "train loss:0.000540887250524265\n",
      "train loss:0.001891136471927763\n",
      "train loss:0.0027219495713117865\n",
      "train loss:0.0024195392704682277\n",
      "train loss:0.0005271083487803535\n",
      "train loss:0.03945931388219717\n",
      "train loss:0.006077365003711048\n",
      "train loss:0.0058579093359551\n",
      "train loss:0.00011879366300451621\n",
      "train loss:0.0014375036249847336\n",
      "train loss:0.00020150776878043633\n",
      "train loss:0.004265901098896825\n",
      "train loss:0.00437764439792059\n",
      "train loss:0.0009210775372383906\n",
      "train loss:0.0009222355320337837\n",
      "train loss:0.002999184192084111\n",
      "train loss:0.001401114340211908\n",
      "train loss:0.0037568131120557903\n",
      "train loss:0.06577862525242191\n",
      "train loss:0.007649817462064641\n",
      "train loss:0.0007843501454875743\n",
      "train loss:0.0015756664253363762\n",
      "train loss:0.0016027542223342403\n",
      "train loss:0.0014686013234680043\n",
      "train loss:0.0012483491582213004\n",
      "train loss:0.0010779358905491185\n",
      "train loss:0.012365418981735786\n",
      "train loss:0.001965110641497544\n",
      "train loss:0.000972564380399145\n",
      "train loss:0.0023252317810015994\n",
      "train loss:0.0033057073562430903\n",
      "train loss:0.00012566100051204736\n",
      "train loss:0.0181627377126222\n",
      "train loss:0.003369149434658999\n",
      "train loss:0.0002496269881287301\n",
      "train loss:0.003199282471983111\n",
      "train loss:0.0044454121661440735\n",
      "train loss:0.004494371079643129\n",
      "train loss:0.0006600319653011198\n",
      "train loss:0.006596884782391613\n",
      "train loss:0.0010677755251985242\n",
      "train loss:0.003524943391449322\n",
      "train loss:0.006797416147757716\n",
      "train loss:0.0020956570885873557\n",
      "train loss:0.0008190008069790636\n",
      "=== epoch:15, train acc:1.0, test acc:0.987 ===\n",
      "train loss:0.0005099789314173323\n",
      "train loss:0.0031338430209517003\n",
      "train loss:0.0004183171343417851\n",
      "train loss:0.0018405576932823302\n",
      "train loss:0.00207304707649532\n",
      "train loss:0.0017148920874867073\n",
      "train loss:0.0011832309512251299\n",
      "train loss:0.030932698871139603\n",
      "train loss:0.001008316310918337\n",
      "train loss:0.0010204953248342207\n",
      "train loss:0.0004978211972339587\n",
      "train loss:0.025631846652772166\n",
      "train loss:0.006902470297322183\n",
      "train loss:0.000693301373123704\n",
      "train loss:0.002185511885290724\n",
      "train loss:0.0026011825181552466\n",
      "train loss:0.0029349068295523254\n",
      "train loss:0.0019170687928625793\n",
      "train loss:0.0007707498828418547\n",
      "train loss:0.0005699019913749692\n",
      "train loss:0.01813736590932384\n",
      "train loss:0.0006549273072275464\n",
      "train loss:0.005162001083601707\n",
      "train loss:0.0008097234162265432\n",
      "train loss:0.0020049506165797305\n",
      "train loss:0.002231079102835797\n",
      "train loss:0.002915716878290151\n",
      "train loss:0.0009273442210175481\n",
      "train loss:0.0012606197730868022\n",
      "train loss:0.00218002111661438\n",
      "train loss:0.0045494740414922154\n",
      "train loss:0.0009033426383762793\n",
      "train loss:0.0016041206637839387\n",
      "train loss:0.0024779667900196754\n",
      "train loss:0.005202837769641136\n",
      "train loss:0.006868057094196173\n",
      "train loss:0.003524431291041644\n",
      "train loss:0.0017861983685074814\n",
      "train loss:0.030557451837090424\n",
      "train loss:0.007228876370713087\n",
      "train loss:0.002159865599802796\n",
      "train loss:0.003513922076769183\n",
      "train loss:0.0005597940463597763\n",
      "train loss:0.0002986244140417211\n",
      "train loss:0.0016210731540867885\n",
      "train loss:0.0028830033045444225\n",
      "train loss:0.0032661405659698424\n",
      "train loss:0.00014040425243484945\n",
      "train loss:0.004117093764326562\n",
      "train loss:0.004958072981039962\n",
      "train loss:0.002003490632812483\n",
      "train loss:0.003867886529091499\n",
      "train loss:0.00012802365457063506\n",
      "train loss:0.005972059333656989\n",
      "train loss:0.0005060321078742218\n",
      "train loss:0.008112264825793167\n",
      "train loss:0.006098455417531211\n",
      "train loss:0.0032612462327638856\n",
      "train loss:0.003143543565675567\n",
      "train loss:0.0036655426984609552\n",
      "train loss:0.000444011069033492\n",
      "train loss:0.004199129108805252\n",
      "train loss:0.0008509593409061966\n",
      "train loss:0.00048549033708771727\n",
      "train loss:0.001005308528246188\n",
      "train loss:0.004329875403392461\n",
      "train loss:0.0016595721533166983\n",
      "train loss:0.00045211483372584166\n",
      "train loss:0.00632101732952705\n",
      "train loss:0.0018416714074750208\n",
      "train loss:0.0012017691593957484\n",
      "train loss:0.01964180117242304\n",
      "train loss:0.0026586222779588892\n",
      "train loss:0.005648421725324415\n",
      "train loss:0.004163710902379013\n",
      "train loss:0.0037733254955871743\n",
      "train loss:0.036396660747279014\n",
      "train loss:8.669464246701219e-05\n",
      "train loss:0.0035761940135736153\n",
      "train loss:0.0008898553260715306\n",
      "train loss:0.001621188531582512\n",
      "train loss:0.0009625309204754275\n",
      "train loss:0.006271008736518879\n",
      "train loss:0.006148027534062603\n",
      "train loss:0.0034715660851873604\n",
      "train loss:0.000990571499945737\n",
      "train loss:0.0026905528931024177\n",
      "train loss:0.00023995154976454662\n",
      "train loss:0.00013064272668386232\n",
      "train loss:0.00018620970493183044\n",
      "train loss:0.006797373801970553\n",
      "train loss:0.003614405862197535\n",
      "train loss:0.003009546198986893\n",
      "train loss:0.002474845961206756\n",
      "train loss:0.0006662461921771744\n",
      "train loss:0.00024398622677149377\n",
      "train loss:0.0010342545363540398\n",
      "train loss:0.0011988302972458123\n",
      "train loss:0.0005423535469119233\n",
      "train loss:0.0008042164521175548\n",
      "train loss:0.0007240936959997131\n",
      "train loss:0.0001273354076294667\n",
      "train loss:0.005482673965447944\n",
      "train loss:0.015421173795805066\n",
      "train loss:0.00013201225880091484\n",
      "train loss:0.0010504289912523063\n",
      "train loss:0.0008233329988031717\n",
      "train loss:0.002596093047398851\n",
      "train loss:0.003956665773545924\n",
      "train loss:0.001153571060822193\n",
      "train loss:0.0005160747461028874\n",
      "train loss:0.002039159693966177\n",
      "train loss:5.641319409171939e-05\n",
      "train loss:0.0031548382349739267\n",
      "train loss:0.007712307514878969\n",
      "train loss:0.0013496018230861786\n",
      "train loss:0.0017483090419341785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005865066314774737\n",
      "train loss:0.001458159680010628\n",
      "train loss:0.004948292664711606\n",
      "train loss:0.005352261121060725\n",
      "train loss:0.006479881901392055\n",
      "train loss:0.0012177848797068264\n",
      "train loss:0.0014036005654413355\n",
      "train loss:0.0004142871494845136\n",
      "train loss:0.012879994341662891\n",
      "train loss:0.001600025409065577\n",
      "train loss:0.0008910545182560184\n",
      "train loss:0.0012532869045516954\n",
      "train loss:0.0007078044899068415\n",
      "train loss:0.002990767250581624\n",
      "train loss:0.0016111829581915483\n",
      "train loss:0.0007880263577899753\n",
      "train loss:0.026110065280789782\n",
      "train loss:0.03310098477366158\n",
      "train loss:0.0002814195528877845\n",
      "train loss:0.016863334227696328\n",
      "train loss:0.0005497342998170496\n",
      "train loss:0.001701898101396798\n",
      "train loss:0.003783687739403739\n",
      "train loss:0.0019147217921252646\n",
      "train loss:0.007095553265227325\n",
      "train loss:0.0008502743085792812\n",
      "train loss:0.00039677901749677946\n",
      "train loss:0.0009320385396173424\n",
      "train loss:0.00385145385225241\n",
      "train loss:0.0005208886956286191\n",
      "train loss:0.025179456134489166\n",
      "train loss:0.001551601367922814\n",
      "train loss:0.005739451347682897\n",
      "train loss:0.006283606680922661\n",
      "train loss:0.0012026479814840015\n",
      "train loss:0.0011498214672317271\n",
      "train loss:0.013746527937760426\n",
      "train loss:0.0024183267957602755\n",
      "train loss:0.013460195054496965\n",
      "train loss:0.0016615759401895584\n",
      "train loss:0.017594775059545834\n",
      "train loss:0.0034371553593327713\n",
      "train loss:0.0003354820093900322\n",
      "train loss:0.013054926568728826\n",
      "train loss:9.285487540351375e-05\n",
      "train loss:0.002150366551121943\n",
      "train loss:7.8773075472711e-05\n",
      "train loss:0.0011597724188242163\n",
      "train loss:0.0007533910923748332\n",
      "train loss:0.0042846924473491895\n",
      "train loss:0.0017448344752296694\n",
      "train loss:0.00041238094572526975\n",
      "train loss:0.006488303697421832\n",
      "train loss:0.004668765052056823\n",
      "train loss:0.000727700450503337\n",
      "train loss:0.0015110112468628254\n",
      "train loss:0.00065302371627975\n",
      "train loss:0.0010748383611205751\n",
      "train loss:0.00027923546839077866\n",
      "train loss:0.0036046833654156873\n",
      "train loss:0.0012118242596848685\n",
      "train loss:0.002427800597088045\n",
      "train loss:0.0036939440279220494\n",
      "train loss:0.0038814653776545077\n",
      "train loss:0.007769799164069954\n",
      "train loss:0.007165084978402757\n",
      "train loss:0.00038212281037347783\n",
      "train loss:0.0009022163981584863\n",
      "train loss:0.001089561624358197\n",
      "train loss:0.006758533254325187\n",
      "train loss:0.0012014874699104333\n",
      "train loss:0.011106826656079736\n",
      "train loss:0.0045661019982745936\n",
      "train loss:0.008646273073318313\n",
      "train loss:0.010112028815413175\n",
      "train loss:0.002639532744878664\n",
      "train loss:0.0002605076772281628\n",
      "train loss:0.0013626939020601175\n",
      "train loss:0.0007383983707094114\n",
      "train loss:0.002382556572360512\n",
      "train loss:0.00018497139119092807\n",
      "train loss:0.0036837313245991392\n",
      "train loss:0.002182318420162284\n",
      "train loss:0.007573837129337952\n",
      "train loss:0.023933291352665375\n",
      "train loss:0.0016926469586062798\n",
      "train loss:0.009233385872938048\n",
      "train loss:0.0013941387641581552\n",
      "train loss:0.001382731786491749\n",
      "train loss:0.000940895684355912\n",
      "train loss:0.002713019142585264\n",
      "train loss:0.006381120374812482\n",
      "train loss:0.001913959453699863\n",
      "train loss:0.00307015011657649\n",
      "train loss:0.01287790066088436\n",
      "train loss:0.0036993946940229692\n",
      "train loss:0.00037491774530945646\n",
      "train loss:0.0009441103017640635\n",
      "train loss:0.0005334608306708277\n",
      "train loss:0.002347476552535996\n",
      "train loss:0.0027940739053091616\n",
      "train loss:2.4331776053061794e-05\n",
      "train loss:0.004352108928598348\n",
      "train loss:0.0015102428519599446\n",
      "train loss:0.0006820540721356327\n",
      "train loss:0.0005594497579495368\n",
      "train loss:0.004507402061913166\n",
      "train loss:0.0001619700431414943\n",
      "train loss:0.004784646979085256\n",
      "train loss:0.0005511272148341092\n",
      "train loss:0.002459522692408809\n",
      "train loss:0.00033663564759027514\n",
      "train loss:0.0016728579396225966\n",
      "train loss:0.002355447152988947\n",
      "train loss:0.007810494947288622\n",
      "train loss:0.00030793549878179864\n",
      "train loss:0.0028770873113943903\n",
      "train loss:0.004947312882923015\n",
      "train loss:0.018674583807949237\n",
      "train loss:0.00022419356988138823\n",
      "train loss:0.0013361588423126622\n",
      "train loss:0.001109835978370606\n",
      "train loss:0.000765237720262593\n",
      "train loss:0.004797438603484869\n",
      "train loss:0.005999596317807209\n",
      "train loss:0.0006364027285556278\n",
      "train loss:0.006136627869861914\n",
      "train loss:0.007363663394160793\n",
      "train loss:0.0007299024298693768\n",
      "train loss:0.0018136736086961371\n",
      "train loss:0.00045477965304861127\n",
      "train loss:0.005920240400276554\n",
      "train loss:0.0035366935920083838\n",
      "train loss:0.003734547933973045\n",
      "train loss:0.005956907186169771\n",
      "train loss:0.0008869801399327498\n",
      "train loss:0.0007377443916042178\n",
      "train loss:0.0012306425521067187\n",
      "train loss:0.0004013463961465471\n",
      "train loss:0.0017329608263813572\n",
      "train loss:0.007469602296447645\n",
      "train loss:0.0005460379883747637\n",
      "train loss:0.0012992021274148347\n",
      "train loss:0.0027680766867081504\n",
      "train loss:0.002603515021993465\n",
      "train loss:0.001896315697128873\n",
      "train loss:0.0016476406698363259\n",
      "train loss:0.000169053616108063\n",
      "train loss:0.0014080373111341421\n",
      "train loss:0.0005689350121143796\n",
      "train loss:0.005523059602287205\n",
      "train loss:0.00153437088677273\n",
      "train loss:0.006673551584970642\n",
      "train loss:0.0034124303664922837\n",
      "train loss:0.0019072665103152173\n",
      "train loss:0.002164340420609924\n",
      "train loss:0.00020483598716970446\n",
      "train loss:0.0024250091281654185\n",
      "train loss:0.007377358080479936\n",
      "train loss:0.000414631490626644\n",
      "train loss:0.00028750120919526957\n",
      "train loss:0.004021622878689177\n",
      "train loss:0.0010619060237056686\n",
      "train loss:0.0018887040850243883\n",
      "train loss:0.001054596613281845\n",
      "train loss:0.0006777342282790126\n",
      "train loss:0.0019000142134978555\n",
      "train loss:0.0016923687800603877\n",
      "train loss:0.0013374798208092731\n",
      "train loss:0.008190721195525523\n",
      "train loss:0.0013600582479996299\n",
      "train loss:0.0028090776961634013\n",
      "train loss:0.0020030828028709045\n",
      "train loss:0.000863613898554976\n",
      "train loss:0.010251836253215274\n",
      "train loss:0.00013345399999469497\n",
      "train loss:0.0004895111501061689\n",
      "train loss:0.0011910051344767346\n",
      "train loss:0.0010668450034572053\n",
      "train loss:0.00038050721908980753\n",
      "train loss:0.006566446571192701\n",
      "train loss:0.006393604807250835\n",
      "train loss:0.00351772110211418\n",
      "train loss:0.003247730698159966\n",
      "train loss:0.002353745882957356\n",
      "train loss:0.0009963307427383232\n",
      "train loss:0.00477799389209732\n",
      "train loss:0.012243855253206148\n",
      "train loss:0.00337455927484579\n",
      "train loss:0.004022560841953536\n",
      "train loss:0.005108398860331582\n",
      "train loss:0.005942048276158371\n",
      "train loss:0.0006845635470593003\n",
      "train loss:0.002165164814335188\n",
      "train loss:0.0032491311388806237\n",
      "train loss:0.001076354079167383\n",
      "train loss:0.007958873753950131\n",
      "train loss:0.001996328452832787\n",
      "train loss:0.001432139309179615\n",
      "train loss:0.004381659135294919\n",
      "train loss:0.00336961227480067\n",
      "train loss:0.0003202701198587679\n",
      "train loss:0.005003834621665965\n",
      "train loss:0.006134642204780035\n",
      "train loss:0.0024743026852982065\n",
      "train loss:0.0010373796065794823\n",
      "train loss:0.0003552757067833631\n",
      "train loss:0.003314740657633562\n",
      "train loss:0.00613481908524465\n",
      "train loss:0.007088624378024897\n",
      "train loss:0.005932385401020658\n",
      "train loss:0.003678602698156866\n",
      "train loss:0.002019214895409917\n",
      "train loss:0.0071507946149557185\n",
      "train loss:0.006066679866870447\n",
      "train loss:0.0003642354871846681\n",
      "train loss:0.005107480646244334\n",
      "train loss:0.0007488085670429298\n",
      "train loss:0.002185449186755843\n",
      "train loss:0.006251059651830895\n",
      "train loss:0.004441779341557357\n",
      "train loss:0.00040023134850716716\n",
      "train loss:0.004333498177549891\n",
      "train loss:0.0064165879383165396\n",
      "train loss:0.0024810556716619156\n",
      "train loss:0.01883508497072944\n",
      "train loss:0.010018988218894926\n",
      "train loss:0.000439723748514295\n",
      "train loss:0.001455573176901178\n",
      "train loss:0.018327055170542485\n",
      "train loss:0.007349462525097395\n",
      "train loss:0.00018799125083780258\n",
      "train loss:0.00025715288906576444\n",
      "train loss:0.0013206224946481187\n",
      "train loss:0.001788049252672229\n",
      "train loss:0.00790365601925075\n",
      "train loss:0.001008867955059638\n",
      "train loss:0.0003590496743544323\n",
      "train loss:0.002314663894245223\n",
      "train loss:0.0019551819398284927\n",
      "train loss:0.02865880026271252\n",
      "train loss:0.0009633523439271445\n",
      "train loss:0.0002260261000432035\n",
      "train loss:0.0006633445762015726\n",
      "train loss:0.00014956323454188308\n",
      "train loss:0.0014308771047738026\n",
      "train loss:0.001442488916160097\n",
      "train loss:0.0033719191136031886\n",
      "train loss:0.0219071810653885\n",
      "train loss:0.0022000022772469493\n",
      "train loss:0.007460907362744765\n",
      "train loss:0.004958592496341278\n",
      "train loss:0.0012901726723451542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007092685359927267\n",
      "train loss:0.0016662292949924675\n",
      "train loss:0.001129401284409771\n",
      "train loss:0.00016241591823498914\n",
      "train loss:0.00010757788094093109\n",
      "train loss:0.006834605407405237\n",
      "train loss:0.0025295218257296082\n",
      "train loss:0.003069640757084858\n",
      "train loss:0.0029650282382219133\n",
      "train loss:0.0026448726803207034\n",
      "train loss:0.0032170230849519095\n",
      "train loss:0.0029900152794243872\n",
      "train loss:0.00936582146823177\n",
      "train loss:0.00016158586982049932\n",
      "train loss:0.00046598591243530773\n",
      "train loss:0.0014925888742643126\n",
      "train loss:0.00015157468662813686\n",
      "train loss:0.0023635559061388057\n",
      "train loss:0.0006869790501057515\n",
      "train loss:0.0048934484291231544\n",
      "train loss:0.004144713412742919\n",
      "train loss:0.013795484582228783\n",
      "train loss:0.005732626053364334\n",
      "train loss:0.0007425024276114986\n",
      "train loss:0.013707931402217799\n",
      "train loss:0.004911638199451866\n",
      "train loss:0.0015104209747997342\n",
      "train loss:0.0005277050276433818\n",
      "train loss:0.0006617264852518713\n",
      "train loss:0.009126611631558985\n",
      "train loss:0.004380777895179895\n",
      "train loss:0.005872165073559487\n",
      "train loss:0.0006621283177840179\n",
      "train loss:0.004429519427871017\n",
      "train loss:0.006007909800157794\n",
      "train loss:0.007933142084008239\n",
      "train loss:0.0015097890534123543\n",
      "train loss:0.041303327653905424\n",
      "train loss:0.002150261410872129\n",
      "train loss:0.0034892695845240994\n",
      "train loss:0.0021485785284139055\n",
      "train loss:0.008471515816548238\n",
      "train loss:0.003563222395463191\n",
      "train loss:0.007198791489975351\n",
      "train loss:0.0009979939656586223\n",
      "train loss:0.018008754544541386\n",
      "train loss:0.0030719691547055287\n",
      "train loss:0.015874587447762344\n",
      "train loss:0.001417260777314064\n",
      "train loss:0.0008884649827751786\n",
      "train loss:0.008134395747453955\n",
      "train loss:0.0005277894547061437\n",
      "train loss:0.0027001913822606504\n",
      "train loss:0.0032679018908603223\n",
      "train loss:0.007011050468858252\n",
      "train loss:0.0081508384212994\n",
      "train loss:0.002731285668420688\n",
      "train loss:0.008213958068748453\n",
      "train loss:0.001478733548426214\n",
      "train loss:0.00015491894810886267\n",
      "train loss:0.004806715144975816\n",
      "train loss:0.005082340719804327\n",
      "train loss:0.003381188228180411\n",
      "train loss:0.036854386347322965\n",
      "train loss:0.000580203422836828\n",
      "train loss:0.0010402245976262078\n",
      "train loss:0.000534605228806438\n",
      "train loss:0.009511014442296083\n",
      "train loss:0.013427909439083764\n",
      "train loss:0.005218759555395647\n",
      "train loss:0.009834279867988781\n",
      "train loss:0.0013056248068448373\n",
      "train loss:0.0018710617670870764\n",
      "train loss:0.0012632130505005582\n",
      "train loss:0.003909330428187062\n",
      "train loss:0.01064816648286344\n",
      "train loss:0.011938002513174823\n",
      "train loss:0.0028379849218750793\n",
      "train loss:0.002272217323481715\n",
      "train loss:0.0004925369138902318\n",
      "train loss:0.0013380308384726585\n",
      "train loss:0.02341113868056727\n",
      "train loss:0.006993747725872396\n",
      "train loss:0.001515019090977506\n",
      "train loss:0.0009373521862147404\n",
      "train loss:0.003772114252366311\n",
      "train loss:0.007188695887162849\n",
      "train loss:0.001983941915522492\n",
      "train loss:0.004017458207841168\n",
      "train loss:0.007000889157162084\n",
      "train loss:0.000804389277350651\n",
      "train loss:0.0009031772599768268\n",
      "train loss:0.007295508385759495\n",
      "train loss:0.0032288139365201658\n",
      "train loss:0.0002106399571295316\n",
      "train loss:0.009865884506865688\n",
      "train loss:0.0009186158844651127\n",
      "train loss:0.00023423486644296368\n",
      "train loss:0.00031040892584451425\n",
      "train loss:0.009929401529387151\n",
      "train loss:0.004225263686717341\n",
      "train loss:0.0072190144227328714\n",
      "train loss:0.0056630169100512166\n",
      "train loss:0.0025344113591101287\n",
      "train loss:0.0019695704733398525\n",
      "train loss:0.002214428983214091\n",
      "train loss:0.0016338389383357592\n",
      "train loss:0.009323274724717978\n",
      "train loss:0.008338385124881196\n",
      "train loss:0.0056769268822803596\n",
      "train loss:0.0026483735125237494\n",
      "train loss:0.0002014363722235025\n",
      "train loss:0.008065691356557101\n",
      "train loss:0.0015863984027595654\n",
      "train loss:0.00026968281164807333\n",
      "train loss:0.0036073948648895713\n",
      "train loss:0.004504496903461453\n",
      "train loss:0.004337995322143725\n",
      "train loss:0.002273760336923914\n",
      "train loss:0.0017500976342006418\n",
      "train loss:0.005740903862660684\n",
      "train loss:0.0004077712793847298\n",
      "train loss:0.0002288846726507171\n",
      "train loss:0.0020484690200280446\n",
      "train loss:0.0022759158203885556\n",
      "train loss:0.0028881332701342936\n",
      "train loss:0.01282792068115163\n",
      "train loss:0.0014512242189810972\n",
      "train loss:0.0004051860691954622\n",
      "train loss:0.0004521989116135953\n",
      "train loss:0.00036362544622043274\n",
      "train loss:0.0030716191180437647\n",
      "train loss:0.007782908085350023\n",
      "train loss:0.004992289078401057\n",
      "train loss:0.0031000030694351677\n",
      "train loss:0.002857961619476137\n",
      "train loss:0.0028553636729642578\n",
      "train loss:0.0015755813846574712\n",
      "train loss:0.00032146545909496636\n",
      "train loss:8.007280868880178e-05\n",
      "train loss:0.0009075790682758827\n",
      "train loss:0.0029481670152285613\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21404\\2665070209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_param\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                   evaluate_sample_num_per_epoch=1000)\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# 매개변수 보존\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\common\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\common\\trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train loss:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\simple_convnet.py\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, x, t)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0m정답\u001b[0m \u001b[0m레이블\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\simple_convnet.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\common\\layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mout_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 261\u001b[1;33m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim2col\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    262\u001b[0m         \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\개발 파일\\AI model study\\common\\util.py\u001b[0m in \u001b[0;36mim2col\u001b[1;34m(input_data, filter_h, filter_w, stride, pad)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mcol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mcol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout_h\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbf384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
